{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0812860a",
   "metadata": {},
   "source": [
    "# Quick Start\n",
    "\n",
    "Bridgic is an innovative framework for agent programming and dynamic task orchestration. It offers developers a brand-new programming paradigm. Whether it's for rapid experimentation, complex system orchestration, or building intelligent agents with long lifecycles, Bridgic provides concise and powerful support.\n",
    "\n",
    "## Word Learning Assistant\n",
    "\n",
    "In this tutorial, let's build a sample word learning assistant. Input a word, output its derivational variations and make sentences using these variations. At the same time, we will understand the sample usage of Bridgic along with the word learning assistant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea6b1e6",
   "metadata": {},
   "source": [
    "### 1. Initialize\n",
    "\n",
    "Before we start, let's prepare the running environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7468d809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the environment variables.\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "_api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "_model_name = os.environ.get(\"OPENAI_MODEL_NAME\")  # Using gpt-4.1-mini in this example\n",
    "\n",
    "# Import the necessary packages.\n",
    "from bridgic.core.automa import GraphAutoma, worker\n",
    "from bridgic.core.model.types import Message, Role\n",
    "from bridgic.llms.openai.openai_llm import OpenAILlm\n",
    "\n",
    "llm = OpenAILlm(\n",
    "    api_key=_api_key,\n",
    "    timeout=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7408993d",
   "metadata": {},
   "source": [
    "Bridgic provides a powerful encapsulation for model usage. Here, we will simply use it first. If you want to know more details, you can refer to this tutorial: [Model Usage](model_usage.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d70238",
   "metadata": {},
   "source": [
    "### 2. Complete\n",
    "\n",
    "There are two steps to complete the word learning assistant:\n",
    "\n",
    "1. Generate derivatives of the input word.\n",
    "2. Make sentences with derivatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da260e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordLearningAssistant(GraphAutoma):\n",
    "    @worker(is_start=True)\n",
    "    async def generate_derivatives(self, word: str):\n",
    "        print(f\"------Generating derivatives for {word}------\")\n",
    "        response = await llm.achat(\n",
    "            model=_model_name,\n",
    "            messages=[\n",
    "                Message.from_text(text=\"You are a word learning assistant. Generate derivatives of the input word in a list.\", role=Role.SYSTEM),\n",
    "                Message.from_text(text=word, role=Role.USER),\n",
    "            ]\n",
    "        )\n",
    "        print(response.message.content)\n",
    "        print(f\"------End of generating derivatives------\\n\")\n",
    "        return response.message.content\n",
    "\n",
    "    @worker(dependencies=[\"generate_derivatives\"], is_output=True)\n",
    "    async def make_sentences(self, derivatives):\n",
    "        print(f\"------Making sentences with------\")\n",
    "        response = await llm.achat(\n",
    "            model=_model_name,\n",
    "            messages=[\n",
    "                Message.from_text(text=\"You are a word learning assistant. Make sentences with the input derivatives in a list.\", role=Role.SYSTEM),\n",
    "                Message.from_text(text=derivatives, role=Role.USER),\n",
    "            ]\n",
    "        )\n",
    "        print(response.message.content)\n",
    "        print(f\"------End of making sentences------\\n\")\n",
    "        return response.message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81cf951d",
   "metadata": {},
   "source": [
    "Let's run it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6fbb8d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Generating derivatives for happy------\n",
      "1. happiness  \n",
      "2. happily  \n",
      "3. happier  \n",
      "4. happiest  \n",
      "5. unhappiness  \n",
      "6. unhappily  \n",
      "7. unhappier  \n",
      "8. unhappiest\n",
      "------End of generating derivatives------\n",
      "\n",
      "------Making sentences with------\n",
      "1. Happiness is the key to a fulfilling life.  \n",
      "2. She happily accepted the invitation to the party.  \n",
      "3. I'm happier now that I've started a new job.  \n",
      "4. That was the happiest day of my childhood.  \n",
      "5. His unhappiness became apparent after the breakup.  \n",
      "6. They lived unhappily together for many years.  \n",
      "7. After the storm, the plants looked unhappier than before.  \n",
      "8. She felt the unhappiest when she lost her favorite book.\n",
      "------End of making sentences------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "word_learning_assistant = WordLearningAssistant()\n",
    "res = await word_learning_assistant.arun(word=\"happy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a176cd0c",
   "metadata": {},
   "source": [
    "> Note: Ensure you have set up your .env file to store your OPENAI_API_KEY or set up your terminal environment variable. This key is necessary for authenticating requests to the OpenAI API.\n",
    "\n",
    "Great! We have successfully completed the word learning assistant. It correctly completed the task as per our requirements.\n",
    "\n",
    "<div style=\"text-align: center; margin: 2rem 0;\">\n",
    "<hr style=\"border: none; border-top: 2px solid #e2e8f0;\">\n",
    "</div>\n",
    "\n",
    "## What have we done?\n",
    "\n",
    "The above example is the typical usage of writing an agent application with Bridgic. Now let's understand some of its components.\n",
    "\n",
    "### Worker\n",
    "\n",
    "Any callable object (such as functions, methods, etc.) when used by the framework, will be converted into a worker object and serve as the **smallest execution unit** for scheduling and orchestration. \n",
    "\n",
    "Just as in the example of the word learning assistant, we can use decorator syntax to wrap functions and methods into a worker object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d507c1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyAutoma(GraphAutoma):\n",
    "    @worker(is_start=True)\n",
    "    async def start(self, x: int):\n",
    "        return x    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ed3b6b",
   "metadata": {},
   "source": [
    "Or, you can also use it like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614c5d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyAutoma(GraphAutoma): ...\n",
    "my_automa = MyAutoma()\n",
    "\n",
    "# Add the function as a worker with worker decorator in the instance of the automa\n",
    "@my_automa.worker(is_start=True)\n",
    "async def start(x: int):\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fa90f6",
   "metadata": {},
   "source": [
    "Another one, the interface `add_func_as_worker()` can also be used to add workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24aa7fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def start(x: int):\n",
    "    return x\n",
    "\n",
    "class MyAutoma(GraphAutoma): ...\n",
    "my_automa = MyAutoma()\n",
    "\n",
    "# Add the function as a worker\n",
    "my_automa.add_func_as_worker(\n",
    "    key=\"start\",\n",
    "    func=start,\n",
    "    is_start=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179b434b",
   "metadata": {},
   "source": [
    "In addition to functions being convertible to workers, classes that inherit from `Worker` and override either `run()` or `arun()` can also be used directly as workers by `add_worker()` interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940f833b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bridgic.core.automa.worker import Worker\n",
    "\n",
    "class MyWorker(Worker):\n",
    "    async def arun(self, x: int):\n",
    "        return x\n",
    "\n",
    "my_worker = MyWorker()\n",
    "\n",
    "# Add the worker to the automa\n",
    "class MyAutoma(GraphAutoma): ...\n",
    "my_automa = MyAutoma()\n",
    "my_automa.add_worker(\n",
    "    key=\"my_worker\",\n",
    "    worker=my_worker,\n",
    "    is_start=True,\n",
    ")\n",
    "\n",
    "# Run the worker\n",
    "res = await my_automa.arun(x=1)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5107c75",
   "metadata": {},
   "source": [
    "> Note:\n",
    "> 1. A specific worker that inherits from `Worker` must override either the `run()` or `arun()` method.\n",
    "> 2. Bridgic is a framework primarily designed for asynchronous execution, if both `run()` and `arun()` of a worker are overridden, `arun()` will take precedence.\n",
    "\n",
    "Both of these ways can correctly add the workers to `MyAutoma`. \n",
    "\n",
    "Whether using decorator syntax or the corresponding interface, there are usually some parameters:\n",
    "\n",
    "1. `key`: A string. As the unique identifier of a worker in the current automa, it must be ensured that there are no duplicate names within the same automa. Use function names or class names by default.\n",
    "2. `func`(in `add_func_as_worker()`) or `worker`(in `add_worker()`): The actual callable object. **The decorator syntax does not have this parameter.**\n",
    "3. `is_start`: `True` or `False`. Marking the worker as the start for automa. It can be set in multiple workers.\n",
    "4. `dependencies`: A list of string. Mark the preceding workers that the worker depends on.\n",
    "5. `is_output`: `True` or `False`. Marking the worker as the output for automa. There can only be one on an execution branch.\n",
    "6. `args_mapping_rule`: Parameter passing rule. For detailed information on behavior classes, please refer to the tutorial: [Parameter Passing](./parameter_passing.ipynb)\n",
    "\n",
    "> Note: From the perspective of the Bridgic, a worker must be placed in an automa for scheduling before it can be executed. Of course, even after packaging it as a worker, you can directly call `worker.arun()` or `worker.run()` to run it, but this is not within the purview of Bridgic.\n",
    "\n",
    "### Automa\n",
    "\n",
    "Automa serves as the **orchestration engine**. Developers can entrust multiple workers to automa for management, and it is responsible for unified scheduling and operation, acting as the entry point for the entire process.\n",
    "\n",
    "Different types of automa represent different orchestration rules. In the example of the word learning assistant above, we used the `GraphAutoma`, which represents the orchestration and scheduling according to the topological sorting among workers.\n",
    "\n",
    "You can use it by writing a class that inherits from it and writing or adding workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b78c10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write workers in MyAutoma\n",
    "class MyAutoma(GraphAutoma):\n",
    "    @worker(is_start=True)\n",
    "    async def worker_0(self, a, b, x, y):\n",
    "        print(f\"worker_0: a={a}, b={b}, x={x}, y={y}\")\n",
    "\n",
    "    @worker(is_start=True)\n",
    "    async def worker_1(self, x, y):\n",
    "        print(f\"worker_1: x={x}, y={y}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448fab9c",
   "metadata": {},
   "source": [
    "After an automa has the required workers, it can call `await automa_obj.arun(*args, **kwargs)` to start the entire scheduling operation. \n",
    "\n",
    "> Bridgic is an asynchronous framework, `Graphautoma` must be started using arun().\n",
    "\n",
    "At startup, the parameters of `automa_obj.arun(*args, **kwargs)` will be distributed to the worker with `is_start=True` according to positional parameters and keyword parameters. \n",
    "\n",
    "- positional parameters: The positional parameters will be filled into the parameter list of the worker with `is_start=True` in the order of input. An error will be raised if the parameter list of some worker is shorter than the number of positional parameters.\n",
    "- keyword parameters: The keyword parameter will be filled into the corresponding parameter of the corresponding worker with `is_start=True`.\n",
    "- priority: **Positional parameters have a higher priority than keyword parameters**.\n",
    "\n",
    "For example: we pass positional arguments `1` and `2`, and keyword arguments `x=3`, `y=4`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bc5041c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "worker_0: a=1, b=2, x=3, y=4\n",
      "worker_1: x=1, y=2\n"
     ]
    }
   ],
   "source": [
    "my_automa = MyAutoma()\n",
    "await my_automa.arun(1, 2, x=3, y=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9afd803",
   "metadata": {},
   "source": [
    "`1` and `2` were received in sequence by the first and second parameters of `worker_0` and `worker_1` respectively. Because positional parameters have a higher priority than keyword parameters, even if the parameter names of `worker_1` are the same as the input keyword parameters, they will still preferentially receive positional parameters.\n",
    "\n",
    "An error will be raised if the parameter list of some worker is shorter than the number of positional parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f188d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_automa = MyAutoma()\n",
    "await my_automa.arun(1, 2, 3, y=4)  # error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753eaf90",
   "metadata": {},
   "source": [
    "If all parameters are input in the keyword parameters, each worker with `is_start=True` can receive the corresponding parameter value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "331382da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "worker_0: a=1, b=2, x=3, y=4\n",
      "worker_1: x=3, y=4\n"
     ]
    }
   ],
   "source": [
    "my_automa = MyAutoma()\n",
    "await my_automa.arun(a=1, b=2, x=3, y=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023e1ed0",
   "metadata": {},
   "source": [
    "Now, we can start building our Bridgic project!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

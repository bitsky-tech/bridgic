{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ad7e065",
   "metadata": {},
   "source": [
    "# Parameter Passing\n",
    "\n",
    "Bridgic can orchestrate workflows composed of workers. There are three ways to pass data among workers, including Arguments Mapping, Arguments Injection, and Inputs Propagation. Now let's understand them with a sample example.\n",
    "\n",
    "<br>\n",
    "<div style=\"text-align: center;\">\n",
    "<img src=\"../imgs/Parameter_Passing.png\" alt=\"Parameter Passing\" width=\"800\" height=\"600\">\n",
    "</div>\n",
    "<br>\n",
    "\n",
    "## Query Expansion\n",
    "\n",
    "Query expansion is a common step in RAG and can enhance the quality of RAG. To enhance the quality of query expansion, developers often first extract the entity information from the question and use it to assist the model in expanding the original question. \n",
    "\n",
    "Now let's implement this. The user inputs the original question, and then we expand the question to obtain more sub-questions. There are three steps to complete the query expansion:\n",
    "\n",
    "1. Receive the user's input and perform preprocessing to get the original question.\n",
    "2. Extract the entity information from the question to get the entity information.\n",
    "3. Expand and obtain multiple queries.\n",
    "\n",
    "### 1. Initialize\n",
    "\n",
    "Before we start, let's prepare the running environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba6c074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the environment variables.\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "_api_base = os.environ.get(\"VLLM_SERVER_API_BASE\")\n",
    "_api_key = os.environ.get(\"VLLM_SERVER_API_KEY\")\n",
    "_model_name = os.environ.get(\"VLLM_SERVER_MODEL_NAME\")\n",
    "\n",
    "# Import the necessary packages.\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Dict, Tuple\n",
    "from bridgic.core.automa import GraphAutoma, worker, ArgsMappingRule\n",
    "from bridgic.core.intelligence import Message, Role, PydanticModel\n",
    "from bridgic.llms.vllm.vllm_server_llm import VllmServerLlm\n",
    "\n",
    "llm = VllmServerLlm(  # the llm instance\n",
    "    api_base=_api_base,\n",
    "    api_key=_api_key,\n",
    "    timeout=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c2ad70",
   "metadata": {},
   "source": [
    "### 2. Complete Query Expansion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76de67bc",
   "metadata": {},
   "source": [
    "Now let's implement this query expansion. We assume that the user query we receive is in JSON format. It contains three keys:\n",
    "1. `id`: A string that indicates who inputs the query.\n",
    "2. `query`: A string in the form of `Q: user_query` representing the question input by the user.\n",
    "3. `date`: The time when the user entered the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a18adef",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_obj = {\n",
    "    \"id\": \"user_1\",\n",
    "    \"query\": \"Q: What new developments have there been in RAG in the past year?\",\n",
    "    \"date\": \"2025-09-30\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa6f2d0",
   "metadata": {},
   "source": [
    "Furthermore, we define that when the model completes entity extraction and query expansion, it returns the result in a Pydantic data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e88b6d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EntityList(BaseModel):  # The expected format of the model output in the extract_entity worker\n",
    "    entities: List[str] = Field(description=\"All entities in the input.\")\n",
    "\n",
    "class QueryList(BaseModel):  # The expected format of the model output in the expand_query worker\n",
    "    queries: List[str] = Field(description=\"All queries in the input.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513805e8",
   "metadata": {},
   "source": [
    "Next, let's complete the three steps of query expansion to achieve our goal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99b17307",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryExpansion(GraphAutoma):\n",
    "    @worker(is_start=True)\n",
    "    async def pre_query(self, query_obj: Dict):  # Receive the user's input and preprocess query\n",
    "        query = query_obj[\"query\"].split(\":\")[1].strip()  \n",
    "        return query\n",
    "\n",
    "    @worker(is_start=True)\n",
    "    async def pre_date(self, query_obj: Dict):  # Receive the user's input and preprocess date\n",
    "        date = query_obj[\"date\"]\n",
    "        return date\n",
    "\n",
    "    @worker(dependencies=[\"pre_query\", \"pre_date\"], args_mapping_rule=ArgsMappingRule.AS_IS)\n",
    "    async def extract_entity(self, query: str, date: str):  # Extract the entity information from the question, get entity information.\n",
    "        response: EntityList = await llm.astructured_output(  \n",
    "            model=_model_name,\n",
    "            constraint=PydanticModel(model=EntityList),\n",
    "            messages=[\n",
    "                Message.from_text(text=\"extract the entity information from the given query\", role=Role.SYSTEM),\n",
    "                Message.from_text(text=query, role=Role.USER,),\n",
    "            ]\n",
    "        )\n",
    "        return query, response.entities, date\n",
    "\n",
    "    @worker(dependencies=[\"extract_entity\"], is_output=True, args_mapping_rule=ArgsMappingRule.AS_IS)\n",
    "    async def expand_query(self, query_meta: Tuple[str, List[str]]):  # Expand and obtain multiple queries.\n",
    "        query, entities, date = query_meta\n",
    "        task_input = f\"Query: {query}\\nEntities: {entities}\"\n",
    "        response: str = await llm.astructured_output(\n",
    "            model=_model_name,\n",
    "            constraint=PydanticModel(model=QueryList),\n",
    "            messages=[\n",
    "                Message.from_text(text=f\"Centered around the given entities and given date {date}, expand the query to obtain multiple queries\", role=Role.SYSTEM),\n",
    "                Message.from_text(text=task_input, role=Role.USER,),\n",
    "            ]\n",
    "        )\n",
    "        return response.queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631443a8",
   "metadata": {},
   "source": [
    "Let's run it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "235d5630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What are the latest advancements in Retrieval-Augmented Generation (RAG) technology as of 2025?',\n",
       " 'What new developments have emerged in RAG systems over the past 12 months?',\n",
       " 'How have RAG implementations evolved in the last year?',\n",
       " 'What innovations in RAG have been introduced between 2024 and 2025?',\n",
       " 'What are the key breakthroughs in RAG technology in 2025?',\n",
       " 'What new features or improvements have been added to RAG models in the past year?',\n",
       " 'How has the performance of RAG systems improved in the last 12 months?',\n",
       " 'What are the most recent trends and developments in RAG research and deployment?',\n",
       " 'What new techniques have been introduced in RAG to improve accuracy and efficiency in 2025?',\n",
       " 'What are the major updates in RAG frameworks and tools from 2024 to 2025?']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_expansion = QueryExpansion()\n",
    "await query_expansion.arun(query_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1b98fd",
   "metadata": {},
   "source": [
    "Get it! We have successfully completed the small module for query expansion. \n",
    "\n",
    "<div style=\"text-align: center; margin: 2rem 0;\">\n",
    "<hr style=\"border: none; border-top: 2px solid #e2e8f0;\">\n",
    "</div>\n",
    "\n",
    "## What have we done?\n",
    "\n",
    "Reviewing the code, we find that each `@worker` decorator has an `args_mapping_rule` parameter. Let's understand what it does.\n",
    "\n",
    "### Arguments Mapping\n",
    "\n",
    "The `args_mapping_rule` defines the way data is passed between directly dependent workers, that is, how the result of the previous worker is mapped to the parameter of the next worker. Its value can only be specified through the properties of `ArgsMappingRule`.\n",
    "\n",
    "#### AS_IS mode (Bridgic default)\n",
    "\n",
    "In the AS_IS mode, a worker will receive the output of all its directly dependent workers as input parameters in the order declared by the dependencies.\n",
    "\n",
    "In the above example, `extract_entity` declares dependencies: `dependencies=[\"pre_query\", \"pre_date\"]`, so the results of the two preceding workers will be mapped to the first and second parameters of `extract_entity` in the order specified by the dependencies declaration, the result of `pre_query` is mapped to `query` parameter and the result of `pre_date` is mapped to `date` parameter.\n",
    "\n",
    "> Note:\n",
    "> The declaration order in dependencies only affects the order of parameter mapping, but does not influence the execution order of the dependent workers.\n",
    "\n",
    "<br>\n",
    "<div style=\"text-align: center;\">\n",
    "<img src=\"../imgs/args_mapping_AS_IS.png\" alt=\"Parameter Passing\" width=\"600\" height=\"400\">\n",
    "</div>\n",
    "<br>\n",
    "\n",
    "Additionally, if the previous worker returns a result with multiple values, such as `return x, y`, then all the results will be passed as a tuple result. So in the above example, the parameter `query_meta` of `expand_query` received all the result values from `extract_entity`.\n",
    "\n",
    "#### UNPACK mode\n",
    "\n",
    "Let's go back to the previous example. In the `expand_query`, we receive the parameters from the previous worker in the `AS_IS` mode and manually unpack them as a whole, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a6ce2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@worker(dependencies=[\"extract_entity\"], is_output=True, args_mapping_rule=ArgsMappingRule.AS_IS)\n",
    "async def expand_query(self, query_meta: Tuple[str, List[str]]):  # Expand and obtain multiple queries.\n",
    "    query, entities, date = query_meta\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6714f641",
   "metadata": {},
   "source": [
    "This operation requires knowing what the parameters of `query_meta` as a whole contain, which might seem inconvenient. Could we complete the unpacking operation and fill in the corresponding parameters when returning? At this point, the `UNPACK` mode comes in handy.\n",
    "\n",
    "Let's modify the `expand_query` in the above example and add some print messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c877f908",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryExpansion(GraphAutoma):\n",
    "    @worker(is_start=True)\n",
    "    async def pre_query(self, query_obj: Dict):  # Receive the user's input and preprocess query\n",
    "        query = query_obj[\"query\"].split(\":\")[1].strip()  \n",
    "        return query\n",
    "\n",
    "    @worker(is_start=True)\n",
    "    async def pre_date(self, query_obj: Dict):  # Receive the user's input and preprocess date\n",
    "        date = query_obj[\"date\"]\n",
    "        return date\n",
    "\n",
    "    @worker(dependencies=[\"pre_query\", \"pre_date\"], args_mapping_rule=ArgsMappingRule.AS_IS)\n",
    "    async def extract_entity(self, query: str, date: str):  # Extract the entity information from the question, get entity information.\n",
    "        response: EntityList = await llm.astructured_output(  \n",
    "            model=_model_name,\n",
    "            constraint=PydanticModel(model=EntityList),\n",
    "            messages=[\n",
    "                Message.from_text(text=\"extract the entity information from the given query\", role=Role.SYSTEM),\n",
    "                Message.from_text(text=query, role=Role.USER,),\n",
    "            ]\n",
    "        )\n",
    "        return query, response.entities, date\n",
    "\n",
    "    @worker(dependencies=[\"extract_entity\"], is_output=True, args_mapping_rule=ArgsMappingRule.UNPACK)\n",
    "    async def expand_query(self, query: str, entities: List[str], date: str):  # Expand and obtain multiple queries.\n",
    "        print(f\"query: {query}, entities: {entities}, date: {date}\")\n",
    "        task_input = f\"Query: {query}\\nEntities: {entities}\"\n",
    "        response: str = await llm.astructured_output(\n",
    "            model=_model_name,\n",
    "            constraint=PydanticModel(model=QueryList),\n",
    "            messages=[\n",
    "                Message.from_text(text=f\"Centered around the given entities and given date {date}, expand the query to obtain multiple queries\", role=Role.SYSTEM),\n",
    "                Message.from_text(text=task_input, role=Role.USER,),\n",
    "            ]\n",
    "        )\n",
    "        return response.queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c993d7",
   "metadata": {},
   "source": [
    "Let's run it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eef02735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query: What new developments have there been in RAG in the past year?, entities: ['RAG', 'new developments', 'past year'], date: 2025-09-30\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['What are the latest advancements in Retrieval-Augmented Generation (RAG) technologies as of 2025?',\n",
       " 'What new developments have emerged in RAG systems over the past 12 months?',\n",
       " 'How has RAG evolved in the last year with regard to accuracy, efficiency, and scalability?',\n",
       " 'What are the key innovations in RAG that have been introduced between 2024 and 2025?',\n",
       " 'What new tools and frameworks have been launched for RAG implementation in the past year?',\n",
       " 'What recent breakthroughs in RAG have improved context handling and retrieval precision?',\n",
       " 'How have large language models integrated with RAG in the past year to enhance performance?',\n",
       " 'What are the most significant updates in RAG-based applications from 2024 to 2025?',\n",
       " 'What new techniques in RAG have been proposed to reduce hallucinations and improve factual consistency?',\n",
       " 'How have RAG solutions adapted to real-time data retrieval and dynamic content updates in the past year?']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_expansion = QueryExpansion()\n",
    "await query_expansion.arun(query_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffa3e8b",
   "metadata": {},
   "source": [
    "Get it! All the parameters were unpacked and accepted. It can be seen that the `unpack` mode makes our task flow clearer!\n",
    "\n",
    "However, it should be noted that the UNPACK mechanism requires that the current worker can only directly depend on one worker; otherwise, the results of multiple workers will be confused when unpacking!\n",
    "\n",
    "#### MERGE\n",
    "\n",
    "At the same time, conversely, since there is an UNPACK mechanism, is there also a mechanism that can aggregate multiple results for receiving? This is particularly useful when a worker collects the results of multiple dependent workers. At this point, the `MERGE` mode comes in handy.\n",
    "\n",
    "Still referring to the example above, `extract_entity` actually received the results from two workers. Now let's try to make `extract_entity` receive all these results in a single parameter for use, instead of receiving two parameters.\n",
    "\n",
    "Let's modify the `extract_entity` in the above example and add some print messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20669f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryExpansion(GraphAutoma):\n",
    "    @worker(is_start=True)\n",
    "    async def pre_query(self, query_obj: Dict):  # Receive the user's input and preprocess query\n",
    "        query = query_obj[\"query\"].split(\":\")[1].strip()  \n",
    "        return query\n",
    "\n",
    "    @worker(is_start=True)\n",
    "    async def pre_date(self, query_obj: Dict):  # Receive the user's input and preprocess date\n",
    "        date = query_obj[\"date\"]\n",
    "        return date\n",
    "\n",
    "    @worker(dependencies=[\"pre_query\", \"pre_date\"], args_mapping_rule=ArgsMappingRule.MERGE)\n",
    "    async def extract_entity(self, query_meta: Tuple[str, str]):  # Extract the entity information from the question, get entity information.\n",
    "        print(f\"query_meta: {query_meta}\")\n",
    "        query, date = query_meta\n",
    "        response: EntityList = await llm.astructured_output(  \n",
    "            model=_model_name,\n",
    "            constraint=PydanticModel(model=EntityList),\n",
    "            messages=[\n",
    "                Message.from_text(text=\"extract the entity information from the given query\", role=Role.SYSTEM),\n",
    "                Message.from_text(text=query, role=Role.USER,),\n",
    "            ]\n",
    "        )\n",
    "        return query, response.entities, date\n",
    "\n",
    "    @worker(dependencies=[\"extract_entity\"], is_output=True, args_mapping_rule=ArgsMappingRule.UNPACK)\n",
    "    async def expand_query(self, query: str, entities: List[str], date: str):  # Expand and obtain multiple queries.\n",
    "        task_input = f\"Query: {query}\\nEntities: {entities}\"\n",
    "        response: str = await llm.astructured_output(\n",
    "            model=_model_name,\n",
    "            constraint=PydanticModel(model=QueryList),\n",
    "            messages=[\n",
    "                Message.from_text(text=f\"Centered around the given entities and given date {date}, expand the query to obtain multiple queries\", role=Role.SYSTEM),\n",
    "                Message.from_text(text=task_input, role=Role.USER,),\n",
    "            ]\n",
    "        )\n",
    "        return response.queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234bfee4",
   "metadata": {},
   "source": [
    "Let's run it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73143dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query_meta: ['What new developments have there been in RAG in the past year?', '2025-09-30']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['What are the latest advancements in Retrieval-Augmented Generation (RAG) technology as of 2025?',\n",
       " 'What new developments have emerged in RAG systems over the past 12 months?',\n",
       " 'How has RAG evolved in the last year with recent innovations in AI and NLP?',\n",
       " 'What are the key updates and breakthroughs in RAG models from 2024 to 2025?',\n",
       " 'What new features or improvements have been introduced in RAG implementations in the past year?',\n",
       " 'What are the most significant RAG developments reported in 2025?',\n",
       " 'How have retrieval and generation components in RAG been improved in the last year?',\n",
       " 'What are the recent trends and new developments in RAG applications from 2024 to 2025?',\n",
       " 'What innovations in RAG have been introduced by leading AI companies in the past year?',\n",
       " 'What new challenges and solutions have emerged in RAG research over the last 12 months?']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_expansion = QueryExpansion()\n",
    "await query_expansion.arun(query_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c764c362",
   "metadata": {},
   "source": [
    "Get it! The results that `extract_entity` depends on from the workers have all been collected into a list and passed to its parameters.\n",
    "\n",
    "### Arguments Injection\n",
    "\n",
    "Looking back at the example above, we actually find that the `date` information is passed through `pre_date`, `extract_entity`, and finally reaches `expand_query`. However, in reality, `extract_entity` doesn't use this information at all. Thus, passing `date` here seems redundant. And The use of `date` in `expand_query` essentially only means that the data depends on it, but whether it is executed or not, this control dependency does not directly rely on it.\n",
    "\n",
    "> Bridgic emphasizes the separation of data dependency and control dependency. This is beneficial for the future construction of complex execution graphs, as it allows for decoupling and avoids the need to adjust the entire orchestration map due to changes in data dependency. If you want to know Bridgic's in-depth thoughts on this aspect, **you can read this document**.\n",
    "\n",
    "In bridgic, we can use Arguments Injection to make it. We can indicate which worker's result to take by using the `From` marker when declaring parameters, and at the same time set the default value if no result is obtained. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e5c03ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the From marker\n",
    "from bridgic.core.automa import From"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56004fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "@worker(dependencies=[\"extract_entity\"], is_output=True, args_mapping_rule=ArgsMappingRule.UNPACK)\n",
    "async def expand_query(self, query_meta: Tuple[str, str], date: str = From(\"pre_date\", \"2025-01-01\")):  # Expand and obtain multiple queries.\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62cbc450",
   "metadata": {},
   "source": [
    "`date: str = From(\"pre_date\", \"2025-01-01\")` indicates that the value of `date` will be assigned based on the result of the `pre_date` worker. If the result from this worker has not yet been produced, the default value will be used instead.\n",
    "\n",
    "> If the pre_date worker does not exist, or if the pre_date worker has not yet produced a result, and there is no default value, an error will be reported: AutomaDataInjectionError.\n",
    "\n",
    "Let's modify the above example and add some print messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d53af7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryExpansion(GraphAutoma):\n",
    "    @worker(is_start=True)\n",
    "    async def pre_query(self, query_obj: Dict):  # Receive the user's input and preprocess query\n",
    "        query = query_obj[\"query\"].split(\":\")[1].strip()  \n",
    "        return query\n",
    "\n",
    "    @worker(is_start=True)\n",
    "    async def pre_date(self, query_obj: Dict):  # Receive the user's input and preprocess date\n",
    "        date = query_obj[\"date\"]\n",
    "        return date\n",
    "\n",
    "    @worker(dependencies=[\"pre_query\"], args_mapping_rule=ArgsMappingRule.AS_IS)\n",
    "    async def extract_entity(self, query: str):  # Extract the entity information from the question, get entity information.\n",
    "        response: EntityList = await llm.astructured_output(  \n",
    "            model=_model_name,\n",
    "            constraint=PydanticModel(model=EntityList),\n",
    "            messages=[\n",
    "                Message.from_text(text=\"extract the entity information from the given query\", role=Role.SYSTEM),\n",
    "                Message.from_text(text=query, role=Role.USER,),\n",
    "            ]\n",
    "        )\n",
    "        return query, response.entities\n",
    "\n",
    "    @worker(dependencies=[\"extract_entity\"], is_output=True, args_mapping_rule=ArgsMappingRule.UNPACK)\n",
    "    async def expand_query(self, query: str, entities: List[str], date: str = From(\"pre_date\", \"2025-01-01\")):  # Expand and obtain multiple queries.\n",
    "        print(f\"query: {query}, entities: {entities}, date: {date}\")\n",
    "        task_input = f\"Query: {query}\\nEntities: {entities}\"\n",
    "        response: str = await llm.astructured_output(\n",
    "            model=_model_name,\n",
    "            constraint=PydanticModel(model=QueryList),\n",
    "            messages=[\n",
    "                Message.from_text(text=f\"Centered around the given entities and given date {date}, expand the query to obtain multiple queries\", role=Role.SYSTEM),\n",
    "                Message.from_text(text=task_input, role=Role.USER,),\n",
    "            ]\n",
    "        )\n",
    "        return response.queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcc8d11",
   "metadata": {},
   "source": [
    "Let's run it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77f91d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query: What new developments have there been in RAG in the past year?, entities: ['RAG', 'new developments', 'past year'], date: 2025-09-30\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['What are the latest advancements in Retrieval-Augmented Generation (RAG) technology as of 2025?',\n",
       " 'What new developments have emerged in RAG systems over the past 12 months?',\n",
       " 'How have RAG implementations evolved in the last year in terms of performance and scalability?',\n",
       " 'What innovations in RAG have been introduced in 2025 that improve accuracy and context handling?',\n",
       " 'What are the key breakthroughs in RAG research and deployment from 2024 to 2025?',\n",
       " 'What new tools and frameworks have been released for RAG in the past year?',\n",
       " 'How have privacy and security features improved in RAG systems over the last year?',\n",
       " 'What are the most notable RAG developments in enterprise AI applications from 2024 to 2025?',\n",
       " \"What recent improvements have been made to RAG's ability to handle long-context inputs?\",\n",
       " 'How has the integration of RAG with large language models evolved in the past year?']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_expansion = QueryExpansion()\n",
    "await query_expansion.arun(query_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff79e0b",
   "metadata": {},
   "source": [
    "I have modified `extract_entity`, and now it only accepts `query`, making its functionality more pure. Also, in `expand_query`, I have correctly obtained the `date`.\n",
    "\n",
    "### Inputs Propagation\n",
    "\n",
    "Looking back at the example above, our program did not process the `id` field in the input at all. Eventually, we only returned a list of generalized problems, which might cause the external call to be unable to associate which \"id\" corresponds to the result. However, this ID neither requires preprocessing nor is it needed for entity extraction.\n",
    "\n",
    "We can use Inputs Propagation to resolve it. This can be achieved by adding the name of the startup parameter to the worker when declaring the parameters.\n",
    "\n",
    "> Of course, we can resolve it by adding new start worker, using `From` marker, even passing worker by worker. The main purpose of using this feature here is to understand the Inputs Propagation mechanism of Bridgic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae547ab",
   "metadata": {},
   "source": [
    "```diff\n",
    "@worker(dependencies=[\"extract_entity\"], is_output=True args_mapping_rule=ArgsMappingRule.UNPACK)\n",
    "async def expand_query(\n",
    "    self, \n",
    "    query: str, \n",
    "    entities: List[str], \n",
    "+    query_obj: Dict,  # The input of the entire Automa\n",
    "    date: str = From(\"pre_date\", \"2025-01-01\"), \n",
    "):  # Expand and obtain multiple queries.\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c4b3b2",
   "metadata": {},
   "source": [
    "Let's modify the above example and add some print messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "10c6a68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryExpansion(GraphAutoma):\n",
    "    @worker(is_start=True)\n",
    "    async def pre_query(self, query_obj: Dict):  # Receive the user's input and preprocess query\n",
    "        query = query_obj[\"query\"].split(\":\")[1].strip()  \n",
    "        return query\n",
    "\n",
    "    @worker(is_start=True)\n",
    "    async def pre_date(self, query_obj: Dict):  # Receive the user's input and preprocess date\n",
    "        date = query_obj[\"date\"]\n",
    "        return date\n",
    "\n",
    "    @worker(dependencies=[\"pre_query\"], args_mapping_rule=ArgsMappingRule.AS_IS)\n",
    "    async def extract_entity(self, query: str):  # Extract the entity information from the question, get entity information.\n",
    "        response: EntityList = await llm.astructured_output(  \n",
    "            model=_model_name,\n",
    "            constraint=PydanticModel(model=EntityList),\n",
    "            messages=[\n",
    "                Message.from_text(text=\"extract the entity information from the given query\", role=Role.SYSTEM),\n",
    "                Message.from_text(text=query, role=Role.USER,),\n",
    "            ]\n",
    "        )\n",
    "        return query, response.entities\n",
    "\n",
    "    @worker(dependencies=[\"extract_entity\"], is_output=True, args_mapping_rule=ArgsMappingRule.UNPACK)\n",
    "    async def expand_query(self, query: str, entities: List[str], query_obj: Dict, date: str = From(\"pre_date\", \"2025-01-01\")):  # Expand and obtain multiple queries.\n",
    "        print(f\"query: {query}, entities: {entities}, date: {date}, query_obj: {query_obj}\")\n",
    "        task_input = f\"Query: {query}\\nEntities: {entities}\"\n",
    "        response: str = await llm.astructured_output(\n",
    "            model=_model_name,\n",
    "            constraint=PydanticModel(model=QueryList),\n",
    "            messages=[\n",
    "                Message.from_text(text=f\"Centered around the given entities and given date {date}, expand the query to obtain multiple queries\", role=Role.SYSTEM),\n",
    "                Message.from_text(text=task_input, role=Role.USER,),\n",
    "            ]\n",
    "        )\n",
    "        return {\"id\": query_obj[\"id\"], \"queries\": response.queries}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a537378",
   "metadata": {},
   "source": [
    "Let's run it! When using the Inputs Propagation, the startup parameters must be passed in the form of keywords at startup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6dc20d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query: What new developments have there been in RAG in the past year?, entities: ['RAG', 'new developments', 'past year'], date: 2025-09-30, query_obj: {'id': 'user_1', 'query': 'Q: What new developments have there been in RAG in the past year?', 'date': '2025-09-30'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 'user_1',\n",
       " 'queries': ['What are the latest advancements in Retrieval-Augmented Generation (RAG) technologies as of 2025?',\n",
       "  'What new developments have emerged in RAG systems over the past 12 months?',\n",
       "  'How have RAG implementations evolved in the last year in terms of performance and scalability?',\n",
       "  'What are the key innovations in RAG models reported between 2024 and 2025?',\n",
       "  'What new techniques have been introduced in RAG to improve accuracy and context retention in the past year?',\n",
       "  'What recent breakthroughs in RAG have been highlighted in 2025?',\n",
       "  'How have industry leaders advanced RAG technology in the last year?',\n",
       "  'What are the most significant updates in RAG frameworks and tools from 2024 to 2025?',\n",
       "  'What new challenges and solutions have been proposed in RAG research over the past year?',\n",
       "  'What developments in RAG have improved real-time retrieval and generation performance in 2025?']}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_expansion = QueryExpansion()\n",
    "await query_expansion.arun(query_obj=query_obj)  # using keyword parameter passing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346812eb",
   "metadata": {},
   "source": [
    "Among all the ways of parameter passing mentioned above, the priority order is: arguments mapping positional parameters > arguments injection > propagation > arguments mapping keyword parameters."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

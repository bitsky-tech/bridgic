{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd9f9b0d",
   "metadata": {},
   "source": [
    "# 并发模式\n",
    "\n",
    "Bridgic 主要运行在异步事件循环上，同时通过线程无缝支持 I/O 绑定任务。此设计确保了在多样化工作负载下的高并发性。\n",
    "\n",
    "## Web 内容分析助手\n",
    "\n",
    "为了探索 Bridgic 对并发的支持，让我们构建一个 Web 内容分析助手，以总结和介绍给定网页的主要内容。步骤如下：\n",
    "\n",
    "1. 爬取输入 URL 的相关内容。\n",
    "2. 总结和介绍主要内容\n",
    "\n",
    "### 1. 爬取相关内容\n",
    "\n",
    "以 *[Books to Scrape](http://books.toscrape.com/index.html)* 网站为例，我们得到了该网站上某本书页面的 URL。像这样："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609f7dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"http://books.toscrape.com/catalogue/a-light-in-the-attic_1000/index.html\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cc446c",
   "metadata": {},
   "source": [
    "该页面如下所示：\n",
    "\n",
    "<br>\n",
    "<div style=\"text-align: center;\">\n",
    "<img src=\"../../../imgs/books_to-scrape.png\" alt=\"参数传递\" width=\"800\" height=\"600\">\n",
    "</div>\n",
    "<br>\n",
    "\n",
    "> 注意：我们使用 [Books to Scrape](http://books.toscrape.com/index.html)，这是一个专门为练习网络爬虫而创建的演示网站，在本教程中进行介绍。请注意，这里编写爬虫的目的**不是**构建一个真实的爬虫，而是提供一个简单且安全的示例，以演示 Bridgic 如何处理同步和异步执行模型。\n",
    "\n",
    "我们使用 `requests` 来获取给定 URL 的网页内容。使用 `pip install requests` 安装 `requests` 包，并像这样爬取页面："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0bae62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_web_content(url):  # will return the web content of the given url\n",
    "    response = requests.get(url)\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4e4be8",
   "metadata": {},
   "source": [
    "### 2. 总结并介绍主要内容\n",
    "\n",
    "我们创建一个代理，输入一个 URL 并爬取相应的页面，然后让模型总结网页的主要内容。\n",
    "\n",
    "初始化运行时环境。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80454765",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set the API base and key.\n",
    "_api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "_api_base = os.environ.get(\"OPENAI_API_BASE\")\n",
    "_model_name = os.environ.get(\"OPENAI_MODEL_NAME\")\n",
    "\n",
    "# Import the necessary modules.\n",
    "from bridgic.core.automa import GraphAutoma, worker\n",
    "from bridgic.core.model.types import Message, Role\n",
    "from bridgic.llms.openai_like import OpenAILikeLlm\n",
    "\n",
    "llm = OpenAILikeLlm(api_base=_api_base, api_key=_api_key, timeout=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf4e99c",
   "metadata": {},
   "source": [
    "让我们编写一个网页内容分析助手。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03c9320",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WebContentAnalysisAgent(GraphAutoma):\n",
    "    @worker(is_start=True)\n",
    "    def crawl_web_content(self, url: str) -> str:\n",
    "        response = requests.get(url)\n",
    "        return response.text\n",
    "\n",
    "    @worker(dependencies=[\"crawl_web_content\"], is_output=True)\n",
    "    async def analyze_web_content(self, content: str) -> str:\n",
    "        response = await llm.achat(\n",
    "            model=_model_name,\n",
    "            messages=[\n",
    "                Message.from_text(text=\"You are a web content analysis assistant. Your task is to analyze the given web content and summarize the main content.\", role=Role.SYSTEM),\n",
    "                Message.from_text(text=content, role=Role.USER),\n",
    "            ]\n",
    "        )\n",
    "        return response.message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16734af",
   "metadata": {},
   "source": [
    "现在，让我们使用它来帮助我们分析内容。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f999eaf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- - - - - result - - - - -\n",
      "The provided HTML content is from a product page on **Books to Scrape**, a demo website designed for web scraping education. Here's a clear summary of the main content:\n",
      "\n",
      "---\n",
      "\n",
      "### **Main Content Summary: A Light in the Attic**\n",
      "\n",
      "- **Product Title**: *A Light in the Attic*  \n",
      "- **Author**: Shel Silverstein  \n",
      "- **Category**: Poetry  \n",
      "- **Product Type**: Book (Poetry with illustrations)  \n",
      "- **Price**: £51.77 (excl. and incl. tax; tax is £0.00)  \n",
      "- **Availability**: In stock (22 units available)  \n",
      "- **Rating**: 5 stars (all full stars)  \n",
      "- **Number of Reviews**: 0  \n",
      "\n",
      "---\n",
      "\n",
      "### **Product Description Highlights**\n",
      "- Celebrates its 20th anniversary with a special edition.\n",
      "- Known for humorous, creative, and rhythmic poetry that appeals to both children and adults.\n",
      "- Features classic verses such as *\"Rockabye Baby\"*:\n",
      "  > *\"Rockabye baby, in the treetop / Don't you know a treetop / Is no safe place to rock?\"*\n",
      "- Described as a timeless classic that brings joy and laughter to readers of all ages.\n",
      "\n",
      "---\n",
      "\n",
      "### **Important Note**\n",
      "> ⚠️ **This is a demo website** for web scraping training.  \n",
      "> - Prices and ratings are **randomly assigned** and **do not reflect real-world data**.  \n",
      "> - The site is not a real marketplace and should not be used for actual purchases.\n",
      "\n",
      "---\n",
      "\n",
      "### **Navigation Path**\n",
      "Home → Books → Poetry → *A Light in the Attic*\n",
      "\n",
      "---\n",
      "\n",
      "### **Visual Elements**\n",
      "- A single image of the book displayed in a carousel.\n",
      "- Clean, responsive layout with a header, product gallery, pricing, and description sections.\n",
      "\n",
      "---\n",
      "\n",
      "✅ **Purpose of the Page**: To demonstrate how to extract product details (title, price, description, availability, etc.) from e-commerce-style web pages — useful for teaching web scraping techniques.  \n",
      "\n",
      "❌ **Not for real shopping** — all data is fictional.  \n",
      "\n",
      "--- \n",
      "\n",
      "In short: This page showcases a fictional version of a beloved children's poetry book, presented in a realistic e-commerce format, but with no real pricing or user reviews.\n",
      "- - - - - end - - - - -\n"
     ]
    }
   ],
   "source": [
    "web_content_analysis_agent = WebContentAnalysisAgent()\n",
    "\n",
    "# Input the url of the web page to be analyzed.\n",
    "url = \"http://books.toscrape.com/catalogue/a-light-in-the-attic_1000/index.html\"\n",
    "\n",
    "# Call the agent to analyze the web content.\n",
    "res = await web_content_analysis_agent.arun(url)\n",
    "\n",
    "# Print the result.\n",
    "print(f'- - - - - result - - - - -')\n",
    "print(res)\n",
    "print(f'- - - - - end - - - - -')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad2c333",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; margin: 2rem 0;\">\n",
    "<hr style=\"border: none; border-top: 2px solid #e2e8f0;\">\n",
    "</div>\n",
    "\n",
    "## 我们学到了什么？\n",
    "\n",
    "从这个例子可以看出，Bridgic 可以在同一个 automa 中无缝调度异步和同步的 worker。尽管 `crawl_web_content` 执行了一个阻塞的网络请求，Bridgic 会自动将其分派到一个线程中，以确保事件循环保持不被阻塞。同时，`analyze_web_content` 在事件循环中异步运行。有关详细信息，请参阅 [`Worker`](../../../../reference/bridgic-core/bridgic/core/automa/worker/#bridgic.core.automa.worker.Worker)。\n",
    "\n",
    "通过这种方式，Bridgic 保持了异步优先的设计，但也通过其线程池提供了对 I/O 绑定操作的内置支持，确保在不同类型的工作负载之间顺利执行。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
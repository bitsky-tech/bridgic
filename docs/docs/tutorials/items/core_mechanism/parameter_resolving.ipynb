{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ad7e065",
   "metadata": {},
   "source": [
    "# Parameter Resolving\n",
    "\n",
    "In Bridgic, an execution unit (worker), can not only control how its results are passed to the workers that directly depend on it through the **Result Dispatching** mechanism, but also control how it receives the results from its preceding workers through the **Parameter Binding** mechanism. In addition, these mechanisms also determine how an automa’s input arguments are distributed to its internal workers. These two mechanisms are collectively referred to in Bridgic as **Parameter Resolving**.\n",
    "\n",
    "## Result Dispatching\n",
    "\n",
    "Result Dispatching is a mechanism used for distributing data from a worker to multiple workers that directly depend on it, or from an automa’s inputs to its start workers. Let's understand this feature through a practical example.\n",
    "\n",
    "Suppose we need to process multiple user queries in parallel. Each query needs to go through preprocessing, analysis, and then be aggregated. We can use the Result Dispatching mechanism to efficiently handle this scenario.\n",
    "\n",
    "### 1. Initialize\n",
    "\n",
    "Let's start by importing the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d590fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "from bridgic.core.automa import GraphAutoma, worker\n",
    "from bridgic.core.automa.args import InOrder, ResultDispatchingRule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380ea297",
   "metadata": {},
   "source": [
    "### 2. Process Every Inputs\n",
    "\n",
    "First, let's understand how to use [`InOrder`](../../../../reference/bridgic-core/bridgic/core/automa/args/#bridgic.core.automa.args.InOrder) when calling [`arun()`](../../../../reference/bridgic-core/bridgic/core/automa/#bridgic.core.automa.GraphAutoma.arun). When you have multiple start workers and want to distribute different input values to each of them, you can wrap the input data in `InOrder()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4644b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParallelProcessing(GraphAutoma):\n",
    "    @worker(is_start=True)\n",
    "    async def process_query_1(self, user_input: int) -> int:\n",
    "        print(f\"Processing query 1 with input: {user_input}\")\n",
    "        return user_input * 2  # 2\n",
    "    \n",
    "    @worker(is_start=True)\n",
    "    async def process_query_2(self, user_input: int) -> int:\n",
    "        print(f\"Processing query 2 with input: {user_input}\")\n",
    "        return user_input * 3  # 6\n",
    "    \n",
    "    @worker(dependencies=[\"process_query_1\", \"process_query_2\"], is_output=True)\n",
    "    async def aggregate_results(self, result1: int, result2: int) -> int:\n",
    "        print(f\"Aggregating: {result1} + {result2}\")\n",
    "        return result1 + result2  # 8\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc17e48",
   "metadata": {},
   "source": [
    "Now let's run it with `InOrder` to distribute different values to the two start workers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f88c9cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing query 1 with input: 1\n",
      "Processing query 2 with input: 2\n",
      "Aggregating: 2 + 6\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "automa = ParallelProcessing()\n",
    "res = await automa.arun(user_input=InOrder([1, 2]))\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7675f76",
   "metadata": {},
   "source": [
    "Great! As you can see, `InOrder([1, 2])` distributed the values `1` and `2` to `process_query_1` and `process_query_2` respectively, based on the order of the declaration of start workers.\n",
    "\n",
    "> **Note**: \n",
    "> 1. The length of the list/tuple in `InOrder()` must match the number of start workers that accept the corresponding parameter. Otherwise, an error will be raised.\n",
    "> 2. If the data wrapped by `InOrder()` is input in the form of kwargs, the workers must have the same parameter name. Otherwise, the parameters will not be received. \n",
    "\n",
    "<div style=\"text-align: center; margin: 2rem 0;\">\n",
    "<hr style=\"border: none; border-top: 2px solid #e2e8f0;\">\n",
    "</div>\n",
    "\n",
    "### 3. Process Every Item in Result Dispatching\n",
    "\n",
    "Now let's understand how to use [`result_dispatching_rule=ResultDispatchingRule.IN_ORDER`](../../../../reference/bridgic-core/bridgic/core/automa/args/#bridgic.core.automa.args.ResultDispatchingRule) to distribute a worker's output to multiple downstream workers.\n",
    "\n",
    "When a worker sets `result_dispatching_rule=ResultDispatchingRule.IN_ORDER`, its return value must be an iterable (tuple or list). Each element in the return value will be distributed to the downstream workers that directly depend on this worker, in the order they are declared or added. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "766b18ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResultDispatchingExample(GraphAutoma):\n",
    "    @worker(is_start=True, result_dispatching_rule=ResultDispatchingRule.AS_IS)\n",
    "    async def generate_data(self, user_input: int) -> int:\n",
    "        return user_input\n",
    "    \n",
    "    @worker(dependencies=[\"generate_data\"], result_dispatching_rule=ResultDispatchingRule.IN_ORDER)\n",
    "    async def process_and_split(self, data: int) -> Tuple[int, int]:\n",
    "        print(f\"Processing data: {data}\")\n",
    "        # Return a tuple that will be distributed to downstream workers\n",
    "        return data + 1, data + 2  # (2, 3)\n",
    "    \n",
    "    @worker(dependencies=[\"process_and_split\"])\n",
    "    async def worker_a(self, value: int) -> int:\n",
    "        print(f\"Worker A received: {value}\")\n",
    "        return value * 10  # 20\n",
    "    \n",
    "    @worker(dependencies=[\"process_and_split\"])\n",
    "    async def worker_b(self, value: int) -> int:\n",
    "        print(f\"Worker B received: {value}\")\n",
    "        return value * 20  # 60\n",
    "    \n",
    "    @worker(dependencies=[\"worker_a\", \"worker_b\"], is_output=True)\n",
    "    async def combine_results(self, result_a: int, result_b: int) -> int:\n",
    "        print(f\"Combining: {result_a} + {result_b}\")\n",
    "        return result_a + result_b  # 80\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7335dc01",
   "metadata": {},
   "source": [
    "When `process_and_split` returns `(2, 3)`, we want to distribute these elements to `worker_a` and `worker_b` respectively. Note that `result_dispatching_rule` should be set on the worker that **produces** the results, not on the workers that **receive** them.\n",
    "\n",
    "Now let's run it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6673266a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data: 1\n",
      "Worker A received: 2\n",
      "Worker B received: 3\n",
      "Combining: 20 + 60\n",
      "80\n"
     ]
    }
   ],
   "source": [
    "automa = ResultDispatchingExample()\n",
    "res = await automa.arun(user_input=1)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b21b69",
   "metadata": {},
   "source": [
    "Perfect! As you can see:\n",
    "\n",
    "1. `process_and_split` returned `(2, 3)` and had `result_dispatching_rule=ResultDispatchingRule.IN_ORDER`.\n",
    "2. The first value `2` was distributed to `worker_a` (the first downstream worker).\n",
    "3. The second value `3` was distributed to `worker_b` (the second downstream worker).\n",
    "4. Both workers processed their values and the results were combined.\n",
    "\n",
    "> **Important Notes**:\n",
    "> - The worker that sets `result_dispatching_rule=ResultDispatchingRule.IN_ORDER` must return an iterable (tuple or list).\n",
    "> - The length of the returned iterable must match the number of downstream workers that directly depend on this worker.\n",
    "> - The distribution order follows the order in which the downstream workers are declared in the graph.\n",
    "\n",
    "There are two mode of `ResultDispatchingRule`:\n",
    "- **AS_IS**: The result of the worker will be sent as a whole to each downstream worker that depends on it. This is the default behavior.\n",
    "- **IN_ORDER**: The workers will distribute the current results in sequence to the corresponding workers one by one according to the order in which the downstream workers are declared or added.\n",
    "\n",
    "\n",
    "## Parameter Binding\n",
    "\n",
    "Parameter Binding is a mechanism that specifies how a worker receives arguments from its direct predecessors, its non-direct predecessors, or from the input arguments of the automa it belongs to. There are three ways to accomplish the Parameter Binding process, including **Arguments Mapping**, **Arguments Injection**, and **Inputs Propagation**. Now let's understand them through a sample example.\n",
    "\n",
    "<br>\n",
    "<div style=\"text-align: center;\">\n",
    "<img src=\"../../../imgs/Parameter_Passing.png\" alt=\"Parameter Passing\" width=\"800\" height=\"600\">\n",
    "</div>\n",
    "<br>\n",
    "\n",
    "## Query expansion\n",
    "\n",
    "Query expansion is a common step in RAG and can enhance the quality of RAG. To enhance the quality of query expansion, developers often first extract the entity information from the query and use it to assist the model in expanding the original query. \n",
    "\n",
    "Now let's implement this. The user inputs the original query, and then we expand the query to obtain more queries. There are three steps to complete the query expansion:\n",
    "\n",
    "1. Receive the user's input and perform preprocessing to get the original query.\n",
    "2. Extract the entity information from the query to get the entity information.\n",
    "3. Expand and obtain multiple queries.\n",
    "\n",
    "### 1. Initialize\n",
    "\n",
    "Before we start, let's prepare the running environment. In this tutorial, we will use the [OpenAI model integration](../../../../reference/bridgic-llms-openai/bridgic/llms/openai/#bridgic.llms.openai.OpenAILlm) (not OpenAI-like) that supports the [`StructuredOutput`](../../../../reference/bridgic-core/bridgic/core/model/protocols/#bridgic.core.model.protocols.StructuredOutput) feature. Run the following `pip` command to make sure this integration is available.\n",
    "\n",
    "```shell\n",
    "pip install bridgic-llms-openai\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba6c074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the environment variables.\n",
    "import os\n",
    "\n",
    "_api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "_api_base = os.environ.get(\"OPENAI_API_BASE\")\n",
    "_model_name = os.environ.get(\"OPENAI_MODEL_NAME\")\n",
    "\n",
    "# Import the necessary packages.\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Dict, Tuple\n",
    "from bridgic.core.automa import GraphAutoma, worker\n",
    "from bridgic.core.automa.args import ArgsMappingRule\n",
    "from bridgic.core.model.types import Message, Role\n",
    "from bridgic.core.model.protocols import PydanticModel\n",
    "from bridgic.llms.openai import OpenAILlm, OpenAIConfiguration\n",
    "\n",
    "llm = OpenAILlm(  # the llm instance\n",
    "    api_base=_api_base,\n",
    "    api_key=_api_key,\n",
    "    timeout=5,\n",
    "    configuration=OpenAIConfiguration(model=_model_name)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c2ad70",
   "metadata": {},
   "source": [
    "### 2. Complete Query Expansion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76de67bc",
   "metadata": {},
   "source": [
    "Now let's implement this query expansion. We assume that the user query we receive is in JSON format. It contains three keys:\n",
    "1. `id`: A string that indicates who inputs the query.\n",
    "2. `query`: A string in the form of `Q: user_query` representing the question input by the user.\n",
    "3. `date`: The time when the user entered the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a18adef",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_obj = {\n",
    "    \"id\": \"user_1\",\n",
    "    \"query\": \"Q: What new developments have there been in RAG in the past year?\",\n",
    "    \"date\": \"2025-09-30\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa6f2d0",
   "metadata": {},
   "source": [
    "Furthermore, we define that when the model completes entity extraction and query expansion, it returns the result in a Pydantic data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e88b6d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EntityList(BaseModel):  # The expected format of the model output in the extract_entity worker\n",
    "    entities: List[str] = Field(description=\"All entities in the input.\")\n",
    "\n",
    "class QueryList(BaseModel):  # The expected format of the model output in the expand_query worker\n",
    "    queries: List[str] = Field(description=\"All queries in the input.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513805e8",
   "metadata": {},
   "source": [
    "Next, let's complete the three steps of query expansion to achieve our goal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b17307",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryExpansion(GraphAutoma):\n",
    "    @worker(is_start=True)\n",
    "    async def pre_query(self, query_obj: Dict):  # Receive the user's input and preprocess query\n",
    "        query = query_obj[\"query\"].split(\":\")[1].strip()  \n",
    "        return query\n",
    "\n",
    "    @worker(is_start=True)\n",
    "    async def pre_date(self, query_obj: Dict):  # Receive the user's input and preprocess date\n",
    "        date = query_obj[\"date\"]\n",
    "        return date\n",
    "\n",
    "    @worker(dependencies=[\"pre_query\", \"pre_date\"], args_mapping_rule=ArgsMappingRule.AS_IS)\n",
    "    async def extract_entity(self, query: str, date: str):  # Extract the entity information from the question, get entity information.\n",
    "        response: EntityList = await llm.astructured_output(  \n",
    "            constraint=PydanticModel(model=EntityList),\n",
    "            messages=[\n",
    "                Message.from_text(text=\"extract the entity information from the given query\", role=Role.SYSTEM),\n",
    "                Message.from_text(text=query, role=Role.USER,),\n",
    "            ]\n",
    "        )\n",
    "        return query, response.entities, date\n",
    "\n",
    "    @worker(dependencies=[\"extract_entity\"], is_output=True, args_mapping_rule=ArgsMappingRule.AS_IS)\n",
    "    async def expand_query(self, query_meta: Tuple[str, List[str]]):  # Expand and obtain multiple queries.\n",
    "        query, entities, date = query_meta\n",
    "        task_input = f\"Query: {query}\\nEntities: {entities}\"\n",
    "        response: QueryList = await llm.astructured_output(\n",
    "            constraint=PydanticModel(model=QueryList),\n",
    "            messages=[\n",
    "                Message.from_text(text=f\"Centered around the given entities and given date {date}, expand the query to obtain multiple queries\", role=Role.SYSTEM),\n",
    "                Message.from_text(text=task_input, role=Role.USER,),\n",
    "            ]\n",
    "        )\n",
    "        return response.queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631443a8",
   "metadata": {},
   "source": [
    "Let's run it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "235d5630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What are the latest advancements in Retrieval-Augmented Generation (RAG) technology as of 2025?',\n",
       " 'What new developments have emerged in RAG systems over the past 12 months?',\n",
       " 'How have RAG implementations evolved in the last year?',\n",
       " 'What innovations in RAG have been introduced between 2024 and 2025?',\n",
       " 'What are the key breakthroughs in RAG technology in 2025?',\n",
       " 'What new features or improvements have been added to RAG models in the past year?',\n",
       " 'How has the performance of RAG systems improved in the last 12 months?',\n",
       " 'What are the most recent trends and developments in RAG research and deployment?',\n",
       " 'What new techniques have been introduced in RAG to improve accuracy and efficiency in 2025?',\n",
       " 'What are the major updates in RAG frameworks and tools from 2024 to 2025?']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_expansion = QueryExpansion()\n",
    "await query_expansion.arun(query_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1b98fd",
   "metadata": {},
   "source": [
    "Great! We have successfully completed the small module for query expansion. \n",
    "\n",
    "<div style=\"text-align: center; margin: 2rem 0;\">\n",
    "<hr style=\"border: none; border-top: 2px solid #e2e8f0;\">\n",
    "</div>\n",
    "\n",
    "## What have we learnt?\n",
    "\n",
    "### Result Dispatching\n",
    "\n",
    "Result Dispatching provides powerful mechanisms for parallel / concurrent data processing:\n",
    "\n",
    "- **`Distribute` in `arun()`**: Distributes input values to multiple start workers element-wise\n",
    "- **`ResultDispatchRule`**: Allows a worker to distribute its output (must be iterable) to multiple downstream workers\n",
    "    - **AS_IS**: Default mode to send the result of current worker as a whole\n",
    "    - **Distribute**: Set to send the result of current worker according to the order in which the downstream workers are declared or added\n",
    "\n",
    "These features enable efficient parallel / concurrent processing and data flow management in complex workflows.\n",
    "\n",
    "### Arguments Mapping\n",
    "\n",
    "Reviewing the code, we find that each [`@worker`](../../../../reference/bridgic-core/bridgic/core/automa/#bridgic.core.automa.worker._worker_decorator.worker) decorator has an `args_mapping_rule` parameter. \n",
    "\n",
    "The `args_mapping_rule` defines the way data is passed between directly dependent workers, that is, how the result of the previous worker is mapped to the parameter of the next worker. Its value can only be specified through the properties of [`ArgsMappingRule`](../../../../reference/bridgic-core/bridgic/core/automa/args/#bridgic.core.automa.args.ArgsMappingRule).\n",
    "\n",
    "#### AS_IS mode (default)\n",
    "\n",
    "In the AS_IS mode, a worker will receive the output of all its directly dependent workers as input parameters in the order declared by the dependencies.\n",
    "\n",
    "In the above example, `extract_entity` declares dependencies: `dependencies=[\"pre_query\", \"pre_date\"]`, so the results of the two preceding workers will be mapped to the first and second parameters of `extract_entity` in the order specified by the dependencies declaration, the result of `pre_query` is mapped to `query` parameter and the result of `pre_date` is mapped to `date` parameter.\n",
    "\n",
    "> Note:\n",
    "> The declaration order in dependencies only affects the order of parameter mapping, but does not influence the execution order of the dependent workers.\n",
    "\n",
    "<br>\n",
    "<div style=\"text-align: center;\">\n",
    "<img src=\"../../../imgs/args_mapping_AS_IS.png\" alt=\"Parameter Passing\" width=\"600\" height=\"400\">\n",
    "</div>\n",
    "<br>\n",
    "\n",
    "Additionally, if the previous worker returns a result with multiple values, such as `return x, y`, then all the results will be passed as a tuple result. So in the above example, the parameter `query_meta` of `expand_query` received all the result values from `extract_entity`.\n",
    "\n",
    "#### UNPACK mode\n",
    "\n",
    "Let's go back to the previous example. In the `expand_query`, we receive the parameters from the previous worker in the `AS_IS` mode and manually unpack them as a whole, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a6ce2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@worker(dependencies=[\"extract_entity\"], is_output=True, args_mapping_rule=ArgsMappingRule.AS_IS)\n",
    "async def expand_query(self, query_meta: Tuple[str, List[str]]):  # Expand and obtain multiple queries.\n",
    "    query, entities, date = query_meta\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6714f641",
   "metadata": {},
   "source": [
    "This operation requires knowing what the parameters of `query_meta` as a whole contain, which might seem inconvenient. Could we complete the unpacking operation and fill in the corresponding parameters when returning? At this point, the `UNPACK` mode comes in handy.\n",
    "\n",
    "Let's modify the `expand_query` in the above example and add some print messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c877f908",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryExpansion(GraphAutoma):\n",
    "    @worker(is_start=True)\n",
    "    async def pre_query(self, query_obj: Dict):  # Receive the user's input and preprocess query\n",
    "        query = query_obj[\"query\"].split(\":\")[1].strip()  \n",
    "        return query\n",
    "\n",
    "    @worker(is_start=True)\n",
    "    async def pre_date(self, query_obj: Dict):  # Receive the user's input and preprocess date\n",
    "        date = query_obj[\"date\"]\n",
    "        return date\n",
    "\n",
    "    @worker(dependencies=[\"pre_query\", \"pre_date\"], args_mapping_rule=ArgsMappingRule.AS_IS)\n",
    "    async def extract_entity(self, query: str, date: str):  # Extract the entity information from the question, get entity information.\n",
    "        response: EntityList = await llm.astructured_output(  \n",
    "            constraint=PydanticModel(model=EntityList),\n",
    "            messages=[\n",
    "                Message.from_text(text=\"extract the entity information from the given query\", role=Role.SYSTEM),\n",
    "                Message.from_text(text=query, role=Role.USER,),\n",
    "            ]\n",
    "        )\n",
    "        return query, response.entities, date\n",
    "\n",
    "    @worker(dependencies=[\"extract_entity\"], is_output=True, args_mapping_rule=ArgsMappingRule.UNPACK)\n",
    "    async def expand_query(self, query: str, entities: List[str], date: str):  # Expand and obtain multiple queries.\n",
    "        print(f\"query: {query}, entities: {entities}, date: {date}\")\n",
    "        task_input = f\"Query: {query}\\nEntities: {entities}\"\n",
    "        response: QueryList = await llm.astructured_output(\n",
    "            constraint=PydanticModel(model=QueryList),\n",
    "            messages=[\n",
    "                Message.from_text(text=f\"Centered around the given entities and given date {date}, expand the query to obtain multiple queries\", role=Role.SYSTEM),\n",
    "                Message.from_text(text=task_input, role=Role.USER,),\n",
    "            ]\n",
    "        )\n",
    "        return response.queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c993d7",
   "metadata": {},
   "source": [
    "Let's run it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eef02735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query: What new developments have there been in RAG in the past year?, entities: ['RAG', 'new developments', 'past year'], date: 2025-09-30\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['What are the latest advancements in Retrieval-Augmented Generation (RAG) technologies as of 2025?',\n",
       " 'What new developments have emerged in RAG systems over the past 12 months?',\n",
       " 'How has RAG evolved in the last year with regard to accuracy, efficiency, and scalability?',\n",
       " 'What are the key innovations in RAG that have been introduced between 2024 and 2025?',\n",
       " 'What new tools and frameworks have been launched for RAG implementation in the past year?',\n",
       " 'What recent breakthroughs in RAG have improved context handling and retrieval precision?',\n",
       " 'How have large language models integrated with RAG in the past year to enhance performance?',\n",
       " 'What are the most significant updates in RAG-based applications from 2024 to 2025?',\n",
       " 'What new techniques in RAG have been proposed to reduce hallucinations and improve factual consistency?',\n",
       " 'How have RAG solutions adapted to real-time data retrieval and dynamic content updates in the past year?']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_expansion = QueryExpansion()\n",
    "await query_expansion.arun(query_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffa3e8b",
   "metadata": {},
   "source": [
    "Great! All the parameters were unpacked and accepted. It can be seen that the `unpack` mode makes our task flow clearer!\n",
    "\n",
    "However, it should be noted that the UNPACK mechanism requires that the current worker **can only directly depend on one worker**; otherwise, the results of multiple workers will be confused when unpacking!\n",
    "\n",
    "#### MERGE mode\n",
    "\n",
    "At the same time, conversely, since there is an UNPACK mechanism, is there also a mechanism that can aggregate multiple results for receiving? This is particularly useful when a worker collects the results of multiple dependent workers. At this point, the `MERGE` mode comes in handy.\n",
    "\n",
    "Still referring to the example above, `extract_entity` actually received the results from two workers. Now let's try to make `extract_entity` receive all these results in a single parameter for use, instead of receiving two parameters.\n",
    "\n",
    "Let's modify the `extract_entity` in the above example and add some print messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20669f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryExpansion(GraphAutoma):\n",
    "    @worker(is_start=True)\n",
    "    async def pre_query(self, query_obj: Dict):  # Receive the user's input and preprocess query\n",
    "        query = query_obj[\"query\"].split(\":\")[1].strip()  \n",
    "        return query\n",
    "\n",
    "    @worker(is_start=True)\n",
    "    async def pre_date(self, query_obj: Dict):  # Receive the user's input and preprocess date\n",
    "        date = query_obj[\"date\"]\n",
    "        return date\n",
    "\n",
    "    @worker(dependencies=[\"pre_query\", \"pre_date\"], args_mapping_rule=ArgsMappingRule.MERGE)\n",
    "    async def extract_entity(self, query_meta: Tuple[str, str]):  # Extract the entity information from the question, get entity information.\n",
    "        print(f\"query_meta: {query_meta}\")\n",
    "        query, date = query_meta\n",
    "        response: EntityList = await llm.astructured_output(  \n",
    "            constraint=PydanticModel(model=EntityList),\n",
    "            messages=[\n",
    "                Message.from_text(text=\"extract the entity information from the given query\", role=Role.SYSTEM),\n",
    "                Message.from_text(text=query, role=Role.USER,),\n",
    "            ]\n",
    "        )\n",
    "        return query, response.entities, date\n",
    "\n",
    "    @worker(dependencies=[\"extract_entity\"], is_output=True, args_mapping_rule=ArgsMappingRule.UNPACK)\n",
    "    async def expand_query(self, query: str, entities: List[str], date: str):  # Expand and obtain multiple queries.\n",
    "        task_input = f\"Query: {query}\\nEntities: {entities}\"\n",
    "        response: QueryList = await llm.astructured_output(\n",
    "            constraint=PydanticModel(model=QueryList),\n",
    "            messages=[\n",
    "                Message.from_text(text=f\"Centered around the given entities and given date {date}, expand the query to obtain multiple queries\", role=Role.SYSTEM),\n",
    "                Message.from_text(text=task_input, role=Role.USER,),\n",
    "            ]\n",
    "        )\n",
    "        return response.queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234bfee4",
   "metadata": {},
   "source": [
    "Let's run it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73143dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query_meta: ['What new developments have there been in RAG in the past year?', '2025-09-30']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['What are the latest advancements in Retrieval-Augmented Generation (RAG) technology as of 2025?',\n",
       " 'What new developments have emerged in RAG systems over the past 12 months?',\n",
       " 'How has RAG evolved in the last year with recent innovations in AI and NLP?',\n",
       " 'What are the key updates and breakthroughs in RAG models from 2024 to 2025?',\n",
       " 'What new features or improvements have been introduced in RAG implementations in the past year?',\n",
       " 'What are the most significant RAG developments reported in 2025?',\n",
       " 'How have retrieval and generation components in RAG been improved in the last year?',\n",
       " 'What are the recent trends and new developments in RAG applications from 2024 to 2025?',\n",
       " 'What innovations in RAG have been introduced by leading AI companies in the past year?',\n",
       " 'What new challenges and solutions have emerged in RAG research over the last 12 months?']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_expansion = QueryExpansion()\n",
    "await query_expansion.arun(query_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c764c362",
   "metadata": {},
   "source": [
    "Great! The results that `extract_entity` depends on from the workers have all been collected into a list and passed to its parameters.\n",
    "\n",
    "### Arguments Injection\n",
    "\n",
    "Looking back at the example above, we actually find that the `date` information is passed through `pre_date`, `extract_entity`, and finally reaches `expand_query`. However, in reality, `extract_entity` doesn't use this information at all. Thus, passing `date` here seems redundant. And The use of `date` in `expand_query` essentially only means that the data depends on it, but whether it is executed or not, this control dependency does not directly rely on it.\n",
    "\n",
    "> Bridgic emphasizes the separation of data dependency and control dependency. This is beneficial for the future construction of complex graphs, as it allows for decoupling and avoids the need to adjust the entire graph due to changes in data dependency.\n",
    "\n",
    "In Bridgic, we can use Arguments Injection to make it. We can indicate which worker's result to take by using the `From` marker when declaring parameters, and at the same time set the default value if no result is obtained. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5c03ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the From marker\n",
    "from bridgic.core.automa import From\n",
    "\n",
    "@worker(dependencies=[\"extract_entity\"], is_output=True, args_mapping_rule=ArgsMappingRule.UNPACK)\n",
    "async def expand_query(self, query_meta: Tuple[str, str], date: str = From(\"pre_date\", \"2025-01-01\")):  # Expand and obtain multiple queries.\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62cbc450",
   "metadata": {},
   "source": [
    "`date: str = From(\"pre_date\", \"2025-01-01\")` indicates that the value of `date` will be assigned based on the result of the `pre_date` worker. If the result from this worker has not yet been produced, the default value will be used instead.\n",
    "\n",
    "> If the pre_date worker does not exist, or if the pre_date worker has not yet produced a result, and there is no default value, an error will be reported: AutomaDataInjectionError.\n",
    "\n",
    "Let's modify the above example and add some print messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d53af7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryExpansion(GraphAutoma):\n",
    "    @worker(is_start=True)\n",
    "    async def pre_query(self, query_obj: Dict):  # Receive the user's input and preprocess query\n",
    "        query = query_obj[\"query\"].split(\":\")[1].strip()  \n",
    "        return query\n",
    "\n",
    "    @worker(is_start=True)\n",
    "    async def pre_date(self, query_obj: Dict):  # Receive the user's input and preprocess date\n",
    "        date = query_obj[\"date\"]\n",
    "        return date\n",
    "\n",
    "    @worker(dependencies=[\"pre_query\"], args_mapping_rule=ArgsMappingRule.AS_IS)\n",
    "    async def extract_entity(self, query: str):  # Extract the entity information from the question, get entity information.\n",
    "        response: EntityList = await llm.astructured_output(  \n",
    "            constraint=PydanticModel(model=EntityList),\n",
    "            messages=[\n",
    "                Message.from_text(text=\"extract the entity information from the given query\", role=Role.SYSTEM),\n",
    "                Message.from_text(text=query, role=Role.USER,),\n",
    "            ]\n",
    "        )\n",
    "        return query, response.entities\n",
    "\n",
    "    @worker(dependencies=[\"extract_entity\"], is_output=True, args_mapping_rule=ArgsMappingRule.UNPACK)\n",
    "    async def expand_query(self, query: str, entities: List[str], date: str = From(\"pre_date\", \"2025-01-01\")):  # Expand and obtain multiple queries.\n",
    "        print(f\"query: {query}, entities: {entities}, date: {date}\")\n",
    "        task_input = f\"Query: {query}\\nEntities: {entities}\"\n",
    "        response: QueryList = await llm.astructured_output(\n",
    "            constraint=PydanticModel(model=QueryList),\n",
    "            messages=[\n",
    "                Message.from_text(text=f\"Centered around the given entities and given date {date}, expand the query to obtain multiple queries\", role=Role.SYSTEM),\n",
    "                Message.from_text(text=task_input, role=Role.USER,),\n",
    "            ]\n",
    "        )\n",
    "        return response.queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcc8d11",
   "metadata": {},
   "source": [
    "Let's run it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77f91d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query: What new developments have there been in RAG in the past year?, entities: ['RAG', 'new developments', 'past year'], date: 2025-09-30\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['What are the latest advancements in Retrieval-Augmented Generation (RAG) technology as of 2025?',\n",
       " 'What new developments have emerged in RAG systems over the past 12 months?',\n",
       " 'How have RAG implementations evolved in the last year in terms of performance and scalability?',\n",
       " 'What innovations in RAG have been introduced in 2025 that improve accuracy and context handling?',\n",
       " 'What are the key breakthroughs in RAG research and deployment from 2024 to 2025?',\n",
       " 'What new tools and frameworks have been released for RAG in the past year?',\n",
       " 'How have privacy and security features improved in RAG systems over the last year?',\n",
       " 'What are the most notable RAG developments in enterprise AI applications from 2024 to 2025?',\n",
       " \"What recent improvements have been made to RAG's ability to handle long-context inputs?\",\n",
       " 'How has the integration of RAG with large language models evolved in the past year?']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_expansion = QueryExpansion()\n",
    "await query_expansion.arun(query_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff79e0b",
   "metadata": {},
   "source": [
    "I have modified `extract_entity`, and now it only accepts `query`, making its functionality more pure. Also, in `expand_query`, I have correctly obtained the `date`.\n",
    "\n",
    "### Inputs Propagation\n",
    "\n",
    "Looking back at the example above again, our program did not process the `id` field in the input at all. Eventually, we only returned a list of generalized problems, which might cause the external call to be unable to associate which \"id\" corresponds to the result. However, this ID neither requires preprocessing nor is it needed for entity extraction.\n",
    "\n",
    "We can use Inputs Propagation to resolve it. This can be achieved by adding the name of the startup parameter to the worker when declaring the parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae547ab",
   "metadata": {},
   "source": [
    "```diff\n",
    "@worker(dependencies=[\"extract_entity\"], is_output=True args_mapping_rule=ArgsMappingRule.UNPACK)\n",
    "async def expand_query(\n",
    "    self, \n",
    "    query: str, \n",
    "    entities: List[str], \n",
    "+    query_obj: Dict,  # The input of the entire Automa\n",
    "    date: str = From(\"pre_date\", \"2025-01-01\"), \n",
    "):  # Expand and obtain multiple queries.\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c4b3b2",
   "metadata": {},
   "source": [
    "Let's modify the above example and add some print messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c6a68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryExpansion(GraphAutoma):\n",
    "    @worker(is_start=True)\n",
    "    async def pre_query(self, query_obj: Dict):  # Receive the user's input and preprocess query\n",
    "        query = query_obj[\"query\"].split(\":\")[1].strip()  \n",
    "        return query\n",
    "\n",
    "    @worker(is_start=True)\n",
    "    async def pre_date(self, query_obj: Dict):  # Receive the user's input and preprocess date\n",
    "        date = query_obj[\"date\"]\n",
    "        return date\n",
    "\n",
    "    @worker(dependencies=[\"pre_query\"], args_mapping_rule=ArgsMappingRule.AS_IS)\n",
    "    async def extract_entity(self, query: str):  # Extract the entity information from the question, get entity information.\n",
    "        response: EntityList = await llm.astructured_output(  \n",
    "            constraint=PydanticModel(model=EntityList),\n",
    "            messages=[\n",
    "                Message.from_text(text=\"extract the entity information from the given query\", role=Role.SYSTEM),\n",
    "                Message.from_text(text=query, role=Role.USER,),\n",
    "            ]\n",
    "        )\n",
    "        return query, response.entities\n",
    "\n",
    "    @worker(dependencies=[\"extract_entity\"], is_output=True, args_mapping_rule=ArgsMappingRule.UNPACK)\n",
    "    async def expand_query(self, query: str, entities: List[str], query_obj: Dict, date: str = From(\"pre_date\", \"2025-01-01\")):  # Expand and obtain multiple queries.\n",
    "        print(f\"query: {query}, entities: {entities}, date: {date}, query_obj: {query_obj}\")\n",
    "        task_input = f\"Query: {query}\\nEntities: {entities}\"\n",
    "        response: QueryList = await llm.astructured_output(\n",
    "            constraint=PydanticModel(model=QueryList),\n",
    "            messages=[\n",
    "                Message.from_text(text=f\"Centered around the given entities and given date {date}, expand the query to obtain multiple queries\", role=Role.SYSTEM),\n",
    "                Message.from_text(text=task_input, role=Role.USER,),\n",
    "            ]\n",
    "        )\n",
    "        return {\"id\": query_obj[\"id\"], \"queries\": response.queries}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a537378",
   "metadata": {},
   "source": [
    "Let's run it! When using the Inputs Propagation, the startup parameters must be passed in the form of keywords at startup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6dc20d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query: What new developments have there been in RAG in the past year?, entities: ['RAG', 'new developments', 'past year'], date: 2025-09-30, query_obj: {'id': 'user_1', 'query': 'Q: What new developments have there been in RAG in the past year?', 'date': '2025-09-30'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 'user_1',\n",
       " 'queries': ['What are the latest advancements in Retrieval-Augmented Generation (RAG) technologies as of 2025?',\n",
       "  'What new developments have emerged in RAG systems over the past 12 months?',\n",
       "  'How have RAG implementations evolved in the last year in terms of performance and scalability?',\n",
       "  'What are the key innovations in RAG models reported between 2024 and 2025?',\n",
       "  'What new techniques have been introduced in RAG to improve accuracy and context retention in the past year?',\n",
       "  'What recent breakthroughs in RAG have been highlighted in 2025?',\n",
       "  'How have industry leaders advanced RAG technology in the last year?',\n",
       "  'What are the most significant updates in RAG frameworks and tools from 2024 to 2025?',\n",
       "  'What new challenges and solutions have been proposed in RAG research over the past year?',\n",
       "  'What developments in RAG have improved real-time retrieval and generation performance in 2025?']}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_expansion = QueryExpansion()\n",
    "await query_expansion.arun(query_obj=query_obj)  # using keyword parameter passing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346812eb",
   "metadata": {},
   "source": [
    "Among all the ways of parameter passing mentioned above, the priority order is: **arguments mapping positional parameters > arguments injection > propagation > arguments mapping keyword parameters**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

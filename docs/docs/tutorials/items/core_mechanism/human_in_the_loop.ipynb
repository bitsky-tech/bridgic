{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25379a8b",
   "metadata": {},
   "source": [
    "# Human-in-the-loop\n",
    "\n",
    "Bridgic provides the capabilities of human-in-the-loop. Bridgic regards it occurring within an automa as the whole behavior that interacts with the outside world.\n",
    "\n",
    "## Interaction Scenarios\n",
    "\n",
    "Let's understand this process through a few simple examples. Before we start, let's prepare the running environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e32e34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set the API base and key.\n",
    "_api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "_api_base = os.environ.get(\"OPENAI_API_BASE\")\n",
    "_model_name = os.environ.get(\"OPENAI_MODEL_NAME\")\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from bridgic.core.automa import GraphAutoma, worker, Snapshot\n",
    "from bridgic.core.automa.args import From\n",
    "from bridgic.core.automa.interaction import Event, Feedback, FeedbackSender, InteractionFeedback, InteractionException\n",
    "from bridgic.core.model.types import Message, Role\n",
    "from bridgic.core.model.protocols import PydanticModel\n",
    "from bridgic.llms.openai import OpenAILlm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f15da9",
   "metadata": {},
   "source": [
    "### Programming assistant\n",
    "\n",
    "When developing a programming assistant, after it finishes writing a function, the assistant can run and verify it by itself. However, running a program is an action that will allocate system resources, and the user needs to determine whether to allow execution.\n",
    "\n",
    "Let's achieve it with Bridgic. The steps are as follows:\n",
    "\n",
    "1. Generate code based on user requirements.\n",
    "2. Ask the user if they allow you to perform the verification.\n",
    "3. Output result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99108f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the LLM\n",
    "llm = OpenAILlm(api_base=_api_base, api_key=_api_key, timeout=10)\n",
    "\n",
    "class CodeBlock(BaseModel):\n",
    "    code: str = Field(description=\"The code to be executed.\")\n",
    "\n",
    "class CodeAssistant(GraphAutoma):\n",
    "    @worker(is_start=True)\n",
    "    async def generate_code(self, user_requirement: str):\n",
    "        response = await llm.astructured_output(\n",
    "            model=_model_name,\n",
    "            messages=[\n",
    "                Message.from_text(text=f\"You are a programming assistant. Please generate code according to the user's requirements.\", role=Role.SYSTEM),\n",
    "                Message.from_text(text=user_requirement, role=Role.USER),\n",
    "            ],\n",
    "            constraint=PydanticModel(model=CodeBlock)\n",
    "        )\n",
    "        return response.code\n",
    "\n",
    "    @worker(dependencies=[\"generate_code\"])\n",
    "    async def ask_to_run_code(self, code: str):\n",
    "        event = Event(event_type=\"can_run_code\", data=code)\n",
    "        feedback = await self.request_feedback_async(event)\n",
    "        return feedback.data\n",
    "        \n",
    "    @worker(dependencies=[\"ask_to_run_code\"])\n",
    "    async def output_result(self, feedback: str, code: str = From(\"generate_code\")):\n",
    "        code = code.strip(\"```python\").strip(\"```\")\n",
    "        if feedback == \"yes\":\n",
    "            print(f\"- - - - - - Result - - - - - -\")\n",
    "            exec(code)\n",
    "            print(f\"- - - - - - End - - - - - -\")\n",
    "        else:\n",
    "            print(f\"This code was rejected for execution. In response to the requirements, I have generated the following code:\\n {code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5136fc6c",
   "metadata": {},
   "source": [
    "In the `ask_to_run_code()` method of `CodeAssistant`, we use [`request_feedback_async()`](../../../../reference/bridgic-core/bridgic/core/automa/#bridgic.core.automa.Automa.request_feedback_async) to throw a specified Event and expect to receive feedback. To handle this Event, the corresponding logic needs to be registered in automa, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "23256d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "\n",
    "# Handle can_run_code event\n",
    "def can_run_code_handler(event: Event, feedback_sender: FeedbackSender):\n",
    "    print(f\"Can I run this code now to verify if it's correct?\")\n",
    "    print(event.data)\n",
    "    res = input(\"Please input your answer (yes/no): \")\n",
    "    print(f\"\\nPlease input your answer (yes/no): {res}\\n\")  # print the input\n",
    "    if res in [\"yes\", \"no\"]:\n",
    "        feedback_sender.send(Feedback(data=res))\n",
    "    else:\n",
    "        print(\"Invalid input. Please input yes or no.\")\n",
    "        feedback_sender.send(Feedback(data=\"no\"))\n",
    "\n",
    "# register can_run_code event handler to `CodeAssistant` automa\n",
    "code_assistant = CodeAssistant()\n",
    "code_assistant.register_event_handler(\"can_run_code\", can_run_code_handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be93ace5",
   "metadata": {},
   "source": [
    "Now let's use it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3f87eada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can I run this code now to verify if it's correct?\n",
      "```python\n",
      "def print_hello_world():\n",
      "    print('Hello, World!')\n",
      "\n",
      "# Call the function to print 'Hello, World!'\n",
      "print_hello_world()\n",
      "```\n",
      "\n",
      "Please input your answer (yes/no): yes\n",
      "\n",
      "- - - - - - Result - - - - - -\n",
      "Hello, World!\n",
      "- - - - - - End - - - - - -\n"
     ]
    }
   ],
   "source": [
    "await code_assistant.arun(user_requirement=\"Please write a function to print 'Hello, World!'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5674e729",
   "metadata": {},
   "source": [
    "In the above example, Bridgic uses [`Event`](../../../../reference/bridgic-core/bridgic/core/automa/interaction/#bridgic.core.automa.interaction.Event) to wrap the thrown event and [`FeedBack`](../../../../reference/bridgic-core/bridgic/core/automa/interaction/#bridgic.core.automa.interaction.Feedback) to wrap the external feedback information. \n",
    "\n",
    "- `Event` contains three fields:\n",
    "    - `event_type`: A string. The event type is used to identify the registered event handler.\n",
    "    - `timestamp`: A Python datetime object. The timestamp of the event. The default is `datetime.now()`.\n",
    "    - `data`: The data attached to the event.\n",
    "- `FeedBack` contains one field:\n",
    "    - `data`: The data attached to the feedback.\n",
    "\n",
    "`request_feedback_async()` indicates throwing a specific event and simultaneously blocking the program to wait for feedback. The method registered for handling events, if it generates feedback, must be defined as `func(event: Event, feedback_sender: FeedbackSender)`, where the first parameter is the corresponding event and the second parameter is used to send feedback: `feedback_sender.send(Feedback(data=...))`, back to where the event was thrown.\n",
    "\n",
    "### Counting notifier\n",
    "\n",
    "But sometimes, it might only be necessary to throw an event type without expecting any feedback. For example, message notifications. At this point, we call the [`post_event()`](../../../../reference/bridgic-core/bridgic/core/automa/#bridgic.core.automa.Automa.post_event) method and register the method `func(event: Event)` at the same time to achieve this process. \n",
    "\n",
    "For example, implement a counting notifier that counts from 1 to the number input by the user, and at the same time, the user sets which number to remind when it is counted to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ba2ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop from 1 to 10\n",
      "!! Now count to Loop 5 times. !!\n"
     ]
    }
   ],
   "source": [
    "class MessageNotifier(GraphAutoma):\n",
    "    @worker(is_start=True)\n",
    "    async def notify(self, user_input: int, notify_int: int):\n",
    "        print(f\"Loop from 1 to {user_input}\")\n",
    "        for i in range(1, user_input + 1):\n",
    "            if i == notify_int:\n",
    "                event = Event(event_type=\"message_notification\", data=f\"Loop {i} times\")\n",
    "                self.post_event(event)\n",
    "\n",
    "def message_notification_handler(event: Event):\n",
    "    print(f'!! Now count to {event.data}. !!')\n",
    "\n",
    "message_notifier = MessageNotifier()\n",
    "message_notifier.register_event_handler(\"message_notification\", message_notification_handler)\n",
    "await message_notifier.arun(user_input=10, notify_int=5)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7fb65d",
   "metadata": {},
   "source": [
    "### Message assistant\n",
    "\n",
    "When developing specific scenarios, sometimes after throwing an event, it is necessary to wait for its feedback. However, this feedback may take a very long time. If the system keeps waiting, there will be unnecessary waste of resources.\n",
    "\n",
    "Bridgic provides a powerful mechanism for interruption recovery in this situation. This enables the program to interrupt and save the current execution state when encountering such events, wait for a period of time, receive feedback, and then resume execution.\n",
    "\n",
    "Let's implement a message assistant that receives a message from user \"A\" and replies to it, but doesn't know how long it might have to wait for the reply."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f969e43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MessageAssistant(GraphAutoma):\n",
    "    @worker(is_start=True)\n",
    "    async def receive_message(self, message: str):\n",
    "        print(f'- - - - - - Received message - - - - - -')\n",
    "        print(message)\n",
    "        print(f'- - - - - - End - - - - - -\\n')\n",
    "        return message\n",
    "    \n",
    "    @worker(dependencies=[\"receive_message\"])\n",
    "    async def reply_message_and_wait_reply(self, message: str):\n",
    "        print(f'- - - - - - Reply Message - - - - - -')\n",
    "        response = await llm.achat(\n",
    "            model=_model_name,\n",
    "            messages=[\n",
    "                Message.from_text(text=f\"You are a message assistant. Please reply to the following message.\", role=Role.SYSTEM),\n",
    "                Message.from_text(text=message, role=Role.USER),\n",
    "            ]\n",
    "        )\n",
    "        print(response.message.content)\n",
    "        print(f'- - - - - - End - - - - - -\\n')\n",
    "\n",
    "        if \"Bye!\" in message:  # if the message contains \"Bye!\", the reply is complete\n",
    "            return \n",
    "\n",
    "        # wait for reply            \n",
    "        event = Event(event_type=\"wait_for_reply\")\n",
    "        feedback: InteractionFeedback = self.interact_with_human(event)  # interrupt to wait for reply and resume when feedback is received\n",
    "        self.ferry_to(\"receive_message\", feedback.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4365edb",
   "metadata": {},
   "source": [
    "Using [`interact_with_human()`](../../../../reference/bridgic-core/bridgic/core/automa/#bridgic.core.automa.Automa.interact_with_human) throws an event for which it is unknown how long it will take to process, at the same time, an [`InteractionException`](../../../../reference/bridgic-core/bridgic/core/automa/interaction/#bridgic.core.automa.interaction.InteractionException) is thrown.\n",
    "\n",
    "The `InteractionException` contains two fields:\n",
    "\n",
    "- `interactions`: A list of [`Interaction`](../../../../reference/bridgic-core/bridgic/core/automa/interaction/#bridgic.core.automa.interaction.Interaction), each `Interaction` containing an `interaction_id` and an `event`.\n",
    "- `snapshot`: a snapshot of the Automa's current state.\n",
    "\n",
    "Snapshots corresponding to the interaction can be persistently saved, and when needed in the future, the execution can be resumed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "301c3e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- - - - - - Received message - - - - - -\n",
      "Hello, how are you?\n",
      "- - - - - - End - - - - - -\n",
      "\n",
      "- - - - - - Reply Message - - - - - -\n",
      "Hello! I'm functioning well, thank you for asking. I'm always excited to chat and help out! 😊 How can I assist you today?\n",
      "- - - - - - End - - - - - -\n",
      "\n",
      "! ! ! State has been saved and can be resumed later. ! ! !\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "import os\n",
    "\n",
    "# Use a temporary directory to achieve the purpose of persistent storage.\n",
    "temp_dir = tempfile.TemporaryDirectory()\n",
    "\n",
    "# Use a dictionary to record the interaction id and the corresponding snapshot path.\n",
    "cache_dict = {}\n",
    "\n",
    "# deal with delayed interaction\n",
    "message_assistant = MessageAssistant()\n",
    "try:\n",
    "    await message_assistant.arun(message=\"Hello, how are you?\")\n",
    "except InteractionException as e:\n",
    "    interaction_id = e.interactions[0].interaction_id\n",
    "    bytes_file = os.path.join(temp_dir.name, f\"message_assistant_{interaction_id}.bytes\")\n",
    "    version_file = os.path.join(temp_dir.name, f\"message_assistant_{interaction_id}.version\")\n",
    "    with open(bytes_file, \"wb\") as f:\n",
    "        f.write(e.snapshot.serialized_bytes)\n",
    "    with open(version_file, \"w\") as f:\n",
    "        f.write(e.snapshot.serialization_version)\n",
    "\n",
    "    cache_dict[\"A\"] = {\n",
    "        \"interaction_id\": interaction_id,\n",
    "        \"bytes_file\": bytes_file,\n",
    "        \"version_file\": version_file\n",
    "    }\n",
    "    print(f\"! ! ! State has been saved and can be resumed later. ! ! !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589db18c",
   "metadata": {},
   "source": [
    "Suppose after quite a long time, there was finally a reply."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf642f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- - - - - - Reply Message - - - - - -\n",
      "Hello! I'm functioning well, thank you for asking. I'm always excited to chat and help out! 😊 How can I assist you today?\n",
      "- - - - - - End - - - - - -\n",
      "\n",
      "- - - - - - Received message - - - - - -\n",
      "I really enjoy taking with you. Bye!\n",
      "- - - - - - End - - - - - -\n",
      "\n",
      "- - - - - - Reply Message - - - - - -\n",
      "Thank you for enjoying our conversation! I'm glad I could help. Have a wonderful day, and take care! 😊✨\n",
      "- - - - - - End - - - - - -\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# build feedback\n",
    "user = \"A\"\n",
    "reply_message = \"I really enjoy talking with you. Bye!\"\n",
    "interaction_id = cache_dict[user][\"interaction_id\"]\n",
    "feedback = InteractionFeedback(\n",
    "    interaction_id=interaction_id,\n",
    "    data=reply_message\n",
    ")\n",
    "\n",
    "# load snapshot\n",
    "bytes_file = cache_dict[user][\"bytes_file\"]\n",
    "version_file = cache_dict[user][\"version_file\"]\n",
    "with open(bytes_file, \"rb\") as f:\n",
    "    serialized_bytes = f.read()\n",
    "with open(version_file, \"r\") as f:\n",
    "    serialization_version = f.read()\n",
    "snapshot = Snapshot(\n",
    "    serialized_bytes=serialized_bytes, \n",
    "    serialization_version=serialization_version\n",
    ")\n",
    "\n",
    "# automa resumes from the snapshot\n",
    "message_assistant = MessageAssistant.load_from_snapshot(snapshot)\n",
    "await message_assistant.arun(interaction_feedback=feedback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4716b28",
   "metadata": {},
   "source": [
    "When facing a situation that requires feedback but the waiting time is uncertain, this mechanism saves the current state and re-enters when the right moment comes in the future. This not only enables the system to release resources that have been occupied for a long time, but also allows it to be awakened at an appropriate time.\n",
    "\n",
    "## What have we done\n",
    "\n",
    "No matter which form of human-in-the-loop it is, Bridgic provides flexible support.\n",
    "\n",
    "- [`request_feedback_async`](../../../../reference/bridgic-core/bridgic/core/automa/#bridgic.core.automa.Automa.request_feedback_async): Use when the event must return feedback before the program can proceed. The program blocks until feedback is received.\n",
    "- [`post_event`](../../../../reference/bridgic-core/bridgic/core/automa/#bridgic.core.automa.Automa.post_event): Use when you just want to notify or trigger an event without expecting any feedback. The main program continues immediately.\n",
    "- [`interact_with_human`](../../../../reference/bridgic-core/bridgic/core/automa/#bridgic.core.automa.Automa.interact_with_human): Use when feedback is required but may arrive much later. The program is suspended and saved, and resumes only when feedback becomes available."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1be3a0a",
   "metadata": {},
   "source": [
    "# Result Dispatch\n",
    "\n",
    "Result Dispatch is a mechanism for distributing data to multiple workers. Let's understand these features with a practical example.\n",
    "\n",
    "## Parallel Processing Example\n",
    "\n",
    "Suppose we need to process multiple user queries in parallel. Each query needs to go through preprocessing, analysis, and then be aggregated. We can use Result Dispatch to efficiently handle this scenario.\n",
    "\n",
    "### 1. Initialize\n",
    "\n",
    "Let's start by importing the necessary packages.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bff1b6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "from bridgic.core.automa import GraphAutoma, worker\n",
    "from bridgic.core.automa.args import Distribute, ResultDispatchRule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b287bbf",
   "metadata": {},
   "source": [
    "### 2. Input Dispatching\n",
    "\n",
    "First, let's understand how to use `Distribute` when calling `arun()`. When you have multiple start workers and want to distribute different input values to each of them, you can wrap the input data in `Distribute()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86131bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParallelProcessing(GraphAutoma):\n",
    "    @worker(is_start=True)\n",
    "    async def process_query_1(self, user_input: int) -> int:\n",
    "        print(f\"Processing query 1 with input: {user_input}\")\n",
    "        return user_input * 2  # 2\n",
    "    \n",
    "    @worker(is_start=True)\n",
    "    async def process_query_2(self, user_input: int) -> int:\n",
    "        print(f\"Processing query 2 with input: {user_input}\")\n",
    "        return user_input * 3  # 6\n",
    "    \n",
    "    @worker(dependencies=[\"process_query_1\", \"process_query_2\"], is_output=True)\n",
    "    async def aggregate_results(self, result1: int, result2: int) -> int:\n",
    "        print(f\"Aggregating: {result1} + {result2}\")\n",
    "        return result1 + result2  # 8\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa967e3",
   "metadata": {},
   "source": [
    "Now let's run it with `Distribute` to distribute different values to the two start workers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268a7751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing query 1 with input: 1\n",
      "Processing query 2 with input: 2\n",
      "Aggregating: 2 + 6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "automa = ParallelProcessing()\n",
    "await automa.arun(user_input=Distribute([1, 2]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7397a84c",
   "metadata": {},
   "source": [
    "Great! As you can see, `Distribute([1, 2])` distributed the values `1` and `2` to `process_query_1` and `process_query_2` respectively, based on the order of the declaration of start workers.\n",
    "\n",
    "> **Note**: The length of the list/tuple in `Distribute()` must match the number of start workers that accept the corresponding parameter. Otherwise, an error will be raised.\n",
    "\n",
    "<div style=\"text-align: center; margin: 2rem 0;\">\n",
    "<hr style=\"border: none; border-top: 2px solid #e2e8f0;\">\n",
    "</div>\n",
    "\n",
    "### 3. Result Dispatching\n",
    "\n",
    "Now let's understand how to use `result_dispatch_rule=ResultDispatchRule.DISTRIBUTE` to distribute a worker's output to multiple downstream workers.\n",
    "\n",
    "When a worker sets `result_dispatch_rule=ResultDispatchRule.DISTRIBUTE`, its return value must be an iterable (tuple or list). Each element in the return value will be distributed to the downstream workers that directly depend on this worker, in the order they are declared or added.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16f93bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResultDispatchingExample(GraphAutoma):\n",
    "    @worker(is_start=True, result_dispatch_rule=ResultDispatchRule.AS_IS)\n",
    "    async def generate_data(self, user_input: int) -> int:\n",
    "        return user_input\n",
    "    \n",
    "    @worker(dependencies=[\"generate_data\"], result_dispatch_rule=ResultDispatchRule.DISTRIBUTE)\n",
    "    async def process_and_split(self, data: int) -> Tuple[int, int]:\n",
    "        print(f\"Processing data: {data}\")\n",
    "        # Return a tuple that will be distributed to downstream workers\n",
    "        return data + 1, data + 2  # (2, 3)\n",
    "    \n",
    "    @worker(dependencies=[\"process_and_split\"])\n",
    "    async def worker_a(self, value: int) -> int:\n",
    "        print(f\"Worker A received: {value}\")\n",
    "        return value * 10  # 20\n",
    "    \n",
    "    @worker(dependencies=[\"process_and_split\"])\n",
    "    async def worker_b(self, value: int) -> int:\n",
    "        print(f\"Worker B received: {value}\")\n",
    "        return value * 20  # 60\n",
    "    \n",
    "    @worker(dependencies=[\"worker_a\", \"worker_b\"], is_output=True)\n",
    "    async def combine_results(self, result_a: int, result_b: int) -> int:\n",
    "        print(f\"Combining: {result_a} + {result_b}\")\n",
    "        return result_a + result_b  # 80\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9a63e6",
   "metadata": {},
   "source": [
    "Wait, there's an issue with the above code. When `process_and_split` returns `(2, 3)`, we want to distribute these values to `worker_a` and `worker_b`. The `result_dispatch_rule` be set on the worker that **produces** the results to be distributed, not on the workers that **receive** them.\n",
    "\n",
    "Now let's run it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac003374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data: 1\n",
      "Worker A received: 2\n",
      "Worker B received: 3\n",
      "Combining: 20 + 60\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "automa = ResultDispatchingExample()\n",
    "await automa.arun(user_input=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876545ed",
   "metadata": {},
   "source": [
    "Perfect! As you can see:\n",
    "\n",
    "1. `process_and_split` returned `(2, 3)` and had `result_dispatch_rule=ResultDispatchRule.DISTRIBUTE`\n",
    "2. The first value `2` was distributed to `worker_a` (the first downstream worker)\n",
    "3. The second value `3` was distributed to `worker_b` (the second downstream worker)\n",
    "4. Both workers processed their values and the results were combined\n",
    "\n",
    "> **Important Notes**:\n",
    "> - The worker that sets `result_dispatch_rule=ResultDispatchRule.DISTRIBUTE` must return an iterable (tuple or list)\n",
    "> - The length of the return value must match the number of downstream workers that directly depend on this worker\n",
    "> - The distribution order follows the order in which the downstream workers are declared in the graph\n",
    "\n",
    "There are two mode of `ResultDispatchRule`:\n",
    "- **AS_IS**: The result of the worker will be sent as a whole to each downstream worker that depends on it. At the same time, this is the default behavior.\n",
    "- **Distribute**: The workers will distribute the current results in sequence to the corresponding workers one by one according to the order in which the downstream workers are declared or added."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa1bf4c",
   "metadata": {},
   "source": [
    "## What have we leant?\n",
    "\n",
    "Result Dispatch provides powerful mechanisms for parallel data processing:\n",
    "\n",
    "- **`Distribute` in `arun()`**: Distributes input values to multiple start workers element-wise\n",
    "- **`ResultDispatchRule`**: Allows a worker to distribute its output (must be iterable) to multiple downstream workers\n",
    "    - **AS_IS**: Default mode to send the result of current worker as a whole\n",
    "    - **Distribute**: Set to send the result of current worker according to the order in which the downstream workers are declared or added\n",
    "\n",
    "These features enable efficient parallel processing and data flow management in complex workflows."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0812860a",
   "metadata": {},
   "source": [
    "# Quick Start\n",
    "\n",
    "In this tutorial, we assume that Bridgic is already installed on your system. If thatâ€™s not the case, see [Installation](../../../installation).\n",
    "\n",
    "Let's create a simple word learning assistant as an example. You'll provide a word, and the assistant will generate its derivational forms and use them in sentences. Through this example, we'll also learn how to use Bridgic in practice.\n",
    "\n",
    "## Word learning assistant\n",
    "\n",
    "### 1. Model Initialization\n",
    "\n",
    "Before getting started, let's set up our environment. In this quick start, we'll use the integration out of the box.\n",
    "For an in-depth explanation of model integration, see: [LLM Integration](../../model_integration/llm_integration/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7468d809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the environment variables.\n",
    "import os\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "# Import the necessary packages.\n",
    "from bridgic.core.automa import GraphAutoma, worker\n",
    "from bridgic.core.model.types import Message, Role\n",
    "\n",
    "# Here we use OpenAILikeLlm because the package `bridgic-llms-openai-like` is installed automatically \n",
    "# when you install Bridgic. This makes sure the OpenAI-like model integration works out of the box.\n",
    "from bridgic.llms.openai_like.openai_like_llm import OpenAILikeLlm, OpenAILikeConfiguration\n",
    "\n",
    "\n",
    "# In this tutorial, we use OpenAI as an example. \n",
    "# You can freely replace these model settings to use any LLM provider you like.\n",
    "_api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "_api_base = os.environ.get(\"OPENAI_API_BASE\")\n",
    "_model_name = os.environ.get(\"OPENAI_MODEL_NAME\")\n",
    "\n",
    "llm = OpenAILikeLlm(\n",
    "    api_key=_api_key,\n",
    "    api_base=_api_base,\n",
    "    configuration=OpenAILikeConfiguration(model=_model_name),\n",
    "    timeout=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d70238",
   "metadata": {},
   "source": [
    "### 2. Automa Orchestration\n",
    "\n",
    "There are two steps to complete the word learning assistant:\n",
    "\n",
    "1. Generate derivatives of the input word.\n",
    "2. Make sentences with derivatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da260e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordLearningAssistant(GraphAutoma):\n",
    "    @worker(is_start=True)\n",
    "    async def generate_derivatives(self, word: str):\n",
    "        print(f\"------Generating derivatives for {word}------\")\n",
    "        response = await llm.achat(\n",
    "            model=_model_name,\n",
    "            messages=[\n",
    "                Message.from_text(text=\"You are a word learning assistant. Generate derivatives of the input word in a list.\", role=Role.SYSTEM),\n",
    "                Message.from_text(text=word, role=Role.USER),\n",
    "            ]\n",
    "        )\n",
    "        print(response.message.content)\n",
    "        print(f\"------End of generating derivatives------\\n\")\n",
    "        return response.message.content\n",
    "\n",
    "    @worker(dependencies=[\"generate_derivatives\"], is_output=True)\n",
    "    async def make_sentences(self, derivatives):\n",
    "        print(f\"------Making sentences with------\")\n",
    "        response = await llm.achat(\n",
    "            model=_model_name,\n",
    "            messages=[\n",
    "                Message.from_text(text=\"You are a word learning assistant. Make sentences with the input derivatives in a list.\", role=Role.SYSTEM),\n",
    "                Message.from_text(text=derivatives, role=Role.USER),\n",
    "            ]\n",
    "        )\n",
    "        print(response.message.content)\n",
    "        print(f\"------End of making sentences------\\n\")\n",
    "        return response.message.content\n",
    "\n",
    "word_learning_assistant = WordLearningAssistant()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81cf951d",
   "metadata": {},
   "source": [
    "### 3. Agent Running\n",
    "\n",
    "Let's run this assistant, via [`arun`](../../../../reference/bridgic-core/bridgic/core/automa/#bridgic.core.automa.GraphAutoma.arun) method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a6fbb8d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Generating derivatives for happy------\n",
      "Here are some derivatives of the word \"happy\":\n",
      "\n",
      "1. Happiness\n",
      "2. Happily\n",
      "3. Happier\n",
      "4. Happiest\n",
      "5. Unhappy\n",
      "6. Unhappiness\n",
      "7. Happinesses (plural form)\n",
      "8. Happifying (gerund form)\n",
      "9. Happify (verb form)\n",
      "\n",
      "Feel free to ask for derivatives of another word!\n",
      "------End of generating derivatives------\n",
      "\n",
      "------Making sentences with------\n",
      "Sure! Here are sentences using each of the derivatives of the word \"happy\":\n",
      "\n",
      "1. **Happiness**: The pursuit of happiness is a common goal for many people.\n",
      "2. **Happily**: She smiled happily as she opened her birthday gifts.\n",
      "3. **Happier**: After taking a vacation, I felt much happier than I had in months.\n",
      "4. **Happiest**: That day was the happiest moment of my life when my daughter graduated.\n",
      "5. **Unhappy**: He seemed unhappy at the party and left early.\n",
      "6. **Unhappiness**: Her unhappiness was evident in her quiet demeanor.\n",
      "7. **Happinesses**: Different people find happinesses in various aspects of life, like family, work, and hobbies.\n",
      "8. **Happifying**: The act of volunteering can be a happifying experience for both the giver and the receiver.\n",
      "9. **Happify**: Listening to uplifting music can help to happify your day.\n",
      "\n",
      "Let me know if you need sentences for another word!\n",
      "------End of making sentences------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = await word_learning_assistant.arun(word=\"happy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a176cd0c",
   "metadata": {},
   "source": [
    "> Note: Ensure you have set up your .env file to store your OPENAI_API_KEY or set up your terminal environment variable. This key is necessary for authenticating requests to the OpenAI API.\n",
    "\n",
    "Great! We have successfully completed the word learning assistant. It correctly completed the task as per our requirements.\n",
    "\n",
    "<div style=\"text-align: center; margin: 2rem 0;\">\n",
    "<hr style=\"border: none; border-top: 2px solid #e2e8f0;\">\n",
    "</div>\n",
    "\n",
    "## What have we done?\n",
    "\n",
    "The above example is the typical usage of writing an agent application with Bridgic. Now let's understand some of its components.\n",
    "\n",
    "### Worker\n",
    "\n",
    "Any callable object (such as functions, methods, etc.) when used by the framework, will be converted into a worker object and serve as the **basic execution unit** for scheduling and orchestration. \n",
    "\n",
    "Just as in the example of the word learning assistant, we can use decorator syntax to wrap functions and methods into a worker object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d507c1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyAutoma(GraphAutoma):\n",
    "    @worker(is_start=True)\n",
    "    async def start(self, x: int):\n",
    "        return x    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ed3b6b",
   "metadata": {},
   "source": [
    "Or, you can also use it like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614c5d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyAutoma(GraphAutoma): ...\n",
    "my_automa = MyAutoma()\n",
    "\n",
    "# Add the function as a worker with worker decorator in the instance of the automa\n",
    "@my_automa.worker(is_start=True)\n",
    "async def start(x: int):\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fa90f6",
   "metadata": {},
   "source": [
    "Another one, the interface [`add_func_as_worker()`](../../../../reference/bridgic-core/bridgic/core/automa/#bridgic.core.automa.GraphAutoma.add_func_as_worker) can also be used to add workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24aa7fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def start(x: int):\n",
    "    return x\n",
    "\n",
    "class MyAutoma(GraphAutoma): ...\n",
    "my_automa = MyAutoma()\n",
    "\n",
    "# Add the function as a worker\n",
    "my_automa.add_func_as_worker(\n",
    "    key=\"start\",\n",
    "    func=start,\n",
    "    is_start=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179b434b",
   "metadata": {},
   "source": [
    "In addition to functions being convertible to workers, classes that inherit from [`Worker`](../../../../reference/bridgic-core/bridgic/core/automa/worker/#bridgic.core.automa.worker.Worker) and override either [`run()`](../../../../reference/bridgic-core/bridgic/core/automa/worker/#bridgic.core.automa.worker.Worker.run) or [`arun()`](../../../../reference/bridgic-core/bridgic/core/automa/worker/#bridgic.core.automa.worker.Worker.arun) can also be used directly as workers by [`add_worker()`](../../../../reference/bridgic-core/bridgic/core/automa/#bridgic.core.automa.GraphAutoma.add_worker) interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940f833b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bridgic.core.automa.worker import Worker\n",
    "\n",
    "class MyWorker(Worker):\n",
    "    async def arun(self, x: int):\n",
    "        return x\n",
    "\n",
    "my_worker = MyWorker()\n",
    "\n",
    "# Add the worker to the automa\n",
    "class MyAutoma(GraphAutoma): ...\n",
    "my_automa = MyAutoma()\n",
    "my_automa.add_worker(\n",
    "    key=\"my_worker\",\n",
    "    worker=my_worker,\n",
    "    is_start=True,\n",
    ")\n",
    "\n",
    "# Run the worker\n",
    "res = await my_automa.arun(x=1)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5107c75",
   "metadata": {},
   "source": [
    "> Note:\n",
    "> 1. A specific worker that inherits from `Worker` must override either the `run()` or `arun()` method.\n",
    "> 2. Bridgic is a framework primarily designed for asynchronous execution, if both `run()` and `arun()` of a worker are overridden, `arun()` will take precedence.\n",
    "\n",
    "Both of these ways can correctly add the workers to `MyAutoma`. \n",
    "\n",
    "Whether using decorator syntax or the corresponding interface, there are usually some parameters:\n",
    "\n",
    "1. `key`: A string. As the unique identifier of a worker in the current automa, it must be ensured that there are no duplicate names within the same automa. Use function names or class names by default.\n",
    "2. `func`(in [`add_func_as_worker()`](../../../../reference/bridgic-core/bridgic/core/automa/#bridgic.core.automa.GraphAutoma.add_func_as_worker)) or `worker`(in [`add_worker()`](../../../../reference/bridgic-core/bridgic/core/automa/#bridgic.core.automa.GraphAutoma.add_worker)): The actual callable object. **The decorator syntax does not have this parameter.**\n",
    "3. `is_start`: `True` or `False`. Marking the worker as the start for automa. It can be set in multiple workers.\n",
    "4. `dependencies`: A list of string. Mark the preceding workers that the worker depends on.\n",
    "5. `is_output`: `True` or `False`. Marking the worker as the output for automa. There can only be one on an execution branch.\n",
    "6. `args_mapping_rule`: Parameter passing rule. For detailed information on behavior classes, please refer to the tutorial: [Parameter Binding](../../core_mechanism/parameter_binding/)\n",
    "\n",
    "> Note: From the perspective of the Bridgic, a worker must be placed in an automa for scheduling before it can be executed. Of course, even after packaging it as a worker, you can directly call `worker.arun()` or `worker.run()` to run it, but this is not within the purview of Bridgic.\n",
    "\n",
    "### GraphAutoma\n",
    "\n",
    "Automa serves as the **scheduling engine**. In the example of the word learning assistant above, we used the [`GraphAutoma`](../../../../reference/bridgic-core/bridgic/core/automa/#bridgic.core.automa.GraphAutoma), which represents the scheduling according to the topological sorting among workers.\n",
    "\n",
    "You can use `GraphAutoma` by writing a class that inherits from it and writing or adding workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b78c10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write workers in MyAutoma\n",
    "class MyAutoma(GraphAutoma):\n",
    "    @worker(is_start=True)\n",
    "    async def worker_0(self, a, b, x, y):\n",
    "        print(f\"worker_0: a={a}, b={b}, x={x}, y={y}\")\n",
    "\n",
    "    @worker(is_start=True)\n",
    "    async def worker_1(self, x, y):\n",
    "        print(f\"worker_1: x={x}, y={y}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448fab9c",
   "metadata": {},
   "source": [
    "After an automa has the required workers, it can call `await automa_obj.arun(*args, **kwargs)` to start the entire scheduling operation. \n",
    "\n",
    "> Bridgic is an asynchronous framework, `Graphautoma` must be started using arun().\n",
    "\n",
    "At startup, the parameters of `automa_obj.arun(*args, **kwargs)` will be distributed to the worker with `is_start=True` according to positional parameters and keyword parameters. \n",
    "\n",
    "- positional parameters: The positional parameters will be filled into the parameter list of the worker with `is_start=True` in the order of input. An error will be raised if the parameter list of some worker is shorter than the number of positional parameters of `arun()`.\n",
    "- keyword parameters: The keyword parameter will be filled into the corresponding parameter of the corresponding worker with `is_start=True`.\n",
    "- priority: **Positional parameters have a higher priority than keyword parameters**.\n",
    "\n",
    "For example: we pass positional arguments `1` and `2`, and keyword arguments `x=3`, `y=4`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bc5041c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "worker_0: a=1, b=2, x=3, y=4\n",
      "worker_1: x=1, y=2\n"
     ]
    }
   ],
   "source": [
    "my_automa = MyAutoma()\n",
    "await my_automa.arun(1, 2, x=3, y=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9afd803",
   "metadata": {},
   "source": [
    "`1` and `2` were received in sequence by the first and second parameters of `worker_0` and `worker_1` respectively. Because positional parameters have a higher priority than keyword parameters, even if the parameter names of `worker_1` are the same as the input keyword parameters, they will still preferentially receive positional parameters.\n",
    "\n",
    "An error will be raised if the parameter list of some worker is shorter than the number of positional parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f188d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_automa = MyAutoma()\n",
    "await my_automa.arun(1, 2, 3, y=4)  # worker_1 raises an error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753eaf90",
   "metadata": {},
   "source": [
    "If all parameters are input in the keyword parameters, each worker with `is_start=True` can receive the corresponding parameter value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "331382da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "worker_0: a=1, b=2, x=3, y=4\n",
      "worker_1: x=3, y=4\n"
     ]
    }
   ],
   "source": [
    "my_automa = MyAutoma()\n",
    "await my_automa.arun(a=1, b=2, x=3, y=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023e1ed0",
   "metadata": {},
   "source": [
    "Now, we can start building our Bridgic project!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_bridgic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.24"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

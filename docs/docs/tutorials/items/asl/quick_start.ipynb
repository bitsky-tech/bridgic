{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "659d56ac",
   "metadata": {},
   "source": [
    "# Quick Start \n",
    "\n",
    "Welcome to the **ASL(Agent Stucture Language)** — A DSL(Domain Specific Language) about how to building an agent — documentation! This page will give you an introduction to 80% of the ASL usage that you will use on a daily basis.\n",
    "\n",
    "## Overview\n",
    "\n",
    "ASL is a declarative language for agent construction. After all basic functions are modularly implemented, ASL pursue a what-you-see-is-what-you-get approach for the internal processes of the agent. We can clearly see the orchestration process and hierarchical structure at a glance.\n",
    "\n",
    "In this document, You will learn:\n",
    "1. How to build an agent by ASL.\n",
    "2. How to reuse the exit agents in a componentized parttern.\n",
    "3. How to build an agent with nested structure.\n",
    "4. How to reuse fregment of a control flow.\n",
    "5. How to control data transmission in the agent\n",
    "6. How to achieve dynamic topology during the agent's runtime.\n",
    "\n",
    "## Build an Agent by ASL\n",
    "\n",
    "Take the simplest text generation process as an example. When a user inputs a query, we break it down, and then generate text for every sub-query.\n",
    "\n",
    "Let's first prepare necessary environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee829ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the environment variables.\n",
    "import os\n",
    "\n",
    "_api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "_api_base = os.environ.get(\"OPENAI_API_BASE\")\n",
    "_model_name = os.environ.get(\"OPENAI_MODEL_NAME\")\n",
    "\n",
    "# Import the necessary packages.\n",
    "from typing import List, Dict\n",
    "from bridgic.core.model.types import Message, Role\n",
    "from bridgic.core.agentic.asl import ASLAutoma, graph\n",
    "from bridgic.llms.openai import OpenAILlm, OpenAIConfiguration\n",
    "\n",
    "llm = OpenAILlm(  # the llm instance\n",
    "    api_base=_api_base,\n",
    "    api_key=_api_key,\n",
    "    timeout=5,\n",
    "    configuration=OpenAIConfiguration(model=_model_name),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c69b76",
   "metadata": {},
   "source": [
    "Secondly, modularly implement the functional functions needed in this process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "138ae30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Break down the query into a list of sub-queries.\n",
    "async def break_down_query(user_input: str) -> List[str]:\n",
    "    llm_response = await llm.achat(\n",
    "        messages=[\n",
    "            Message.from_text(text=f\"Break down the query into multiple sub-queries and only return the sub-queries\", role=Role.SYSTEM),\n",
    "            Message.from_text(text=user_input, role=Role.USER,),\n",
    "        ]\n",
    "    )\n",
    "    return [item.strip() for item in llm_response.message.content.split(\"\\n\") if item.strip()]\n",
    "\n",
    "# Define the function to conduct a web search.\n",
    "async def query_answer(queries: List[str]) -> Dict[str, str]:\n",
    "    answers = []\n",
    "    for query in queries:\n",
    "        response = await llm.achat(\n",
    "            messages=[\n",
    "                Message.from_text(text=f\"Answer the given query briefly\", role=Role.SYSTEM),\n",
    "                Message.from_text(text=query, role=Role.USER,),\n",
    "            ]\n",
    "        )\n",
    "        answers.append(response.message.content)\n",
    "    \n",
    "    res = {\n",
    "        query: answer\n",
    "        for query, answer in zip(queries, answers)\n",
    "    }\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13191627",
   "metadata": {},
   "source": [
    "Now, Let's complete this process using ASL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a1e45f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SplitSolveAgent(ASLAutoma):\n",
    "    with graph as g:\n",
    "        a = break_down_query\n",
    "        b = query_answer\n",
    "\n",
    "        +a >> ~b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d9c0aa",
   "metadata": {},
   "source": [
    "The implementation process of `SplitSolveAgent` was accomplished through orchestration using ASL grammar. In this grammar:\n",
    "- `with graph as g`: Represents opening a graph, and we can **declare the nodes** and **defining the dependency** between the nodes under its syntax block.\n",
    "- `a = break_down_query`: Represents declaring a node names `a`.\n",
    "- `a >> b`: Represents defining the dependency of `b` is `a`, which means the `b` will execute after `a`.\n",
    "- `+a`: Represents defining `a` is the start.\n",
    "- `~b`: Represents defining `b` is the output.\n",
    "\n",
    "Now, Let's run it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875f62a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1. When was Einstein born?': 'Albert Einstein was born in 1879.',\n",
       " '2. Where was Einstein born?': 'Albert Einstein was born in Ulm, Kingdom of Württemberg, German Empire.'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_generation_agent = SplitSolveAgent()\n",
    "await text_generation_agent.arun(\"When and where was the Einstein born?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7a2a26",
   "metadata": {},
   "source": [
    "Great! We successfully obtained the result. In the ASL code, we can see very intuitively that the `SplitSolveAgent` has only two nodes, and `b` depends on `a`, with no other redundant information. ASL elevates node declarations and dependency management in an execution flow to first-class language constructs.\n",
    "\n",
    "## Reuse the Exit Agents in Componentized Parttern\n",
    "\n",
    "In the above process, we have completed the agent that splits the query and answers them separately. It is a pre-designed module. Now, I want to design a chatbot that merge these individual answers to generate a unified response to the original question. Like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b210101a",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def merge_answers(qa_pairs: Dict[str, str], user_input: str) -> str:\n",
    "    answers = \"\\n\".join([v for v in qa_pairs.values()])\n",
    "    llm_response = await llm.achat(\n",
    "        messages=[\n",
    "            Message.from_text(text=f\"Merge the given answers into a unified response to the original question\", role=Role.SYSTEM),\n",
    "            Message.from_text(text=f\"Query: {user_input}\\nAnswers: {answers}\", role=Role.USER,),\n",
    "        ]\n",
    "    )\n",
    "    return llm_response.message.content\n",
    "\n",
    "# Define the Chatbot agent, use SplitSolveAgent in componentized parttern.\n",
    "class Chatbot(ASLAutoma):\n",
    "    with graph as g:\n",
    "        a = SplitSolveAgent()\n",
    "        b = merge_answers\n",
    "\n",
    "        +a >> ~b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6cf2e2e",
   "metadata": {},
   "source": [
    "Let's run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f2eefe69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Albert Einstein was born in 1879 in Ulm, Kingdom of Württemberg, German Empire.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot = Chatbot()\n",
    "await chatbot.arun(user_input=\"When and where was the Einstein born?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd150101",
   "metadata": {},
   "source": [
    "Great! Our chatbot successfully answered our questions. During its implementation, we directly declared `SplitSolveAgent` within the `with graph` statement block. We did not write a function to encapsulate it, nor did we use any form of API to manually add it to the graph. Everything was naturally declared and completed.\n",
    "\n",
    "## Build an Agent with Nested Structure or Arranging Fregment\n",
    "\n",
    "When we have all the functional function ready, but we don't `SplitSolveAgent`, we don't have to implement it specifically to reuse it. Instead, we can write everything in one agent directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dead7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatbotNested(ASLAutoma):\n",
    "    with graph as g:  #  the chatbot agent to define its graph\n",
    "        with graph as split_solve:  #  the split_solve agent to define its graph\n",
    "            a = break_down_query\n",
    "            b = query_answer    \n",
    "            +a >> ~b\n",
    "        end = merge_answers\n",
    "        \n",
    "        +split_solve >> ~end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5370b5fc",
   "metadata": {},
   "source": [
    "Let's run it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e29285da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Albert Einstein was born in 1879 in Ulm, Kingdom of Württemberg, German Empire.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot_nested = ChatbotNested()\n",
    "await chatbot_nested.arun(user_input=\"When and where was the Einstein born?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8db8e3",
   "metadata": {},
   "source": [
    "We successfully achieved the expected result. We can clearly see that there are two layers of graphs in `ChatbotNested` and what the arrangement structure of each graph is. \n",
    "\n",
    "Of course, the arrangement in one graph cannot use the nodes from another graph. In the above example, for graph `g`, nodes `a` and `b` are invisible, and it can only use `split_solve` as a whole to arrange beneath it. Similarly, for `split_solve`, it cannot see the nodes within other graphs either.\n",
    "\n",
    "> Note: If a node that is unknown to the graph is referenced in it, an exception will be thrown.\n",
    "\n",
    "These are the basic usages of ASL. Next, we will introduce other common usages of ASL.\n",
    "\n",
    "## Reuse fregment of a Control Flow.\n",
    "\n",
    "In a task arrangement, a certain part of the process might be universal, such as `a >> b >> c` and `a >> b >> d`. Here, `a >> b` is actually a common process in this agent arrangement, and we can name it separately for reuse.\n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ffcdf1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def add1(x: int) -> int:\n",
    "    return x + 1\n",
    "\n",
    "async def add2(x: int) -> int:\n",
    "    return x + 2\n",
    "\n",
    "async def multiply(x: int) -> int:\n",
    "    return x * 2\n",
    "\n",
    "async def division(x: int) -> int:\n",
    "    return x / 2\n",
    "\n",
    "async def merge_result(x: int, y: int) -> int:\n",
    "    return x + y\n",
    "\n",
    "class MyAutoma(ASLAutoma):\n",
    "    with graph as g:\n",
    "        a = add1\n",
    "        b = add2\n",
    "        add_process = +a >> b\n",
    "\n",
    "        c = multiply\n",
    "        d = division\n",
    "        add_multiply = add_process >> c\n",
    "        add_division = add_process >> d\n",
    "\n",
    "        merge = merge_result\n",
    "        (add_multiply & add_division) >> ~merge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec1368a",
   "metadata": {},
   "source": [
    "In this example, we have two logical sequences: one involves performing two additions first and then a multiplication, and the other involves performing two additions first and then a division. We can name the same addition operation twice as `add_process`, and then use it to complete two different logical sections respectively, without having to write `a >> b` every time. And later on, we also gave each of the two logical fregments their own names, and ultimately arranged our logic.\n",
    "\n",
    "<br>\n",
    "<div style=\"text-align: center;\">\n",
    "<img src=\"../../../imgs/flow_fregment.png\" alt=\"Parameter Passing\" width=\"800\" height=\"600\">\n",
    "</div>\n",
    "<br>\n",
    "\n",
    "In the grammar:\n",
    "- `add_process = a >> b`: Represents that the variable `add_process` is `a >> b` to be reuse.\n",
    "- `(add_multiply & add_division)`: Represents that the expressions for arranging control flow have associative laws. It indicates that `add_multiply` and `add_division` are arranged as a whole."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f16abaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_automa = MyAutoma()\n",
    "await my_automa.arun(x=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eafa9b2",
   "metadata": {},
   "source": [
    "## Control Data Transmission in the Agent\n",
    "\n",
    "When executing an ASL code, the program first \"translates\" it into the corresponding objects in Bridgic. For instance, a node declared in ASL is actually a [`Worker`](../../../reference/bridgic-core/bridgic/core/automa/worker/index.md) during execution. Therefore, ASL also possesses all the underlying capabilities of Bridgic.\n",
    "\n",
    "Bridgic offers a variety of rich [parameter binding mechanisms](../core_mechanism/parameter_binding.ipynb). In ASL, we can utilize them by setting the `Settings` and `Data` attributes of a node.\n",
    "\n",
    "For example, the following code："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6736cbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bridgic.core.automa.args import ArgsMappingRule\n",
    "from bridgic.core.agentic.asl import Settings\n",
    "\n",
    "\n",
    "async def start1(user_input: int) -> int:\n",
    "    return user_input + 1\n",
    "\n",
    "async def start2(user_input: int) -> int:\n",
    "    return user_input + 2\n",
    "\n",
    "async def worker1(x: List[int], user_input: int) -> int:\n",
    "    return sum(x) + user_input\n",
    "\n",
    "\n",
    "class MyAutoma(ASLAutoma):\n",
    "    with graph as g:\n",
    "        a = start1\n",
    "        b = start2\n",
    "        c = worker1 *Settings(args_mapping_rule=ArgsMappingRule.MERGE)\n",
    "\n",
    "        +(a & b) >> ~c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d0cc62",
   "metadata": {},
   "source": [
    "The above code defines such a structure:\n",
    "\n",
    "<br>\n",
    "<div style=\"text-align: center;\">\n",
    "<img src=\"../../../imgs/asl_data_flow.png\" alt=\"Asl Data Flow\" width=\"400\" height=\"300\">\n",
    "</div>\n",
    "<br>\n",
    "\n",
    "In this grammar:\n",
    "- `worker1 *Settings`: Represents that when adding the `worker1` function as an execution unit, some configurations are made for it. The field of `Settings` is the same as [the decorator `@worker` in bridgic](../quick_start/quick_start.ipynb#Worker). Now, `c` will receive result from `a` and `b` in the `ArgsMappingRule.MERGE` form.\n",
    "- `+(a & b)`: Represents that the expressions for arranging control flow have distributive laws. `(a & b)` indicates that `a` and `b` are arranged as a whole. `+(a & b)` indicates `a` and `b` are both start entry point, this equals to `(+a & +b)`.\n",
    "\n",
    "> Note: The `+` and `~` can only be applied to declared nodes. If fregment `sequence = a >> b` is declared and then `+sequence`, this is not equivalent to `+a >> b`. But the `>>` is perfectly acceptable in both node and fregment\n",
    "\n",
    "Let's run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "65de96f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_automa = MyAutoma()\n",
    "await my_automa.arun(user_input=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2024e4",
   "metadata": {},
   "source": [
    "In addition, bridgic also has a arguments injection mechanism, which can also be used in ASL through `Data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c77a3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bridgic.core.automa.args import From\n",
    "from bridgic.core.agentic.asl import Data\n",
    "\n",
    "\n",
    "async def worker1(user_input: int) -> int:\n",
    "    return user_input + 1\n",
    "\n",
    "async def worker2(x: int) -> int:\n",
    "    return x + 2\n",
    "\n",
    "async def worker3(x: int, y: int) -> int:\n",
    "    return x + y\n",
    "\n",
    "\n",
    "class MyAutoma(ASLAutoma):\n",
    "    with graph as g:\n",
    "        a = worker1\n",
    "        b = worker2\n",
    "        c = worker3 *Data(y=From('a'))\n",
    "\n",
    "        +a >> b >> ~c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2937f5",
   "metadata": {},
   "source": [
    "In this grammar:\n",
    "- `*Data(y=From('a'))`: Represents that the arguments injection mechanism of Bridgic was used to declare that the parameter y of `worker3` comes from the result of a of the declared node `a`.\n",
    "\n",
    "> Note: Data declaration arguments injection is equivalent to assigning a default value to a certain parameter of a function, which is dynamically injected at runtime. For example: `c = worker3 *Data(y=From('a'))` is equivalent to `async def worker3(x: int, y: int = From('a'))`. This means that you cannot write `c = worker3 *Data(x=From('a'))`, because it is equivalent to `async def worker3(x: int = From('a'), y: int)`, This violates Python’s rule that parameters with default values cannot precede parameters without default values in a function signature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cab990d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_automa = MyAutoma()\n",
    "await my_automa.arun(user_input=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5efcb89",
   "metadata": {},
   "source": [
    "## Achieve Dynamic Topology during the Agent's Runtime\n",
    "\n",
    "During the runtime of an agent, sometimes we need to dynamically adjust the structure of the graph based on the intermediate running state. ASL also provides the ability to declare such dynamic behaviors.\n",
    "\n",
    "A typical example is that during the execution process, nodes are dynamically created based on the number of results from intermediate tasks to handle the corresponding data.\n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "77d7b483",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bridgic.core.agentic.asl import ASLField, concurrent\n",
    "\n",
    "\n",
    "async def product_task(user_input: int) -> List[int]:\n",
    "    tasks = [i for i in range(user_input)]\n",
    "    return tasks\n",
    "\n",
    "async def task_handler(sub_task: int) -> List[int]:\n",
    "    res = sub_task + 1\n",
    "    return res\n",
    "\n",
    "\n",
    "class DynamicGraph(ASLAutoma):\n",
    "    with graph(user_input=ASLField(type=int)) as g:\n",
    "        productor = product_task\n",
    "\n",
    "        with concurrent(tasks = ASLField(type=list, distribute=True)) as c:\n",
    "            dynamic_handler = lambda tasks: (\n",
    "                task_handler *Settings(key=f\"task_handler_{task}\")\n",
    "                for task in tasks\n",
    "            )\n",
    "\n",
    "        +productor >> ~c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889b30b2",
   "metadata": {},
   "source": [
    "In this example, the node `productor` generates a list based on `user_input`, and each element in this list is the data that each subsequent `task_handler` needs to process. However, before the program starts running and the user actually inputs, we cannot know how many `task_handler` are needed. We can only create them dynamically at runtime.\n",
    "\n",
    "This example uses the `concurrent` container, which represents a graph structure where all internal nodes run concurrently. This means that when it is triggered to execute, all its internal nodes will execute simultaneously.\n",
    "\n",
    "<br>\n",
    "<div style=\"text-align: center;\">\n",
    "<img src=\"../../../imgs/dynamic_topo.png\" alt=\"Parameter Passing\" width=\"400\" height=\"300\">\n",
    "</div>\n",
    "<br>\n",
    "\n",
    "\n",
    "In this grammar:\n",
    "- `with graph(key=ASLField(...), ...)`: When necessary, the input parameters of a graph can be declared. This parameter must use the `ASLField` data structure provided by ASL to declare its type, parameter behavior, etc. In addition, the parameters of this declaration must be consistent with the parameter names used internally. For instance, for the `productor` node corresponding to the `product_task` function, if its parameter declaration is `user_input`, then the corresponding graph parameter should also be `user_input`. Otherwise, a parameter missing error will raise.\n",
    "- `dynamic_handler`: An lambda function in Python. It declares a logic for generating `task_handler` based on `tasks`, and then ASL dynamically generates and executes them at appropriate times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "208eeb5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dynamic_graph = DynamicGraph()\n",
    "await dynamic_graph.arun(user_input=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d319f5a8",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "By now, you know the basics of how to write ASL code!\n",
    "\n",
    "Check out the Tutorial to put them into practice and build your first mini-agent with ASL."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

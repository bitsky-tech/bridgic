{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "659d56ac",
   "metadata": {},
   "source": [
    "# ASL\n",
    "\n",
    "Welcome to **ASL (Agent Structure Language)** â€” an internal DSL(Domain Specific Language) in Python for building agents! This tutorial will walk you through the core concepts and the most commonly used features of ASL.\n",
    "\n",
    "## Overview\n",
    "\n",
    "ASL is a declarative language for agent construction that follows a \"what-you-see-is-what-you-get\" philosophy. Once you've implemented your basic functions, ASL allows you to clearly express and define the orchestration process and hierarchical structure of your agent at a glance.\n",
    "\n",
    "In this tutorial, you will learn:\n",
    "1. How to build your first agent\n",
    "2. How to reuse existing agents in a componentized pattern\n",
    "3. How to build agents with nested graph structures\n",
    "4. How to reuse fragments of control flow\n",
    "5. How to control data transmission between workers\n",
    "6. How to achieve dynamic topology during runtime\n",
    "\n",
    "## Building Your First Agent\n",
    "\n",
    "Let's start with a simple example: a text generation agent that breaks down a user query into sub-queries and generates answers for each one.\n",
    "\n",
    "First, let's set up the necessary environment and imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee829ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the environment variables.\n",
    "import os\n",
    "\n",
    "_api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "_api_base = os.environ.get(\"OPENAI_API_BASE\")\n",
    "_model_name = os.environ.get(\"OPENAI_MODEL_NAME\")\n",
    "\n",
    "# Import the necessary packages.\n",
    "from typing import List, Dict\n",
    "from bridgic.core.model.types import Message, Role\n",
    "from bridgic.asl import ASLAutoma, graph\n",
    "from bridgic.llms.openai import OpenAILlm, OpenAIConfiguration\n",
    "\n",
    "llm = OpenAILlm(  # the llm instance\n",
    "    api_base=_api_base,\n",
    "    api_key=_api_key,\n",
    "    timeout=5,\n",
    "    configuration=OpenAIConfiguration(model=_model_name),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c69b76",
   "metadata": {},
   "source": [
    "Now, let's implement the core functions that will be used in our agent workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "138ae30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Break down the query into a list of sub-queries.\n",
    "async def break_down_query(user_input: str) -> List[str]:\n",
    "    llm_response = await llm.achat(\n",
    "        messages=[\n",
    "            Message.from_text(text=f\"Break down the query into multiple sub-queries and only return the sub-queries\", role=Role.SYSTEM),\n",
    "            Message.from_text(text=user_input, role=Role.USER,),\n",
    "        ]\n",
    "    )\n",
    "    return [item.strip() for item in llm_response.message.content.split(\"\\n\") if item.strip()]\n",
    "\n",
    "# Define the function to conduct a web search.\n",
    "async def query_answer(queries: List[str]) -> Dict[str, str]:\n",
    "    answers = []\n",
    "    for query in queries:\n",
    "        response = await llm.achat(\n",
    "            messages=[\n",
    "                Message.from_text(text=f\"Answer the given query briefly\", role=Role.SYSTEM),\n",
    "                Message.from_text(text=query, role=Role.USER,),\n",
    "            ]\n",
    "        )\n",
    "        answers.append(response.message.content)\n",
    "    \n",
    "    res = {\n",
    "        query: answer\n",
    "        for query, answer in zip(queries, answers)\n",
    "    }\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13191627",
   "metadata": {},
   "source": [
    "Now, let's use ASL to orchestrate this workflow. The core idea of ASL is: **first declare all [workers](../../../home/concepts.md/#worker) under a corresponding [graph](../../../home/concepts.md/#graphautoma), assigning a unique key to both the graph and each worker, and then define the dependencies between them**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a1e45f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SplitSolveAgent(ASLAutoma):\n",
    "    with graph as g:\n",
    "        a = break_down_query\n",
    "        b = query_answer\n",
    "\n",
    "        +a >> ~b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d9c0aa",
   "metadata": {},
   "source": [
    "The `SplitSolveAgent` implementation uses ASL syntax to orchestrate the workflow. Let's break down the core ASL syntax:\n",
    "\n",
    "**Key points:**\n",
    "\n",
    "- **`with graph as g:`** - Opens a graph context. Within this block, you can declare workers and define dependencies between them.\n",
    "- **`a = break_down_query`** - Declares a worker named `a` that corresponds to the `break_down_query` function\n",
    "- **`a >> b`** - Defines a dependency: `b` depends on `a`, meaning `b` will execute only after `a` completes\n",
    "- **`+a`** - Marks `a` as a start worker (entry point of the workflow)\n",
    "- **`~b`** - Marks `b` as an output worker (exit point of the workflow)\n",
    "\n",
    "**Syntax Reference**\n",
    "\n",
    "In the syntax specification below, angle brackets like `<GRAPH>`, `<KEY>`, `<WORKER>`, etc., are **metasyntax variables** (placeholders) that represent entities of specific types. Replace them with actual values when writing your code.\n",
    "\n",
    "| Syntax | Meaning | Example |\n",
    "|--------|---------|---------|\n",
    "| `with <GRAPH> as <KEY>:` | Defines a graph container with a given key.<br><br>**Notes:**<br>`<GRAPH>` can be either `graph` or `concurrent`:<br>1. `graph`: Allows arbitrary orchestration of worker execution order<br>  2. `concurrent`: All workers added to it will execute concurrently<br><br>`<KEY>` is required and must be unique. Without it, the program cannot identify this as an executable graph structure | `with graph as g:` declares a graph named `g`, under which you can start declaring workers and orchestrating the workflow |\n",
    "| `<KEY> = <WORKER>` | Declares and registers a worker with a unique key.<br><br>**Notes:**<br>`<WORKER>` can be one of three types:<br> 1. Python functions (defined with `def` or `async def`)<br>  2. Bridgic `Worker` objects (e.g., `GraphAutoma`, custom `Worker` classes)<br> 3. Another agent implemented using `ASLAutoma`<br><br> `<KEY>` is required and must be unique within the graph scope. Without it, the worker cannot be identified and scheduled<br> All worker declarations must be written inside a `with <GRAPH> as <KEY>:` block, otherwise workers cannot be registered to the correct execution graph | `a = break_down_query` registers `break_down_query` as a worker with key `a` |\n",
    "| `<KEY1> >> <KEY2>` | Defines a dependency: The worker named `<KEY2>` will be triggered after the worker named `<WORKER1>` completes execution | `a >> b` means `b` will execute after `a` finishes |\n",
    "| `+<KEY>` | Marks a worker as a start worker (entry point of the execution graph) | `+a` marks `a` as the starting worker of the execution graph |\n",
    "| `~<KEY>` | Marks a worker as an output worker (exit point of the execution graph) | `~a` marks `a` as an output worker of the execution graph |\n",
    "\n",
    "Now let's run this agent!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "875f62a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1. When was Einstein born?': 'Albert Einstein was born in 1879.',\n",
       " '2. Where was Einstein born?': 'Albert Einstein was born in Ulm, Kingdom of WÃ¼rttemberg, German Empire.'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_generation_agent = SplitSolveAgent()\n",
    "await text_generation_agent.arun(\"When and where was the Einstein born?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7a2a26",
   "metadata": {},
   "source": [
    "Excellent! We successfully obtained the results. From the ASL code, we can clearly see that `SplitSolveAgent` has only two workers, with `b` depending on `a`, and no other redundant information. ASL elevates worker declaration and dependency management to first-class language constructs.\n",
    "\n",
    "## Componentized Agent Reuse\n",
    "\n",
    "In the example above, we created an agent that splits queries and answers them separately. This is a reusable module. Now, let's build a chatbot that merges these individual answers into a unified response. We can directly reuse `SplitSolveAgent` just to write: `a = SplitSolveAgent()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b210101a",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def merge_answers(qa_pairs: Dict[str, str], user_input: str) -> str:\n",
    "    answers = \"\\n\".join([v for v in qa_pairs.values()])\n",
    "    llm_response = await llm.achat(\n",
    "        messages=[\n",
    "            Message.from_text(text=f\"Merge the given answers into a unified response to the original question\", role=Role.SYSTEM),\n",
    "            Message.from_text(text=f\"Query: {user_input}\\nAnswers: {answers}\", role=Role.USER,),\n",
    "        ]\n",
    "    )\n",
    "    return llm_response.message.content\n",
    "\n",
    "# Define the Chatbot agent, use SplitSolveAgent in componentized parttern.\n",
    "class Chatbot(ASLAutoma):\n",
    "    with graph as g:\n",
    "        a = SplitSolveAgent()\n",
    "        b = merge_answers\n",
    "\n",
    "        +a >> ~b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6cf2e2e",
   "metadata": {},
   "source": [
    "Let's run the chatbot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2eefe69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Albert Einstein was born in 1879 in Ulm, Kingdom of WÃ¼rttemberg, German Empire.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot = Chatbot()\n",
    "await chatbot.arun(user_input=\"When and where was the Einstein born?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd150101",
   "metadata": {},
   "source": [
    "Perfect! Our chatbot successfully answered the question. Notice that in the implementation, we directly declared `SplitSolveAgent` within the `with graph` block. We didn't need to write a wrapper function or use any API to manually add it to the graph. Everything was naturally declared and composed.\n",
    "\n",
    "## Building Agents with Nested Structures\n",
    "\n",
    "If you have all the functional functions ready but haven't created `SplitSolveAgent` as a separate class, you don't need to implement it separately just to reuse it. Instead, you can define everything directly in one agent using nested graphs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dead7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatbotNested(ASLAutoma):\n",
    "    with graph as g:  # The chatbot agent defines its graph\n",
    "\n",
    "        with graph as split_solve:  # The split_solve agent defines its graph\n",
    "            a = break_down_query\n",
    "            b = query_answer    \n",
    "            +a >> ~b\n",
    "\n",
    "        end = merge_answers\n",
    "        +split_solve >> ~end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5370b5fc",
   "metadata": {},
   "source": [
    "Let's run it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e29285da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Albert Einstein was born in 1879 in Ulm, Kingdom of WÃ¼rttemberg, German Empire.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot_nested = ChatbotNested()\n",
    "await chatbot_nested.arun(user_input=\"When and where was the Einstein born?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8db8e3",
   "metadata": {},
   "source": [
    "We successfully achieved the expected result! We can clearly see that `ChatbotNested` has two layers of graphs, and the arrangement structure of each graph is visible at a glance.\n",
    "\n",
    "**Important**: workers in one graph cannot reference workers from another graph. In the above example, for graph `g`, workers `a` and `b` are invisibleâ€”it can only use `split_solve` as a whole. Similarly, `split_solve` cannot see workers within other graphs.\n",
    "\n",
    "> **Note**: If you reference a worker that doesn't exist in the current graph scope, an exception will be raised.\n",
    "\n",
    "These are the basic usages of ASL. Next, let's explore more advanced features.\n",
    "\n",
    "## Reusing Control Flow Fragments\n",
    "\n",
    "In a workflow, certain parts of the process might be common across multiple paths. For example, if you have `a >> b >> c` and `a >> b >> d`, the `a >> b` sequence is shared. ASL allows you to name and reuse such fragments.\n",
    "\n",
    "Here's an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ffcdf1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def add1(x: int) -> int:\n",
    "    return x + 1\n",
    "\n",
    "async def add2(x: int) -> int:\n",
    "    return x + 2\n",
    "\n",
    "async def multiply(x: int) -> int:\n",
    "    return x * 2\n",
    "\n",
    "async def division(x: int) -> int:\n",
    "    return x / 2\n",
    "\n",
    "async def merge_result(x: int, y: int) -> int:\n",
    "    return x + y\n",
    "\n",
    "class MyAutoma(ASLAutoma):\n",
    "    with graph as g:\n",
    "        a = add1\n",
    "        b = add2\n",
    "        add_process = +a >> b\n",
    "\n",
    "        c = multiply\n",
    "        d = division\n",
    "        add_multiply = add_process >> c\n",
    "        add_division = add_process >> d\n",
    "\n",
    "        merge = merge_result\n",
    "        (add_multiply & add_division) >> ~merge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec1368a",
   "metadata": {},
   "source": [
    "In this example, we have two logical sequences: one performs two additions followed by multiplication, and the other performs two additions followed by division. We can name the common `a >> b` sequence as `add_process` and reuse it, avoiding repetition. We also named each complete logical fragment (`add_multiply` and `add_division`) and then arranged them together.\n",
    "\n",
    "<br>\n",
    "<div style=\"text-align: center;\">\n",
    "<img src=\"../../../imgs/flow_fregment.png\" alt=\"Flow Fragment Reuse\" width=\"800\" height=\"600\">\n",
    "</div>\n",
    "<br>\n",
    "\n",
    "**Key points:**\n",
    "- `add_process = +a >> b`: Declares the orchestration logic `+a >> b` as a fragment named `add_process`. This fragment can be reused later to compose new execution logic without repeating the same sequence.\n",
    "- `(add_multiply & add_division)`: Groups `add_multiply` and `add_division` together. They will be treated as a single unit during orchestration.\n",
    "\n",
    "**Syntax Reference**\n",
    "\n",
    "| Syntax | Meaning | Example |\n",
    "|--------|---------|---------|\n",
    "| `<KEY> = <ORCHESTRATION_EXPRESSION>` | Defines and registers a fragment of a workflow.<br><br>**Note**: The `+` and `~` operators cannot be applied to fragments. If you declare `flow = a >> b` and then use `+flow`, this is **not** equivalent to `+a >> b`. | `flow = a >> b` registers the execution logic `a >> b` as a fragment named `flow`. You can reuse this fragment later without rewriting `a >> b` |\n",
    "| `<KEY1> & <KEY2>` | Defines a union unit (parallel group).<br><br>When an operator is applied to this unit, it operates on all elements within it, following the distributive property. | `(a & b) >> c` means `c` will execute after both `a` and `b` finish; `a >> (b & c)` means both `b` and `c` depend on `a` and will execute concurrently after `a` completes |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f16abaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_automa = MyAutoma()\n",
    "await my_automa.arun(x=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eafa9b2",
   "metadata": {},
   "source": [
    "## Controlling Data Transmission\n",
    "\n",
    "When ASL code is executed, it's first translated into corresponding Bridgic objects. For instance, a worker declared in ASL becomes a [`Worker`](../../../home/concepts.md/#worker) during execution. Therefore, ASL inherits all the underlying capabilities of Bridgic.\n",
    "\n",
    "Bridgic provides rich [parameter resolving mechanisms](../core_mechanism/parameter_binding.ipynb). In ASL, you can utilize these by configuring the `Settings` and `Data` attributes of a worker.\n",
    "\n",
    "### Using Settings for Argument Mapping\n",
    "\n",
    "The `Settings` class allows you to configure how arguments are mapped to workers. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6736cbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bridgic.core.automa.args import ArgsMappingRule\n",
    "from bridgic.asl import Settings\n",
    "\n",
    "\n",
    "async def start1(user_input: int) -> int:\n",
    "    return user_input + 1\n",
    "\n",
    "async def start2(user_input: int) -> int:\n",
    "    return user_input + 2\n",
    "\n",
    "async def worker1(x: List[int], user_input: int) -> int:\n",
    "    return sum(x) + user_input\n",
    "\n",
    "\n",
    "class MyAutoma(ASLAutoma):\n",
    "    with graph as g:\n",
    "        a = start1\n",
    "        b = start2\n",
    "        c = worker1 *Settings(args_mapping_rule=ArgsMappingRule.MERGE)\n",
    "\n",
    "        +(a & b) >> ~c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d0cc62",
   "metadata": {},
   "source": [
    "The above code defines this structure:\n",
    "\n",
    "<br>\n",
    "<div style=\"text-align: center;\">\n",
    "<img src=\"../../../imgs/asl_data_flow.png\" alt=\"ASL Data Flow\" width=\"400\" height=\"300\">\n",
    "</div>\n",
    "<br>\n",
    "\n",
    "**Key points:**\n",
    "- `add_process = +a >> b`: Declares the orchestration logic `+a >> b` as a fragment named `add_process`. This fragment can be reused later to compose new execution logic without repeating the same sequence.\n",
    "- `(add_multiply & add_division)`: Groups `add_multiply` and `add_division` together. They will be treated as a single unit during orchestration.\n",
    "\n",
    "**Syntax Reference**\n",
    "\n",
    "| Syntax | Meaning | Example |\n",
    "|--------|---------|---------|\n",
    "| `<WORKER> *Settings(...)` | Attaches configuration settings to a worker using the `*` operator.<br><br>**Settings supports three configuration fields:**<br>â€¢ `key`: The unique identifier for the worker at runtime, defaults to the `<KEY>` from `<KEY> = <WORKER>`<br>â€¢ `args_mapping_rule`: Defines how the worker receives results from preceding workers, defaults to `ArgsMappingRule.AS_IS`<br>â€¢ `result_dispatching_rule`: Defines how the worker dispatches its results to subsequent workers, defaults to `ResultDispatchingRule.AS_IS` | `worker1 *Settings(args_mapping_rule=ArgsMappingRule.MERGE)` configures `worker1` to merge results from multiple dependencies into a list. Other fields remain at their default values |\n",
    "\n",
    "> **Note**: The `key` defined in `Settings` is only used internally for scheduling during the graph execution. Therefore, when orchestrating the workflow in ASL, you still need to use the `<KEY>` in `<KEY> = <WORKER>`.\n",
    "\n",
    "Let's run it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65de96f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_automa = MyAutoma()\n",
    "await my_automa.arun(user_input=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2024e4",
   "metadata": {},
   "source": [
    "### Using Data for Argument Injection\n",
    "\n",
    "Bridgic also provides an argument injection mechanism that can be used in ASL through the `Data` class. This allows you to inject values from other workers' results into function parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c77a3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bridgic.core.automa.args import From\n",
    "from bridgic.asl import Data\n",
    "\n",
    "\n",
    "async def worker1(user_input: int) -> int:\n",
    "    return user_input + 1\n",
    "\n",
    "async def worker2(x: int) -> int:\n",
    "    return x + 2\n",
    "\n",
    "async def worker3(x: int, y: int) -> int:\n",
    "    return x + y\n",
    "\n",
    "\n",
    "class MyAutoma(ASLAutoma):\n",
    "    with graph as g:\n",
    "        a = worker1\n",
    "        b = worker2\n",
    "        c = worker3 *Data(y=From('a'))\n",
    "\n",
    "        +a >> b >> ~c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2937f5",
   "metadata": {},
   "source": [
    "**Key points:**\n",
    "- `*Data(y=From('a'))`: The `*` operator attaches data configuration to a worker. `From('a')` specifies that the parameter `y` of `worker3` should be injected from the result of worker `a` at runtime.\n",
    "\n",
    "**Syntax Reference**\n",
    "\n",
    "| Syntax | Meaning | Example |\n",
    "|--------|---------|---------|\n",
    "| `<WORKER> *Data(...)` | Attaches data configuration to a worker using the `*` operator. <br><br>**Important Note**: Data injection is equivalent to assigning a default value to a function parameter, which is dynamically injected at runtime. For example, `c = worker3 *Data(y=From('a'))` is conceptually equivalent to `async def worker3(x: int, y: int = From('a'))`. This means you **cannot** write `c = worker3 *Data(x=From('a'))`, because it would be equivalent to `async def worker3(x: int = From('a'), y: int)`, which violates Pythonâ€™s rule that parameters with default values cannot precede parameters without default values in a function signature.| `worker3 *Data(y=From('a'))` injects the result of worker `a` into parameter `y` of `worker3` |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cab990d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_automa = MyAutoma()\n",
    "await my_automa.arun(user_input=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5efcb89",
   "metadata": {},
   "source": [
    "## Dynamic Topology at Runtime\n",
    "\n",
    "Sometimes you need to dynamically adjust the graph structure based on intermediate execution results. ASL provides the ability to declare such dynamic behaviors using lambda functions.\n",
    "\n",
    "A typical use case is creating workers dynamically based on the number of items in a list returned by a previous task. Each item needs its own handler worker, but you don't know how many handlers you'll need until runtime.\n",
    "\n",
    "Here's an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d7b483",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bridgic.asl import ASLField, concurrent\n",
    "from bridgic.core.automa.args import ResultDispatchingRule\n",
    "\n",
    "\n",
    "async def produce_task(user_input: int) -> List[int]:\n",
    "    tasks = [i for i in range(user_input)]\n",
    "    return tasks\n",
    "\n",
    "async def task_handler(sub_task: int) -> List[int]:\n",
    "    res = sub_task + 1\n",
    "    return res\n",
    "\n",
    "\n",
    "class DynamicGraph(ASLAutoma):\n",
    "    with graph(user_input=ASLField(type=int)) as g:\n",
    "        producer = produce_task\n",
    "\n",
    "        with concurrent(tasks = ASLField(type=list, dispatching_rule=ResultDispatchingRule.IN_ORDER)) as c:\n",
    "            dynamic_handler = lambda tasks: (\n",
    "                task_handler *Settings(key=f\"task_handler_{task}\")\n",
    "                for task in tasks\n",
    "            )\n",
    "\n",
    "        +producer >> ~c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889b30b2",
   "metadata": {},
   "source": [
    "In this example, the `producer` worker generates a list based on `user_input`. Each element in this list needs to be processed by a `task_handler` worker. However, we don't know how many `task_handler` workers we'll need until runtime.\n",
    "\n",
    "This example uses the `concurrent` container, which represents a graph structure where all internal workers run concurrently.\n",
    "\n",
    "<br>\n",
    "<div style=\"text-align: center;\">\n",
    "<img src=\"../../../imgs/dynamic_topo.png\" alt=\"Dynamic Topology\" width=\"400\" height=\"300\">\n",
    "</div>\n",
    "<br>\n",
    "\n",
    "**Key points:**\n",
    "- `with graph(<PARAM>=ASLField(...))`: Declares input parameters for a graph using `ASLField` to specify type and behavior. Parameter names must match those used by workers within the graph.\n",
    "- `with concurrent(...)`: Creates a concurrent execution container where all internal workers execute concurrently.\n",
    "- `dynamic_handler = lambda ...`: A lambda function that generates worker instances dynamically at runtime.\n",
    "\n",
    "**Syntax Reference**\n",
    "\n",
    "| Syntax | Meaning | Example |\n",
    "|--------|---------|---------|\n",
    "| `with graph(<PARAM>=ASLField(...)) as <KEY>` | Declares input parameters for a graph. `ASLField` is a field class that extends Pydantic's `FieldInfo`, used to specify parameter type, default values, and behavior. <br><br>**ASLField parameters:** `type` (the parameter type), `default` (optional default value), and `dispatching_rule` (for concurrent containers, controls how data is distributed). Parameter names must match those used by workers within the graph. | `with graph(user_input=ASLField(type=int)) as g:` declares a graph parameter `user_input` of type `int` |\n",
    "| `<KEY> = lambda <PARAM>: (...)` | Defines a lambda function that generates worker instances dynamically. It receives parameters from the container and returns a generator of worker instances. ASL creates and executes these workers at runtime. | `dynamic_handler = lambda tasks: (task_handler *Settings(key=f\"task_{i}\") for i, task in enumerate(tasks))` generates worker instances based on the `tasks` parameter |\n",
    "\n",
    "> **Note**: Lambda functions for dynamic workers must be declared within a `concurrent` or other container(such as `sequential` in the future), not within a regular `graph`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "208eeb5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dynamic_graph = DynamicGraph()\n",
    "await dynamic_graph.arun(user_input=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d319f5a8",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Congratulations! You've learned the features of ASL:\n",
    "\n",
    "- âœ… **Basic syntax**: Declaring workers, defining dependencies with `>>`, marking start/output workers with `+`/`~`\n",
    "- âœ… **Component reuse**: Using existing agents as building blocks\n",
    "- âœ… **Nested structures**: Creating hierarchical graph organizations\n",
    "- âœ… **Fragment reuse**: Naming and reusing common control flow patterns\n",
    "- âœ… **Data control**: Using `Settings` for argument mapping and `Data` for argument injection\n",
    "- âœ… **Dynamic topology**: Creating workers dynamically at runtime using lambda functions\n",
    "\n",
    "**Syntax of ASL**\n",
    "\n",
    "| Syntax | Meaning | Example |\n",
    "|--------|---------|---------|\n",
    "| `with <GRAPH> as <KEY>:` | Defines a graph container with a given name.<br><br>**Notes:**<br>`<GRAPH>` can be either `graph` or `concurrent`:<br>1. `graph`: Allows arbitrary orchestration of worker execution order<br>  2. `concurrent`: All workers added to it will execute concurrently<br><br>`<KEY>` is required and must be unique. Without it, the program cannot identify this as an executable graph structure | `with graph as g:` declares a graph named `g`, under which you can start declaring workers and orchestrating the workflow |\n",
    "| `with <GRAPH>(<PARAM>=ASLField(...)) as <KEY>` | Declares input parameters for a graph. `ASLField` is a field class that extends Pydantic's `FieldInfo`, used to specify parameter type, default values, and behavior. <br><br>**ASLField parameters:** `type` (the parameter type), `default` (optional default value), and `dispatching_rule` (for concurrent containers, controls how data is distributed). Parameter names must match those used by workers within the graph. | `with graph(user_input=ASLField(type=int)) as g:` declares a graph parameter `user_input` of type `int` |\n",
    "| `<KEY> = <WORKER>` | Declares and registers a worker with a unique key.<br><br>**Notes:**<br>`<WORKER>` can be one of three types:<br> 1. Python functions (defined with `def` or `async def`)<br>  2. Bridgic `Worker` objects (e.g., `GraphAutoma`, custom `Worker` classes)<br> 3. Another agent implemented using `ASLAutoma`<br><br> `<KEY>` is required and must be unique within the graph scope. Without it, the worker cannot be identified and scheduled<br> All worker declarations must be written inside a `with <GRAPH> as <KEY>:` block, otherwise workers cannot be registered to the correct execution graph | `a = break_down_query` registers `break_down_query` as a worker with key `a` |\n",
    "| `<KEY> = lambda <PARAM>: (...)` | Defines a lambda function that generates worker instances dynamically. It receives parameters from the container and returns a generator of worker instances. ASL creates and executes these workers at runtime. | `dynamic_handler = lambda tasks: (task_handler *Settings(key=f\"task_{i}\") for i, task in enumerate(tasks))` generates worker instances based on the `tasks` parameter |\n",
    "| `<KEY1> >> <KEY2>` | Defines a dependency: The worker named `<KEY2>` will be triggered after the worker named `<WORKER1>` completes execution | `a >> b` means `b` will execute after `a` finishes |\n",
    "| `+<KEY>` | Marks a worker as a start worker (entry point of the execution graph) | `+a` marks `a` as the starting worker of the execution graph |\n",
    "| `~<KEY>` | Marks a worker as an output worker (exit point of the execution graph) | `~a` marks `a` as an output worker of the execution graph |\n",
    "| `<KEY1> & <KEY2>` | Defines a union unit (parallel group).<br><br>When an operator is applied to this unit, it operates on all elements within it, following the distributive property. | `(a & b) >> c` means `c` will execute after both `a` and `b` finish; `a >> (b & c)` means both `b` and `c` depend on `a` and will execute concurrently after `a` completes |\n",
    "| `<KEY> = <ORCHESTRATION_EXPRESSION>` | Defines and registers a fragment of a workflow.<br><br>**Note**: The `+` and `~` operators cannot be applied to fragments. If you declare `flow = a >> b` and then use `+flow`, this is **not** equivalent to `+a >> b`. | `flow = a >> b` registers the execution logic `a >> b` as a fragment named `flow`. You can reuse this fragment later without rewriting `a >> b` |\n",
    "| `<WORKER> *Settings(...)` | Attaches configuration settings to a worker using the `*` operator.<br><br>**Settings supports three configuration fields:**<br>â€¢ `key`: The unique identifier for the worker at runtime, defaults to the `<KEY>` from `<KEY> = <WORKER>`<br>â€¢ `args_mapping_rule`: Defines how the worker receives results from preceding workers, defaults to `ArgsMappingRule.AS_IS`<br>â€¢ `result_dispatching_rule`: Defines how the worker dispatches its results to subsequent workers, defaults to `ResultDispatchingRule.AS_IS` | `worker1 *Settings(args_mapping_rule=ArgsMappingRule.MERGE)` configures `worker1` to merge results from multiple dependencies into a list. Other fields remain at their default values |\n",
    "| `<WORKER> *Data(...)` | Attaches data configuration to a worker using the `*` operator. <br><br>**Important Note**:<br> Data injection is equivalent to assigning a default value to a function parameter, which is dynamically injected at runtime. For example, `c = worker3 *Data(y=From('a'))` is conceptually equivalent to `async def worker3(x: int, y: int = From('a'))`. This means you **cannot** write `c = worker3 *Data(x=From('a'))`, because it would be equivalent to `async def worker3(x: int = From('a'), y: int)`, which violates Pythonâ€™s rule that parameters with default values cannot precede parameters without default values in a function signature.| `worker3 *Data(y=From('a'))` injects the result of worker `a` into parameter `y` of `worker3` |\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "Now that you understand the basics, you're ready to:\n",
    "\n",
    "- Explore more advanced features in the ASL reference documentation\n",
    "- Build your own agents using ASL\n",
    "- Learn about Bridgic's underlying mechanisms for [parameter resolving](../core_mechanism/parameter_resolving.ipynb) and worker execution\n",
    "\n",
    "Happy building! ðŸš€"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

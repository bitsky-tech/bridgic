{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "659d56ac",
   "metadata": {},
   "source": [
    "# Quick Start \n",
    "\n",
    "Welcome to the **ASL(Agent Stucture Language)** — A DSL(Domain Specific Language) about how to building an agent — documentation! This page will give you an introduction to 80% of the ASL usage that you will use on a daily basis.\n",
    "\n",
    "> You will learn:\n",
    ">   1. How to build an agent by ASL.\n",
    ">   2. How to reuse the exit agents in a componentized parttern.\n",
    ">   3. How to build an agent with nested structure.\n",
    ">   4. How to control data transmission in the agent\n",
    ">   5. How to achieve dynamic topology during the agent's runtime.\n",
    "\n",
    "\n",
    "## Introduction\n",
    "\n",
    "ASL is a declarative language for agent construction. After all basic functions are modularly implemented, ASL pursue a what-you-see-is-what-you-get approach for the internal processes of the agent. We can clearly see the orchestration process and hierarchical structure at a glance.\n",
    "\n",
    "### Build an Agent by ASL\n",
    "\n",
    "Take the simplest text generation process as an example. When a user inputs a query, we break it down, and then generate text for every sub-query.\n",
    "\n",
    "Let's first prepare necessary environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee829ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the environment variables.\n",
    "import os\n",
    "\n",
    "_api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "_api_base = os.environ.get(\"OPENAI_API_BASE\")\n",
    "_model_name = os.environ.get(\"OPENAI_MODEL_NAME\")\n",
    "\n",
    "# Import the necessary packages.\n",
    "from typing import List, Dict\n",
    "from bridgic.core.model.types import Message, Role\n",
    "from bridgic.core.agentic.asl import ASLAutoma, graph\n",
    "from bridgic.llms.openai import OpenAILlm, OpenAIConfiguration\n",
    "\n",
    "llm = OpenAILlm(  # the llm instance\n",
    "    api_base=_api_base,\n",
    "    api_key=_api_key,\n",
    "    timeout=5,\n",
    "    configuration=OpenAIConfiguration(model=_model_name),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c69b76",
   "metadata": {},
   "source": [
    "Secondly, modularly implement the functional functions needed in this process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "138ae30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Break down the query into a list of sub-queries.\n",
    "async def break_down_query(user_input: str) -> List[str]:\n",
    "    llm_response = await llm.achat(\n",
    "        messages=[\n",
    "            Message.from_text(text=f\"Break down the query into multiple sub-queries and only return the sub-queries\", role=Role.SYSTEM),\n",
    "            Message.from_text(text=user_input, role=Role.USER,),\n",
    "        ]\n",
    "    )\n",
    "    return [item.strip() for item in llm_response.message.content.split(\"\\n\") if item.strip()]\n",
    "\n",
    "# Define the function to conduct a web search.\n",
    "async def query_answer(queries: List[str]) -> Dict[str, str]:\n",
    "    answers = []\n",
    "    for query in queries:\n",
    "        response = await llm.achat(\n",
    "            messages=[\n",
    "                Message.from_text(text=f\"Answer the given query briefly\", role=Role.SYSTEM),\n",
    "                Message.from_text(text=query, role=Role.USER,),\n",
    "            ]\n",
    "        )\n",
    "        answers.append(response.message.content)\n",
    "    \n",
    "    res = {\n",
    "        query: answer\n",
    "        for query, answer in zip(queries, answers)\n",
    "    }\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13191627",
   "metadata": {},
   "source": [
    "Now, Let's complete this process using ASL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a1e45f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SplitSolveAgent(ASLAutoma):\n",
    "    with graph as g:\n",
    "        a = break_down_query\n",
    "        b = query_answer\n",
    "\n",
    "        +a >> ~b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d9c0aa",
   "metadata": {},
   "source": [
    "The implementation process of `SplitSolveAgent` was accomplished through orchestration using ASL grammar. In this grammar:\n",
    "- `with graph as g`: Represents opening a graph, and we can **declare the nodes** and **defining the dependency** between the nodes under its syntax block.\n",
    "- `a = break_down_query`: Represents declaring a node names `a`.\n",
    "- `a >> b`: Represents defining the dependency of `b` is `a`, which means the `b` will execute after `a`.\n",
    "- `+a`: Represents defining `a` is the start.\n",
    "- `~b`: Represents defining `b` is the output.\n",
    "\n",
    "Now, Let's run it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875f62a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1. When was Einstein born?': 'Albert Einstein was born in 1879.',\n",
       " '2. Where was Einstein born?': 'Albert Einstein was born in Ulm, Kingdom of Württemberg, German Empire.'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_generation_agent = SplitSolveAgent()\n",
    "await text_generation_agent.arun(\"When and where was the Einstein born?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7a2a26",
   "metadata": {},
   "source": [
    "Great! We successfully obtained the result. In the ASL code, we can see very intuitively that the `SplitSolveAgent` has only two nodes, and `b` depends on `a`, with no other redundant information. ASL elevates node declarations and dependency management in an execution flow to first-class language constructs.\n",
    "\n",
    "### Reuse the Exit Agents in Componentized Parttern\n",
    "\n",
    "In the above process, we have completed the agent that splits the query and answers them separately. It is a pre-designed module. Now, I want to design a chatbot that merge these individual answers to generate a unified response to the original question. Like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b210101a",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def merge_answers(qa_pairs: Dict[str, str], user_input: str) -> str:\n",
    "    answers = \"\\n\".join([v for v in qa_pairs.values()])\n",
    "    llm_response = await llm.achat(\n",
    "        messages=[\n",
    "            Message.from_text(text=f\"Merge the given answers into a unified response to the original question\", role=Role.SYSTEM),\n",
    "            Message.from_text(text=f\"Query: {user_input}\\nAnswers: {answers}\", role=Role.USER,),\n",
    "        ]\n",
    "    )\n",
    "    return llm_response.message.content\n",
    "\n",
    "# Define the Chatbot agent, use SplitSolveAgent in componentized parttern.\n",
    "class Chatbot(ASLAutoma):\n",
    "    with graph as g:\n",
    "        a = SplitSolveAgent()\n",
    "        b = merge_answers\n",
    "\n",
    "        +a >> ~b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6cf2e2e",
   "metadata": {},
   "source": [
    "Let's run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f2eefe69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Albert Einstein was born in 1879 in Ulm, Kingdom of Württemberg, German Empire.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot = Chatbot()\n",
    "await chatbot.arun(user_input=\"When and where was the Einstein born?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd150101",
   "metadata": {},
   "source": [
    "Great! Our chatbot successfully answered our questions. During its implementation, we directly declared `SplitSolveAgent` within the `with graph` statement block. We did not write a function to encapsulate it, nor did we use any form of API to manually add it to the graph. Everything was naturally declared and completed.\n",
    "\n",
    "### Build an Agent with Nested Structure or Arranging Fregment\n",
    "\n",
    "When we have all the functional function ready, but we don't `SplitSolveAgent`, we don't have to implement it specifically to reuse it. Instead, we can write everything in one agent directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dead7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatbotNested(ASLAutoma):\n",
    "    with graph as g:  #  the chatbot agent to define its graph\n",
    "        with graph as split_solve:  #  the split_solve agent to define its graph\n",
    "            a = break_down_query\n",
    "            b = query_answer    \n",
    "            +a >> ~b\n",
    "        end = merge_answers\n",
    "        \n",
    "        +split_solve >> ~end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5370b5fc",
   "metadata": {},
   "source": [
    "Let's run it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e29285da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Albert Einstein was born in 1879 in Ulm, Kingdom of Württemberg, German Empire.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot_nested = ChatbotNested()\n",
    "await chatbot_nested.arun(user_input=\"When and where was the Einstein born?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8db8e3",
   "metadata": {},
   "source": [
    "We successfully achieved the expected result. We can clearly see that there are two layers of graphs in `ChatbotNested` and what the arrangement structure of each graph is. \n",
    "\n",
    "Of course, the arrangement in one graph cannot use the nodes from another graph. In the above example, for graph `g`, nodes `a` and `b` are invisible, and it can only use `split_solve` as a whole to arrange beneath it. Similarly, for `split_solve`, it cannot see the nodes within other graphs either.\n",
    "\n",
    "> Note: If a node that is unknown to the graph is referenced in it, an exception will be thrown.\n",
    "\n",
    "### Control Data Transmission in the Agent\n",
    "\n",
    "When executing an ASL code, the program first \"translates\" it into the corresponding objects in Bridgic. For instance, a node declared in ASL is actually a [`Worker`](../../../reference/bridgic-core/bridgic/core/automa/worker/index.md) during execution. Therefore, ASL also possesses all the underlying capabilities of Bridgic.\n",
    "\n",
    "Bridgic offers a variety of rich [parameter binding mechanisms](../core_mechanism/parameter_binding.ipynb). In ASL, we can utilize them by setting the `Settings` and `Data` attributes of a node.\n",
    "\n",
    "For example, the following code："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6736cbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bridgic.core.automa.args import ArgsMappingRule\n",
    "from bridgic.core.agentic.asl import Settings\n",
    "\n",
    "\n",
    "async def start1(user_input: int) -> int:\n",
    "    return user_input + 1\n",
    "\n",
    "async def start2(user_input: int) -> int:\n",
    "    return user_input + 2\n",
    "\n",
    "async def worker1(x: List[int], user_input: int) -> int:\n",
    "    print(f\"worker1: {x}, {user_input}\")\n",
    "    return sum(x) + user_input\n",
    "\n",
    "\n",
    "class MyAgent(ASLAutoma):\n",
    "    with graph as g:\n",
    "        a = start1\n",
    "        b = start2\n",
    "        c = worker1 *Settings(args_mapping_rule=ArgsMappingRule.MERGE)\n",
    "\n",
    "        +(a & b) >> ~c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d0cc62",
   "metadata": {},
   "source": [
    "The above code defines such a structure:\n",
    "\n",
    "<br>\n",
    "<div style=\"text-align: center;\">\n",
    "<img src=\"../../../imgs/asl_data_flow.png\" alt=\"Parameter Passing\" width=\"800\" height=\"600\">\n",
    "</div>\n",
    "<br>\n",
    "\n",
    "In this grammar:\n",
    "- `worker1 *Settings`: Represents that when adding the `worker1` function as an execution unit, some configurations are made for it. The field of `Settings` is the same as [the decorator `@worker` in bridgic](../quick_start/quick_start.ipynb#Worker). Now, `c` will receive result from `a` and `b` in the `ArgsMappingRule.MERGE` form.\n",
    "- `+(a & b)`: Represents that the expressions for arranging control flow have distributive and associative laws. `(a & b)` indicates that `a` and `b` are arranged as a whole. `+(a & b)` indicates `a` and `b` are both start entry point.\n",
    "\n",
    "Let's run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "65de96f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "worker1: [2, 3], 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_agent = MyAgent()\n",
    "await my_agent.arun(user_input=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2024e4",
   "metadata": {},
   "source": [
    "In addition, bridgic also has a arguments injection mechanism, which can also be used in ASL through `Data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8c77a3f8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "non-default argument follows default argument",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mbridgic\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautoma\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01margs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m From\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mbridgic\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magentic\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01masl\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Data\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mMyAgent\u001b[39;00m(ASLAutoma):\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m graph \u001b[38;5;28;01mas\u001b[39;00m g:\n\u001b[1;32m      6\u001b[0m         a \u001b[38;5;241m=\u001b[39m start1\n",
      "Cell \u001b[0;32mIn[36], line 8\u001b[0m, in \u001b[0;36mMyAgent\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m a \u001b[38;5;241m=\u001b[39m start1\n\u001b[1;32m      7\u001b[0m b \u001b[38;5;241m=\u001b[39m start2\n\u001b[0;32m----> 8\u001b[0m c \u001b[38;5;241m=\u001b[39m worker1 \u001b[38;5;241m*\u001b[39mData(x\u001b[38;5;241m=\u001b[39mFrom(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     10\u001b[0m \u001b[38;5;241m+\u001b[39ma \u001b[38;5;241m>>\u001b[39m b \u001b[38;5;241m>>\u001b[39m \u001b[38;5;241m~\u001b[39mc\n",
      "File \u001b[0;32m~/Desktop/project/bridgic/bridgic-core/bridgic/core/agentic/asl/_asl_automa.py:84\u001b[0m, in \u001b[0;36mTrackingNamespace.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# update the data of the element\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[0;32m---> 84\u001b[0m     \u001b[43melement\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;66;03m# judge if the value is a lambda function\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, Callable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(value\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__code__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mco_name\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<lambda>\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m~/Desktop/project/bridgic/bridgic-core/bridgic/core/agentic/asl/_canvas_object.py:255\u001b[0m, in \u001b[0;36m_CanvasObject.update_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworker_material, Callable):\n\u001b[1;32m    254\u001b[0m     func_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworker_material, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__name__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mrepr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworker_material))\n\u001b[0;32m--> 255\u001b[0m     \u001b[43moverride_func_signature\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mworker_material\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/project/bridgic/bridgic-core/bridgic/core/automa/args/_args_binding.py:876\u001b[0m, in \u001b[0;36moverride_func_signature\u001b[0;34m(name, func, data)\u001b[0m\n\u001b[1;32m    872\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    873\u001b[0m         \u001b[38;5;66;03m# Keep original parameter unchanged\u001b[39;00m\n\u001b[1;32m    874\u001b[0m         new_params\u001b[38;5;241m.\u001b[39mappend(original_param)\n\u001b[0;32m--> 876\u001b[0m new_signature \u001b[38;5;241m=\u001b[39m \u001b[43moriginal_sig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;28msetattr\u001b[39m(func, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__signature__\u001b[39m\u001b[38;5;124m\"\u001b[39m, new_signature)\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/inspect.py:2902\u001b[0m, in \u001b[0;36mSignature.replace\u001b[0;34m(self, parameters, return_annotation)\u001b[0m\n\u001b[1;32m   2899\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_annotation \u001b[38;5;129;01mis\u001b[39;00m _void:\n\u001b[1;32m   2900\u001b[0m     return_annotation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_return_annotation\n\u001b[0;32m-> 2902\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2903\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mreturn_annotation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_annotation\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/inspect.py:2836\u001b[0m, in \u001b[0;36mSignature.__init__\u001b[0;34m(self, parameters, return_annotation, __validate_parameters__)\u001b[0m\n\u001b[1;32m   2830\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m kind_defaults:\n\u001b[1;32m   2831\u001b[0m         \u001b[38;5;66;03m# No default for this parameter, but the\u001b[39;00m\n\u001b[1;32m   2832\u001b[0m         \u001b[38;5;66;03m# previous parameter of the same kind had\u001b[39;00m\n\u001b[1;32m   2833\u001b[0m         \u001b[38;5;66;03m# a default\u001b[39;00m\n\u001b[1;32m   2834\u001b[0m         msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnon-default argument follows default \u001b[39m\u001b[38;5;124m'\u001b[39m \\\n\u001b[1;32m   2835\u001b[0m               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124margument\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m-> 2836\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m   2837\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2838\u001b[0m     \u001b[38;5;66;03m# There is a default for this parameter.\u001b[39;00m\n\u001b[1;32m   2839\u001b[0m     kind_defaults \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: non-default argument follows default argument"
     ]
    }
   ],
   "source": [
    "from bridgic.core.automa.args import From\n",
    "from bridgic.core.agentic.asl import Data\n",
    "\n",
    "class MyAgent(ASLAutoma):\n",
    "    with graph as g:\n",
    "        a = start1\n",
    "        b = start2\n",
    "        c = worker1 *Data(x=From('a'))\n",
    "\n",
    "        +a >> b >> ~c"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

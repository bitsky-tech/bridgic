{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "659d56ac",
   "metadata": {},
   "source": [
    "# Quick Start \n",
    "\n",
    "Welcome to the **ASL(Agent Stucture Language)** — A DSL(Domain Specific Language) about how to building an agent — documentation! This page will give you an introduction to 80% of the ASL usage that you will use on a daily basis.\n",
    "\n",
    "> You will learn:\n",
    ">   1. How to build an agent by ASL.\n",
    ">   2. How to reuse the exit agents in a componentized parttern.\n",
    ">   3. How to build an agent with a nested structure.\n",
    ">   4. How to control data transmission in the agent\n",
    ">   5. How to achieve dynamic topology during the agent's runtime.\n",
    "\n",
    "\n",
    "## Introduction\n",
    "\n",
    "ASL is a declarative language for agent construction. After all basic functions are modularly implemented, we pursue a what-you-see-is-what-you-get approach for the internal processes of the agent. We can clearly see the orchestration process and hierarchical structure at a glance.\n",
    "\n",
    "### Build an Agent by ASL\n",
    "\n",
    "Take the simplest text generation process as an example. When a user inputs a query, we break it down, and then generate text for every sub-query.\n",
    "\n",
    "Let's first prepare necessary environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee829ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the environment variables.\n",
    "import os\n",
    "\n",
    "_api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "_api_base = os.environ.get(\"OPENAI_API_BASE\")\n",
    "_model_name = os.environ.get(\"OPENAI_MODEL_NAME\")\n",
    "\n",
    "# Import the necessary packages.\n",
    "from typing import List, Dict\n",
    "from bridgic.core.model.types import Message, Role\n",
    "from bridgic.core.agentic.asl import ASLAutoma, graph\n",
    "from bridgic.llms.openai import OpenAILlm, OpenAIConfiguration\n",
    "\n",
    "llm = OpenAILlm(  # the llm instance\n",
    "    api_base=_api_base,\n",
    "    api_key=_api_key,\n",
    "    timeout=5,\n",
    "    configuration=OpenAIConfiguration(model=_model_name),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c69b76",
   "metadata": {},
   "source": [
    "Secondly, modularly implement the functional functions needed in this process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "138ae30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Break down the query into a list of sub-queries.\n",
    "async def break_down_query(user_input: str) -> List[str]:\n",
    "    llm_response = await llm.achat(\n",
    "        messages=[\n",
    "            Message.from_text(text=f\"Break down the query into multiple sub-queries and only return the sub-queries\", role=Role.SYSTEM),\n",
    "            Message.from_text(text=user_input, role=Role.USER,),\n",
    "        ]\n",
    "    )\n",
    "    return [item.strip() for item in llm_response.message.content.split(\"\\n\") if item.strip()]\n",
    "\n",
    "# Define the function to conduct a web search.\n",
    "async def query_answer(queries: List[str]) -> Dict[str, str]:\n",
    "    answers = []\n",
    "    for query in queries:\n",
    "        response = await llm.achat(\n",
    "            messages=[\n",
    "                Message.from_text(text=f\"Answer the given query briefly\", role=Role.SYSTEM),\n",
    "                Message.from_text(text=query, role=Role.USER,),\n",
    "            ]\n",
    "        )\n",
    "        answers.append(response.message.content)\n",
    "    \n",
    "    res = {\n",
    "        query: answer\n",
    "        for query, answer in zip(queries, answers)\n",
    "    }\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13191627",
   "metadata": {},
   "source": [
    "Now, Let's complete this process using ASL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4a1e45f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SplitSolveAgent(ASLAutoma):\n",
    "    with graph as g:\n",
    "        a = break_down_query\n",
    "        b = query_answer\n",
    "\n",
    "        +a >> ~b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d9c0aa",
   "metadata": {},
   "source": [
    "The implementation process of `SplitSolveAgent` was accomplished through orchestration using ASL grammar. In this grammar:\n",
    "- `with graph as g`: Represents opening a graph, and we can **declare the nodes** and **defining the dependency** between the nodes under its syntax block.\n",
    "- `a = break_down_query`: Represents declaring a node names `a`.\n",
    "- `a >> b`: Represents defining the dependency of `b` is `a`, which means the `b` will execute after `a`.\n",
    "- `+a`: Represents defining `a` is the start.\n",
    "- `~b`: Represents defining `b` is the output.\n",
    "\n",
    "Now, Let's run it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875f62a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1. When was Einstein born?': 'Albert Einstein was born in 1879.',\n",
       " '2. Where was Einstein born?': 'Albert Einstein was born in Ulm, Kingdom of Württemberg, German Empire.'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_generation_agent = SplitSolveAgent()\n",
    "await text_generation_agent.arun(\"When and where was the Einstein born?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7a2a26",
   "metadata": {},
   "source": [
    "Great! We successfully obtained the result. In the ASL code, we can see very intuitively that the `SplitSolveAgent` has only two nodes, and `b` depends on `a`, with no other redundant information.\n",
    "\n",
    "### Reuse the Exit Agents in Componentized Parttern\n",
    "\n",
    "In the above process, we have completed the agent that splits the query and answers them separately. It is a pre-designed module. Now, I want to design a chatbot that merge these individual answers to generate a unified response to the original question. Like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b210101a",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def merge_answers(qa_pairs: Dict[str, str], user_input: str) -> str:\n",
    "    answers = \"\\n\".join([v for _, v in qa_pairs.values()])\n",
    "    llm_response = await llm.achat(\n",
    "        messages=[\n",
    "            Message.from_text(text=f\"Merge the given answers into a unified response to the original question\", role=Role.SYSTEM),\n",
    "            Message.from_text(text=f\"Query: {user_input}\\nAnswers: {answers}\", role=Role.USER,),\n",
    "        ]\n",
    "    )\n",
    "    return llm_response.message.content\n",
    "\n",
    "# Define the Chatbot agent, use SplitSolveAgent in componentized parttern.\n",
    "class Chatbot(ASLAutoma):\n",
    "    with graph as g:\n",
    "        a = SplitSolveAgent()\n",
    "        b = merge_answers\n",
    "\n",
    "        +a >> ~b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6cf2e2e",
   "metadata": {},
   "source": [
    "Let's run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f2eefe69",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "break_down_query() missing 1 required positional argument: 'user_input'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m chatbot \u001b[38;5;241m=\u001b[39m Chatbot()\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m chatbot\u001b[38;5;241m.\u001b[39marun(user_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen and where was the Einstein born?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/project/bridgic/bridgic-core/bridgic/core/agentic/asl/_asl_automa.py:475\u001b[0m, in \u001b[0;36mASLAutoma.arun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21marun\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Tuple[Any, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Dict[\u001b[38;5;28mstr\u001b[39m, Any]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    457\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    458\u001b[0m \u001b[38;5;124;03m    Execute the automaton asynchronously.\u001b[39;00m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m        The result of executing the automaton workflow.\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 475\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39marun(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Desktop/project/bridgic/bridgic-core/bridgic/core/automa/_graph_automa.py:1151\u001b[0m, in \u001b[0;36mGraphAutoma.arun\u001b[0;34m(self, feedback_data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_top_level():\n\u001b[1;32m   1146\u001b[0m     \u001b[38;5;66;03m# For top-level automa, wrap in a task to ensure context isolation\u001b[39;00m\n\u001b[1;32m   1147\u001b[0m     task \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mcreate_task(\n\u001b[1;32m   1148\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_arun_internal(\u001b[38;5;241m*\u001b[39margs, feedback_data\u001b[38;5;241m=\u001b[39mfeedback_data, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs),\n\u001b[1;32m   1149\u001b[0m         name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGraphAutoma-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-arun\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m task\n\u001b[1;32m   1152\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1153\u001b[0m     \u001b[38;5;66;03m# For nested automa, directly call _arun_internal to avoid redundant task creation\u001b[39;00m\n\u001b[1;32m   1154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_arun_internal(\u001b[38;5;241m*\u001b[39margs, feedback_data\u001b[38;5;241m=\u001b[39mfeedback_data, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Desktop/project/bridgic/bridgic-core/bridgic/core/automa/_graph_automa.py:1503\u001b[0m, in \u001b[0;36mGraphAutoma._arun_internal\u001b[0;34m(self, feedback_data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;66;03m# For non-interaction exceptions, immediately raise the first one directly, since none of them are meant to be suppressed.\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(non_interaction_exceptions) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1503\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m non_interaction_exceptions[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;66;03m# Find next kickoff workers and rebuild _current_kickoff_workers\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m run_finished_worker_keys: List[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m [kickoff_info\u001b[38;5;241m.\u001b[39mworker_key \u001b[38;5;28;01mfor\u001b[39;00m kickoff_info \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_kickoff_workers \u001b[38;5;28;01mif\u001b[39;00m kickoff_info\u001b[38;5;241m.\u001b[39mrun_finished]\n",
      "File \u001b[0;32m~/Desktop/project/bridgic/bridgic-core/bridgic/core/automa/_graph_automa.py:1414\u001b[0m, in \u001b[0;36mGraphAutoma._arun_internal\u001b[0;34m(self, feedback_data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1411\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_running_tasks:\n\u001b[1;32m   1412\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1413\u001b[0m         \u001b[38;5;66;03m# It will raise an exception if task failed.\u001b[39;00m\n\u001b[0;32m-> 1414\u001b[0m         task_result \u001b[38;5;241m=\u001b[39m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1415\u001b[0m         _set_worker_run_finished(task\u001b[38;5;241m.\u001b[39mworker_key)\n\u001b[1;32m   1417\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m task\u001b[38;5;241m.\u001b[39mworker_key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers:\n\u001b[1;32m   1418\u001b[0m             \u001b[38;5;66;03m# The current running worker may be removed.\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/project/bridgic/bridgic-core/bridgic/core/automa/_graph_automa.py:1397\u001b[0m, in \u001b[0;36mGraphAutoma._arun_internal\u001b[0;34m(self, feedback_data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1395\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1396\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1397\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m undone_tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1398\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1399\u001b[0m     \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\n",
      "File \u001b[0;32m~/Desktop/project/bridgic/bridgic-core/bridgic/core/automa/_graph_automa.py:102\u001b[0m, in \u001b[0;36m_GraphAdaptedWorker.arun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m callback\u001b[38;5;241m.\u001b[39mon_worker_start(\n\u001b[1;32m     95\u001b[0m         key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey,\n\u001b[1;32m     96\u001b[0m         is_top_level\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     97\u001b[0m         parent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent,\n\u001b[1;32m     98\u001b[0m         arguments\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margs\u001b[39m\u001b[38;5;124m\"\u001b[39m: args, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: kwargs},\n\u001b[1;32m     99\u001b[0m     )\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 102\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decorated_worker\u001b[38;5;241m.\u001b[39marun(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;66;03m# Try to handle the exception with callbacks\u001b[39;00m\n\u001b[1;32m    105\u001b[0m     handled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m try_handle_error_with_callbacks(\n\u001b[1;32m    106\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_worker_callbacks,\n\u001b[1;32m    107\u001b[0m         key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    111\u001b[0m         error\u001b[38;5;241m=\u001b[39me,\n\u001b[1;32m    112\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/project/bridgic/bridgic-core/bridgic/core/agentic/asl/_asl_automa.py:475\u001b[0m, in \u001b[0;36mASLAutoma.arun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21marun\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Tuple[Any, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Dict[\u001b[38;5;28mstr\u001b[39m, Any]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    457\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    458\u001b[0m \u001b[38;5;124;03m    Execute the automaton asynchronously.\u001b[39;00m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m        The result of executing the automaton workflow.\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 475\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39marun(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Desktop/project/bridgic/bridgic-core/bridgic/core/automa/_graph_automa.py:1154\u001b[0m, in \u001b[0;36mGraphAutoma.arun\u001b[0;34m(self, feedback_data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m task\n\u001b[1;32m   1152\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1153\u001b[0m     \u001b[38;5;66;03m# For nested automa, directly call _arun_internal to avoid redundant task creation\u001b[39;00m\n\u001b[0;32m-> 1154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_arun_internal(\u001b[38;5;241m*\u001b[39margs, feedback_data\u001b[38;5;241m=\u001b[39mfeedback_data, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Desktop/project/bridgic/bridgic-core/bridgic/core/automa/_graph_automa.py:1503\u001b[0m, in \u001b[0;36mGraphAutoma._arun_internal\u001b[0;34m(self, feedback_data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;66;03m# For non-interaction exceptions, immediately raise the first one directly, since none of them are meant to be suppressed.\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(non_interaction_exceptions) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1503\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m non_interaction_exceptions[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;66;03m# Find next kickoff workers and rebuild _current_kickoff_workers\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m run_finished_worker_keys: List[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m [kickoff_info\u001b[38;5;241m.\u001b[39mworker_key \u001b[38;5;28;01mfor\u001b[39;00m kickoff_info \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_kickoff_workers \u001b[38;5;28;01mif\u001b[39;00m kickoff_info\u001b[38;5;241m.\u001b[39mrun_finished]\n",
      "File \u001b[0;32m~/Desktop/project/bridgic/bridgic-core/bridgic/core/automa/_graph_automa.py:1414\u001b[0m, in \u001b[0;36mGraphAutoma._arun_internal\u001b[0;34m(self, feedback_data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1411\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_running_tasks:\n\u001b[1;32m   1412\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1413\u001b[0m         \u001b[38;5;66;03m# It will raise an exception if task failed.\u001b[39;00m\n\u001b[0;32m-> 1414\u001b[0m         task_result \u001b[38;5;241m=\u001b[39m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1415\u001b[0m         _set_worker_run_finished(task\u001b[38;5;241m.\u001b[39mworker_key)\n\u001b[1;32m   1417\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m task\u001b[38;5;241m.\u001b[39mworker_key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers:\n\u001b[1;32m   1418\u001b[0m             \u001b[38;5;66;03m# The current running worker may be removed.\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/project/bridgic/bridgic-core/bridgic/core/automa/_graph_automa.py:1397\u001b[0m, in \u001b[0;36mGraphAutoma._arun_internal\u001b[0;34m(self, feedback_data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1395\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1396\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1397\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m undone_tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1398\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1399\u001b[0m     \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\n",
      "File \u001b[0;32m~/Desktop/project/bridgic/bridgic-core/bridgic/core/automa/_graph_automa.py:102\u001b[0m, in \u001b[0;36m_GraphAdaptedWorker.arun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m callback\u001b[38;5;241m.\u001b[39mon_worker_start(\n\u001b[1;32m     95\u001b[0m         key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey,\n\u001b[1;32m     96\u001b[0m         is_top_level\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     97\u001b[0m         parent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent,\n\u001b[1;32m     98\u001b[0m         arguments\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margs\u001b[39m\u001b[38;5;124m\"\u001b[39m: args, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: kwargs},\n\u001b[1;32m     99\u001b[0m     )\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 102\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decorated_worker\u001b[38;5;241m.\u001b[39marun(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;66;03m# Try to handle the exception with callbacks\u001b[39;00m\n\u001b[1;32m    105\u001b[0m     handled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m try_handle_error_with_callbacks(\n\u001b[1;32m    106\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_worker_callbacks,\n\u001b[1;32m    107\u001b[0m         key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    111\u001b[0m         error\u001b[38;5;241m=\u001b[39me,\n\u001b[1;32m    112\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/project/bridgic/bridgic-core/bridgic/core/automa/worker/_callable_worker.py:59\u001b[0m, in \u001b[0;36mCallableWorker.arun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m WorkerRuntimeError(\n\u001b[1;32m     55\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe callable is expected to be bound to the parent, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     56\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut not bounded yet: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callable\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     57\u001b[0m     )\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_async:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_callable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39marun(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mTypeError\u001b[0m: break_down_query() missing 1 required positional argument: 'user_input'"
     ]
    }
   ],
   "source": [
    "chatbot = Chatbot()\n",
    "await chatbot.arun(user_input=\"When and where was the Einstein born?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

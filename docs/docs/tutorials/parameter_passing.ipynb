{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ad7e065",
   "metadata": {},
   "source": [
    "# Parameter Passing\n",
    "\n",
    "Bridgic can orchestrate workflows composed of workers. There are three ways to pass data among workers, including Arguments Mapping, Arguments Injection, Inputs Propagation. Now let's understand them with a sample example.\n",
    "\n",
    "<br>\n",
    "<div style=\"text-align: center;\">\n",
    "<img src=\"../imgs/Parameter_Passing.png\" alt=\"Parameter Passing\" width=\"800\" height=\"600\">\n",
    "</div>\n",
    "<br>\n",
    "\n",
    "Query expansion is a common step in RAG and can enhance the quality of RAG. To enhance the quality of query expansion, developers often first extract the entity information from the question and use it to assist the model in expanding the original question. \n",
    "\n",
    "Now let's take it. The user inputs the original question, and then we expand the question to obtain more sub-questions. There are three steps to complete the query extension:\n",
    "\n",
    "1. Receive the user's input and perform preprocessing, get original question.\n",
    "2. Extract the entity information from the question, get entity information.\n",
    "3. Expand and obtain multiple queries.\n",
    "\n",
    "Before we start, let's prepare the running environment.\n",
    "\n",
    "Use the `export` command to set up the API information for model invocation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15383545",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Setting environment variables in the terminal:\n",
    "export VLLM_SERVER_API_BASE=\"your-api-url\"\n",
    "export VLLM_SERVER_API_KEY=\"your-api-key\"\n",
    "export VLLM_SERVER_MODEL_NAME=\"your-model-name\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4b976f",
   "metadata": {},
   "source": [
    "Get the environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba6c074",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "_api_base = os.environ.get(\"VLLM_SERVER_API_BASE\")\n",
    "_api_key = os.environ.get(\"VLLM_SERVER_API_KEY\")\n",
    "_model_name = os.environ.get(\"VLLM_SERVER_MODEL_NAME\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63530199",
   "metadata": {},
   "source": [
    "Import the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf67b1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Dict, Tuple\n",
    "from bridgic.core.automa import GraphAutoma, worker, ArgsMappingRule\n",
    "from bridgic.llms.vllm.vllm_server_llm import VllmServerLlm, Message, Role, PydanticModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76de67bc",
   "metadata": {},
   "source": [
    "Now, let's implement this query expansion. We assume that the user query we receive is in json format. It contains two keys:\n",
    "1. `id`: A string that indicates who inputs the query.\n",
    "1. `query`: A string in the form of `Q: user_query` representing the question input by the user.\n",
    "2. `date`: The time when the user entered the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4a18adef",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_obj = {\n",
    "    \"id\": \"user_1\",\n",
    "    \"query\": \"Q: What new developments have there been in RAG in the past year?\",\n",
    "    \"date\": \"2025-09-30\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc99a6e",
   "metadata": {},
   "source": [
    "We initialize the model to facilitate our subsequent convenient invocation of it to complete tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8293fa28",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = VllmServerLlm(  # the llm instance\n",
    "    api_base=_api_base,\n",
    "    api_key=_api_key,\n",
    "    timeout=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa6f2d0",
   "metadata": {},
   "source": [
    "Furthermore, we define that when the model completes entity extraction and query expansion, it returns the result in a Pydantic data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e88b6d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EntityList(BaseModel):  # The expected format of the model output in the extract_entity worker\n",
    "    entities: List[str] = Field(description=\"All entities in the input.\")\n",
    "\n",
    "class QueryList(BaseModel):  # The expected format of the model output in the expand_query worker\n",
    "    queries: List[str] = Field(description=\"All queries in the input.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513805e8",
   "metadata": {},
   "source": [
    "Next, let's outline the three steps of query expansion to achieve our goal:\n",
    "\n",
    "1. Receive the user's input and perform preprocessing, get original question.\n",
    "2. Extract the entity information from the question, get entity information.\n",
    "3. Expand and obtain multiple queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "99b17307",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryExpansion(GraphAutoma):\n",
    "    @worker(is_start=True)\n",
    "    async def pre_query(self, query_obj: Dict):  # Receive the user's input and preprocess query\n",
    "        query = query_obj[\"query\"].split(\":\")[1].strip()  \n",
    "        return query\n",
    "\n",
    "    @worker(is_start=True)\n",
    "    async def pre_date(self, query_obj: Dict):  # Receive the user's input and preprocess date\n",
    "        date = query_obj[\"date\"]\n",
    "        return date\n",
    "\n",
    "    @worker(dependencies=[\"pre_query\", \"pre_date\"], args_mapping_rule=ArgsMappingRule.AS_IS)\n",
    "    async def extract_entity(self, query: str, date: str):  # Extract the entity information from the question, get entity information.\n",
    "        response: EntityList = llm.structured_output(  \n",
    "            model=_model_name,\n",
    "            constraint=PydanticModel(model=EntityList),\n",
    "            messages=[\n",
    "                Message.from_text(text=\"extract the entity information from the given query\", role=Role.SYSTEM),\n",
    "                Message.from_text(text=query, role=Role.USER,),\n",
    "            ]\n",
    "        )\n",
    "        return query, response.entities, date\n",
    "\n",
    "    @worker(dependencies=[\"extract_entity\"], args_mapping_rule=ArgsMappingRule.AS_IS)\n",
    "    async def expand_query(self, query_meta: Tuple[str, List[str]]):  # Expand and obtain multiple queries.\n",
    "        query, entities, date = query_meta\n",
    "        task_input = f\"Query: {query}\\nEntities: {entities}\"\n",
    "        response: str = llm.structured_output(\n",
    "            model=_model_name,\n",
    "            constraint=PydanticModel(model=QueryList),\n",
    "            messages=[\n",
    "                Message.from_text(text=f\"Centered around the given entities and given date {date}, expand the query to obtain multiple queries\", role=Role.SYSTEM),\n",
    "                Message.from_text(text=task_input, role=Role.USER,),\n",
    "            ]\n",
    "        )\n",
    "        return response.queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631443a8",
   "metadata": {},
   "source": [
    "Let's run it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "235d5630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What are the latest advancements in Retrieval-Augmented Generation (RAG) technologies as of 2025?',\n",
       " 'What new developments have emerged in RAG systems over the past 12 months?',\n",
       " 'How have RAG implementations evolved in the last year in terms of performance and scalability?',\n",
       " 'What innovative techniques have been introduced in RAG models since 2024?',\n",
       " 'What are the key breakthroughs in RAG technology reported in 2025?',\n",
       " 'How have recent improvements in RAG affected real-world applications in 2025?',\n",
       " 'What new tools and frameworks have been launched for RAG development in the past year?',\n",
       " 'What are the most significant updates in RAG research published between 2024 and 2025?',\n",
       " 'How have retrieval and generation components in RAG been optimized in the last year?',\n",
       " 'What are the major trends in RAG development as of September 2025?']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_expansion = QueryExpansion(output_worker_key=\"expand_query\")\n",
    "await query_expansion.arun(query_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1b98fd",
   "metadata": {},
   "source": [
    "Get it! We have successfully completed the small module for query expansion. Reviewing the code, we find that each `@worker` decorator has an `args_mapping_rule` parameter. Let's understand what it does.\n",
    "\n",
    "<div style=\"text-align: center; margin: 2rem 0;\">\n",
    "<hr style=\"border: none; border-top: 2px solid #e2e8f0;\">\n",
    "</div>\n",
    "\n",
    "## 1. Arguments Mapping\n",
    "\n",
    "The `args_mapping_rule` defines the way data is passed between directly dependent workers, that is, how the result of the previous worker is mapped to the parameter of the next worker. Its value can only be specified through the properties of `ArgsMappingRule`.\n",
    "\n",
    "### AS_IS mode (Bridgic default)\n",
    "\n",
    "In the AS_IS mode, a worker will receive the output of all its directly dependent workers as input parameters in the order declared by the dependencies.\n",
    "\n",
    "In the above example, `extract_entity` declares dependencies: `dependencies=[\"pre_query\", \"pre_date\"]`, so the results of the two preceding workers will be mapped to the first and second parameters of `extract_entity` in the order specified by the dependencies declaration, the result of `pre_query` is mapped to `query` parameter and the result of `pre_date` is mapped to `date` parameter.\n",
    "\n",
    "> Note:\n",
    "> The declaration order in dependencies only affects the order of parameter mapping, but does not influence the execution order of the dependent workers.\n",
    "\n",
    "<br>\n",
    "<div style=\"text-align: center;\">\n",
    "<img src=\"../imgs/args_mapping_AS_IS.png\" alt=\"Parameter Passing\" width=\"600\" height=\"400\">\n",
    "</div>\n",
    "<br>\n",
    "\n",
    "Additionally, if the previous worker returns a result with multiple values, such as `return x, y`, then all the results will be passed as a tuple result. So in the above example, the parameter `query_meta` of `expand_query` received all the result values from `extract_entity`.\n",
    "\n",
    "### UNPACK mode\n",
    "\n",
    "Let's go back to the previous example. In the `expand_query`, we receive the parameters from the previous worker in the `AS_IS` mode and manually unpack them as a whole, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a6ce2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@worker(dependencies=[\"extract_entity\"], args_mapping_rule=ArgsMappingRule.AS_IS)\n",
    "async def expand_query(self, query_meta: Tuple[str, List[str]]):  # Expand and obtain multiple queries.\n",
    "    query, entities, date = query_meta\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6714f641",
   "metadata": {},
   "source": [
    "This operation requires to know what the parameters of `query_meta` as a whole contain, which might seem inconvenient. Could we complete the unpacking operation and fill in the corresponding parameters when returning? At this point, the `UNPACK` mode comes in handy.\n",
    "\n",
    "Let's modify the `expand_query` in the above example and add some print message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c877f908",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryExpansion(GraphAutoma):\n",
    "    @worker(is_start=True)\n",
    "    async def pre_query(self, query_obj: Dict):  # Receive the user's input and preprocess query\n",
    "        query = query_obj[\"query\"].split(\":\")[1].strip()  \n",
    "        return query\n",
    "\n",
    "    @worker(is_start=True)\n",
    "    async def pre_date(self, query_obj: Dict):  # Receive the user's input and preprocess date\n",
    "        date = query_obj[\"date\"]\n",
    "        return date\n",
    "\n",
    "    @worker(dependencies=[\"pre_query\", \"pre_date\"], args_mapping_rule=ArgsMappingRule.AS_IS)\n",
    "    async def extract_entity(self, query: str, date: str):  # Extract the entity information from the question, get entity information.\n",
    "        response: EntityList = llm.structured_output(  \n",
    "            model=_model_name,\n",
    "            constraint=PydanticModel(model=EntityList),\n",
    "            messages=[\n",
    "                Message.from_text(text=\"extract the entity information from the given query\", role=Role.SYSTEM),\n",
    "                Message.from_text(text=query, role=Role.USER,),\n",
    "            ]\n",
    "        )\n",
    "        return query, response.entities, date\n",
    "\n",
    "    @worker(dependencies=[\"extract_entity\"], args_mapping_rule=ArgsMappingRule.UNPACK)\n",
    "    async def expand_query(self, query: str, entities: List[str], date: str):  # Expand and obtain multiple queries.\n",
    "        print(f\"query: {query}, entities: {entities}, date: {date}\")\n",
    "        task_input = f\"Query: {query}\\nEntities: {entities}\"\n",
    "        response: str = llm.structured_output(\n",
    "            model=_model_name,\n",
    "            constraint=PydanticModel(model=QueryList),\n",
    "            messages=[\n",
    "                Message.from_text(text=f\"Centered around the given entities and given date {date}, expand the query to obtain multiple queries\", role=Role.SYSTEM),\n",
    "                Message.from_text(text=task_input, role=Role.USER,),\n",
    "            ]\n",
    "        )\n",
    "        return response.queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c993d7",
   "metadata": {},
   "source": [
    "Let's run it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eef02735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query: What new developments have there been in RAG in the past year?, entities: ['RAG', 'new developments', 'past year'], date: 2025-09-30\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['What are the latest advancements in Retrieval-Augmented Generation (RAG) technologies as of 2025?',\n",
       " 'What new developments have emerged in RAG systems over the past 12 months?',\n",
       " 'How has RAG evolved in the last year with regard to accuracy, scalability, and real-time performance?',\n",
       " 'What are the key innovations in RAG models reported in 2024 and 2025?',\n",
       " 'What new tools and frameworks have been introduced for RAG implementation in the past year?',\n",
       " 'What breakthroughs in RAG have improved retrieval precision and context handling in 2025?',\n",
       " 'How have privacy and security features been enhanced in RAG systems over the past year?',\n",
       " 'What new applications of RAG have been developed in the last 12 months across industries?',\n",
       " 'What challenges and solutions have been proposed in RAG research during 2024–2025?',\n",
       " 'What role has RAG played in the evolution of large language models in the past year?']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_expansion = QueryExpansion(output_worker_key=\"expand_query\")\n",
    "await query_expansion.arun(query_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffa3e8b",
   "metadata": {},
   "source": [
    "Get it! All the parameters were unpacked and accepted. It can be seen that the `unpack` mode makes our task flow clearer!\n",
    "\n",
    "However, it should be noted that the UNPACK mechanism requires that the current worker can only directly depend on one worker; otherwise, the results of multiple workers will be confused when unpacking!\n",
    "\n",
    "### MERGE\n",
    "\n",
    "At the same time, conversely, since there is an UNPACK mechanism, is there also a mechanism that can aggregate multiple results for receiving? This is particularly useful when a worker collects the results of multiple dependent workers. At this point, the `MERGE` mode comes in handy.\n",
    "\n",
    "Still referring to the example above, `extract_entity` actually received the results from two workers. Now let's try to make `extract_entity` receive all these results in a single parameter for use, instead of receiving two parameters.\n",
    "\n",
    "Let's modify the `extract_entity` in the above example and add some print message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "20669f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryExpansion(GraphAutoma):\n",
    "    @worker(is_start=True)\n",
    "    async def pre_query(self, query_obj: Dict):  # Receive the user's input and preprocess query\n",
    "        query = query_obj[\"query\"].split(\":\")[1].strip()  \n",
    "        return query\n",
    "\n",
    "    @worker(is_start=True)\n",
    "    async def pre_date(self, query_obj: Dict):  # Receive the user's input and preprocess date\n",
    "        date = query_obj[\"date\"]\n",
    "        return date\n",
    "\n",
    "    @worker(dependencies=[\"pre_query\", \"pre_date\"], args_mapping_rule=ArgsMappingRule.MERGE)\n",
    "    async def extract_entity(self, query_meta: Tuple[str, str]):  # Extract the entity information from the question, get entity information.\n",
    "        print(f\"query_meta: {query_meta}\")\n",
    "        query, date = query_meta\n",
    "        response: EntityList = llm.structured_output(  \n",
    "            model=_model_name,\n",
    "            constraint=PydanticModel(model=EntityList),\n",
    "            messages=[\n",
    "                Message.from_text(text=\"extract the entity information from the given query\", role=Role.SYSTEM),\n",
    "                Message.from_text(text=query, role=Role.USER,),\n",
    "            ]\n",
    "        )\n",
    "        return query, response.entities, date\n",
    "\n",
    "    @worker(dependencies=[\"extract_entity\"], args_mapping_rule=ArgsMappingRule.UNPACK)\n",
    "    async def expand_query(self, query: str, entities: List[str], date: str):  # Expand and obtain multiple queries.\n",
    "        task_input = f\"Query: {query}\\nEntities: {entities}\"\n",
    "        response: str = llm.structured_output(\n",
    "            model=_model_name,\n",
    "            constraint=PydanticModel(model=QueryList),\n",
    "            messages=[\n",
    "                Message.from_text(text=f\"Centered around the given entities and given date {date}, expand the query to obtain multiple queries\", role=Role.SYSTEM),\n",
    "                Message.from_text(text=task_input, role=Role.USER,),\n",
    "            ]\n",
    "        )\n",
    "        return response.queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234bfee4",
   "metadata": {},
   "source": [
    "Let's run it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "73143dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query_meta: ['What new developments have there been in RAG in the past year?', '2025-09-30']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['What are the latest advancements in Retrieval-Augmented Generation (RAG) technologies as of 2025?',\n",
       " 'What new developments have emerged in RAG systems over the past 12 months?',\n",
       " 'How has RAG evolved in the last year with recent innovations in AI and natural language processing?',\n",
       " 'What are the key updates and improvements in RAG models from 2024 to 2025?',\n",
       " 'What new features and techniques have been introduced in RAG solutions in the past year?',\n",
       " 'What recent breakthroughs in RAG have been reported in 2025?',\n",
       " 'What are the most significant developments in RAG technology between 2024 and 2025?',\n",
       " 'How have retrieval and generation components in RAG been enhanced in the last year?',\n",
       " 'What new applications of RAG have been introduced in the past year?',\n",
       " 'What research papers or industry reports highlight new developments in RAG from 2024 to 2025?']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_expansion = QueryExpansion(output_worker_key=\"expand_query\")\n",
    "await query_expansion.arun(query_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c764c362",
   "metadata": {},
   "source": [
    "Get it! The results that `extract_entity` depends on from the workers have all been collected into a list and passed to its parameters.\n",
    "\n",
    "<div style=\"text-align: center; margin: 2rem 0;\">\n",
    "<hr style=\"border: none; border-top: 2px solid #e2e8f0;\">\n",
    "</div>\n",
    "\n",
    "## 2. Arguments Injection\n",
    "\n",
    "Looking back at the example above, we actually find that the `date` information is passed through `pre_date`, `extract_entity`, and finally reaches `expand_query`. However, in reality, `extract_entity` doesn't use this information at all. Thus, passing `date` here seems redundant. And The use of `date` in `expand_query` essentially only means that the data depends on it, but whether it is executed or not, this control dependency does not directly rely on it.\n",
    "\n",
    "> Bridgic emphasizes the separation of data dependency and control dependency. This is beneficial for the future construction of complex execution graphs, as it allows for decoupling and avoids the need to adjust the entire orchestration map due to changes in data dependency. If you want to know Bridgic's in-depth thoughts on this aspect, **you can read this document**.\n",
    "\n",
    "In bridgic, we can use Arguments Injection to make it. We can indicate which worker's result to take by using the `From` marker when declaring parameters, and at the same time set the default value if no result is obtained. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1e5c03ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the From marker\n",
    "from bridgic.core.automa import From"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56004fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "@worker(dependencies=[\"extract_entity\"], args_mapping_rule=ArgsMappingRule.UNPACK)\n",
    "async def expand_query(self, query_meta: Tuple[str, str], date: str = From(\"pre_date\", \"2025-01-01\")):  # Expand and obtain multiple queries.\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62cbc450",
   "metadata": {},
   "source": [
    "`date: str = From(\"pre_date\", \"2025-01-01\")` indicates that the value of `date` will be assigned based on the result of the `pre_date` worker. If the result from this worker has not yet been produced, the default value will be used instead.\n",
    "\n",
    "> If the pre_date worker does not exist, or if the pre_date worker has not yet produced a result, and there is no default value, an error will be reported: AutomaDataInjectionError.\n",
    "\n",
    "Let's modify the example in the above example and add some print message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2d53af7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryExpansion(GraphAutoma):\n",
    "    @worker(is_start=True)\n",
    "    async def pre_query(self, query_obj: Dict):  # Receive the user's input and preprocess query\n",
    "        query = query_obj[\"query\"].split(\":\")[1].strip()  \n",
    "        return query\n",
    "\n",
    "    @worker(is_start=True)\n",
    "    async def pre_date(self, query_obj: Dict):  # Receive the user's input and preprocess date\n",
    "        date = query_obj[\"date\"]\n",
    "        return date\n",
    "\n",
    "    @worker(dependencies=[\"pre_query\"], args_mapping_rule=ArgsMappingRule.AS_IS)\n",
    "    async def extract_entity(self, query: str):  # Extract the entity information from the question, get entity information.\n",
    "        response: EntityList = llm.structured_output(  \n",
    "            model=_model_name,\n",
    "            constraint=PydanticModel(model=EntityList),\n",
    "            messages=[\n",
    "                Message.from_text(text=\"extract the entity information from the given query\", role=Role.SYSTEM),\n",
    "                Message.from_text(text=query, role=Role.USER,),\n",
    "            ]\n",
    "        )\n",
    "        return query, response.entities\n",
    "\n",
    "    @worker(dependencies=[\"extract_entity\"], args_mapping_rule=ArgsMappingRule.UNPACK)\n",
    "    async def expand_query(self, query: str, entities: List[str], date: str = From(\"pre_date\", \"2025-01-01\")):  # Expand and obtain multiple queries.\n",
    "        print(f\"query: {query}, entities: {entities}, date: {date}\")\n",
    "        task_input = f\"Query: {query}\\nEntities: {entities}\"\n",
    "        response: str = llm.structured_output(\n",
    "            model=_model_name,\n",
    "            constraint=PydanticModel(model=QueryList),\n",
    "            messages=[\n",
    "                Message.from_text(text=f\"Centered around the given entities and given date {date}, expand the query to obtain multiple queries\", role=Role.SYSTEM),\n",
    "                Message.from_text(text=task_input, role=Role.USER,),\n",
    "            ]\n",
    "        )\n",
    "        return response.queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcc8d11",
   "metadata": {},
   "source": [
    "Let's run it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "77f91d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query: What new developments have there been in RAG in the past year?, entities: ['RAG', 'new developments', 'past year'], date: 2025-09-30\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['What are the latest advancements in Retrieval-Augmented Generation (RAG) technology as of 2025?',\n",
       " 'What new developments have emerged in RAG systems over the past 12 months?',\n",
       " 'How have RAG implementations evolved in the last year in terms of performance and scalability?',\n",
       " 'What are the most significant innovations in RAG research and deployment from 2024 to 2025?',\n",
       " 'What new features or techniques in RAG have been introduced in the past year to improve accuracy and context handling?',\n",
       " 'How have industry applications of RAG changed in the last year with new technical developments?',\n",
       " 'What are the key breakthroughs in RAG that have been reported in 2025?',\n",
       " 'What new tools and frameworks have been released for RAG development in the past year?',\n",
       " 'How have security and privacy concerns in RAG been addressed in recent developments?',\n",
       " 'What are the major shifts in RAG architecture and model integration observed in the last year?']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_expansion = QueryExpansion(output_worker_key=\"expand_query\")\n",
    "await query_expansion.arun(query_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff79e0b",
   "metadata": {},
   "source": [
    "I have modified `extract_entity`, and now it only accepts `query`, making its functionality more pure. Also, in `expand_query`, I have correctly obtained the `date`.\n",
    "\n",
    "<div style=\"text-align: center; margin: 2rem 0;\">\n",
    "<hr style=\"border: none; border-top: 2px solid #e2e8f0;\">\n",
    "</div>\n",
    "\n",
    "## 3. Inputs Propagation\n",
    "\n",
    "Looking back at the example above, our program did not process the `id` field in the input at all. Eventually, we only returned a list of generalized problems, which might cause the external call to be unable to associate which \"id\" corresponds to the result. However, this ID neither requires preprocessing nor is it needed for entity extraction.\n",
    "\n",
    "We can use Inputs Propagation to resolve it. This can be achieved by adding the name of the startup parameter to the worker when declaring the parameters.\n",
    "\n",
    "> Of course, we can resolve it by adding new start worker, using `From` marker, even passing worker by worker. The main purpose of using this feature here is to understand the Inputs Propagation mechanism of Bridgic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae547ab",
   "metadata": {},
   "source": [
    "```diff\n",
    "@worker(dependencies=[\"extract_entity\"], args_mapping_rule=ArgsMappingRule.UNPACK)\n",
    "async def expand_query(\n",
    "    self, \n",
    "    query: str, \n",
    "    entities: List[str], \n",
    "+    query_obj: Dict,  # The input of the entire Automa\n",
    "    date: str = From(\"pre_date\", \"2025-01-01\"), \n",
    "):  # Expand and obtain multiple queries.\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c4b3b2",
   "metadata": {},
   "source": [
    "Let's modify the example in the above example and add some print message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "10c6a68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryExpansion(GraphAutoma):\n",
    "    @worker(is_start=True)\n",
    "    async def pre_query(self, query_obj: Dict):  # Receive the user's input and preprocess query\n",
    "        query = query_obj[\"query\"].split(\":\")[1].strip()  \n",
    "        return query\n",
    "\n",
    "    @worker(is_start=True)\n",
    "    async def pre_date(self, query_obj: Dict):  # Receive the user's input and preprocess date\n",
    "        date = query_obj[\"date\"]\n",
    "        return date\n",
    "\n",
    "    @worker(dependencies=[\"pre_query\"], args_mapping_rule=ArgsMappingRule.AS_IS)\n",
    "    async def extract_entity(self, query: str):  # Extract the entity information from the question, get entity information.\n",
    "        response: EntityList = llm.structured_output(  \n",
    "            model=_model_name,\n",
    "            constraint=PydanticModel(model=EntityList),\n",
    "            messages=[\n",
    "                Message.from_text(text=\"extract the entity information from the given query\", role=Role.SYSTEM),\n",
    "                Message.from_text(text=query, role=Role.USER,),\n",
    "            ]\n",
    "        )\n",
    "        return query, response.entities\n",
    "\n",
    "    @worker(dependencies=[\"extract_entity\"], args_mapping_rule=ArgsMappingRule.UNPACK)\n",
    "    async def expand_query(self, query: str, entities: List[str], query_obj: Dict, date: str = From(\"pre_date\", \"2025-01-01\")):  # Expand and obtain multiple queries.\n",
    "        print(f\"query: {query}, entities: {entities}, date: {date}, query_obj: {query_obj}\")\n",
    "        task_input = f\"Query: {query}\\nEntities: {entities}\"\n",
    "        response: str = llm.structured_output(\n",
    "            model=_model_name,\n",
    "            constraint=PydanticModel(model=QueryList),\n",
    "            messages=[\n",
    "                Message.from_text(text=f\"Centered around the given entities and given date {date}, expand the query to obtain multiple queries\", role=Role.SYSTEM),\n",
    "                Message.from_text(text=task_input, role=Role.USER,),\n",
    "            ]\n",
    "        )\n",
    "        return {\"id\": query_obj[\"id\"], \"queries\": response.queries}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a537378",
   "metadata": {},
   "source": [
    "Let's run it! When using the Inputs Propagation, the startup parameters must be passed in the form of key-words at startup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ef6dc20d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query: What new developments have there been in RAG in the past year?, entities: ['RAG', 'new developments', 'past year'], date: 2025-09-30, query_obj: {'id': 'user_1', 'query': 'Q: What new developments have there been in RAG in the past year?', 'date': '2025-09-30'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 'user_1',\n",
       " 'queries': ['What are the latest advancements in Retrieval-Augmented Generation (RAG) technologies as of 2025?',\n",
       "  'What new developments have emerged in RAG systems over the past 12 months?',\n",
       "  'How have RAG implementations evolved in the last year in terms of performance and scalability?',\n",
       "  'What are the key innovations in RAG that have been introduced between 2024 and 2025?',\n",
       "  'What new techniques in RAG have been published or adopted in the past year?',\n",
       "  'What are the most significant updates in RAG frameworks and tools from 2024 to 2025?',\n",
       "  'How have RAG models improved in accuracy and context handling in the last year?',\n",
       "  'What new applications of RAG have been developed in the past 12 months?',\n",
       "  'What challenges and solutions in RAG have been highlighted in recent research (2024–2025)?',\n",
       "  'What are the major trends in RAG development as of September 2025?']}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_expansion = QueryExpansion(output_worker_key=\"expand_query\")\n",
    "await query_expansion.arun(query_obj=query_obj)  # using key-words parameter passing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346812eb",
   "metadata": {},
   "source": [
    "Among all the ways of parameter passing mentioned above, the priority order is: arguments mapping positional parameters > arguments injection > propagation > arguments mapping key-words parameters. If want to know how it works, please read this document: **xxx**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

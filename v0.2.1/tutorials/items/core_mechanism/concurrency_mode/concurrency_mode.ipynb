{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd9f9b0d",
   "metadata": {},
   "source": [
    "# Concurrency Mode\n",
    "\n",
    "Bridgic runs primarily on an asynchronous event loop, while seamlessly supporting I/O-bound tasks through threads. This design ensures high concurrency across diverse workloads.\n",
    "\n",
    "## Web content analysis assistant\n",
    "\n",
    "To explore Bridgic’s support for concurrency, let’s build a web content analysis assistant to summarize and introduce the main content of a given web page. The steps are as follows:\n",
    "\n",
    "1. Crawl relevant content of the input url.\n",
    "2. Summarize and introduce main content\n",
    "\n",
    "### 1. Crawl relevant content\n",
    "\n",
    "Taking the *[Books to Scrape](http://books.toscrape.com/index.html)* website as an example, we are given the url of a book page on the website. Like this: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609f7dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"http://books.toscrape.com/catalogue/a-light-in-the-attic_1000/index.html\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cc446c",
   "metadata": {},
   "source": [
    "The page looks like this:\n",
    "\n",
    "<br>\n",
    "<div style=\"text-align: center;\">\n",
    "<img src=\"../../../imgs/books_to-scrape.png\" alt=\"Parameter Passing\" width=\"800\" height=\"600\">\n",
    "</div>\n",
    "<br>\n",
    "\n",
    "> Note: We use [Books to Scrape](http://books.toscrape.com/index.html), a demo website created specifically for practicing web scraping, to introduce in this tutorial. Please note that the purpose of writing a crawler here is **not** to build a real scraper, but to provide a simple and safe example to demonstrate how Bridgic handles both synchronous and asynchronous execution models.\n",
    "\n",
    "We use `requests` to obtain the web content of the given url. Use `pip install requests` to install `requests` package and crawl the page like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0bae62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_web_content(url):  # will return the web content of the given url\n",
    "    response = requests.get(url)\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4e4be8",
   "metadata": {},
   "source": [
    "### 2. Summarize and introduce main content\n",
    "\n",
    "We create an agent, input a url and crawl the corresponding page, and then let the model summarize the main content of the web page.\n",
    "\n",
    "Initialize the runtime environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80454765",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set the API base and key.\n",
    "_api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "_api_base = os.environ.get(\"OPENAI_API_BASE\")\n",
    "_model_name = os.environ.get(\"OPENAI_MODEL_NAME\")\n",
    "\n",
    "# Import the necessary modules.\n",
    "from bridgic.core.automa import GraphAutoma, worker\n",
    "from bridgic.core.model.types import Message, Role\n",
    "from bridgic.llms.openai_like import OpenAILikeLlm\n",
    "\n",
    "llm = OpenAILikeLlm(api_base=_api_base, api_key=_api_key, timeout=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf4e99c",
   "metadata": {},
   "source": [
    "Let's write web content analysis assistant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03c9320",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WebContentAnalysisAgent(GraphAutoma):\n",
    "    @worker(is_start=True)\n",
    "    def crawl_web_content(self, url: str) -> str:\n",
    "        response = requests.get(url)\n",
    "        return response.text\n",
    "\n",
    "    @worker(dependencies=[\"crawl_web_content\"], is_output=True)\n",
    "    async def analyze_web_content(self, content: str) -> str:\n",
    "        response = await llm.achat(\n",
    "            model=_model_name,\n",
    "            messages=[\n",
    "                Message.from_text(text=\"You are a web content analysis assistant. Your task is to analyze the given web content and summarize the main content.\", role=Role.SYSTEM),\n",
    "                Message.from_text(text=content, role=Role.USER),\n",
    "            ]\n",
    "        )\n",
    "        return response.message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16734af",
   "metadata": {},
   "source": [
    "Now, let's use it to help us analyze the content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f999eaf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- - - - - result - - - - -\n",
      "The provided HTML content is from a product page on **Books to Scrape**, a demo website designed for web scraping education. Here's a clear summary of the main content:\n",
      "\n",
      "---\n",
      "\n",
      "### **Main Content Summary: A Light in the Attic**\n",
      "\n",
      "- **Product Title**: *A Light in the Attic*  \n",
      "- **Author**: Shel Silverstein  \n",
      "- **Category**: Poetry  \n",
      "- **Product Type**: Book (Poetry with illustrations)  \n",
      "- **Price**: £51.77 (excl. and incl. tax; tax is £0.00)  \n",
      "- **Availability**: In stock (22 units available)  \n",
      "- **Rating**: 5 stars (all full stars)  \n",
      "- **Number of Reviews**: 0  \n",
      "\n",
      "---\n",
      "\n",
      "### **Product Description Highlights**\n",
      "- Celebrates its 20th anniversary with a special edition.\n",
      "- Known for humorous, creative, and rhythmic poetry that appeals to both children and adults.\n",
      "- Features classic verses such as *\"Rockabye Baby\"*:\n",
      "  > *\"Rockabye baby, in the treetop / Don't you know a treetop / Is no safe place to rock?\"*\n",
      "- Described as a timeless classic that brings joy and laughter to readers of all ages.\n",
      "\n",
      "---\n",
      "\n",
      "### **Important Note**\n",
      "> ⚠️ **This is a demo website** for web scraping training.  \n",
      "> - Prices and ratings are **randomly assigned** and **do not reflect real-world data**.  \n",
      "> - The site is not a real marketplace and should not be used for actual purchases.\n",
      "\n",
      "---\n",
      "\n",
      "### **Navigation Path**\n",
      "Home → Books → Poetry → *A Light in the Attic*\n",
      "\n",
      "---\n",
      "\n",
      "### **Visual Elements**\n",
      "- A single image of the book displayed in a carousel.\n",
      "- Clean, responsive layout with a header, product gallery, pricing, and description sections.\n",
      "\n",
      "---\n",
      "\n",
      "✅ **Purpose of the Page**: To demonstrate how to extract product details (title, price, description, availability, etc.) from e-commerce-style web pages — useful for teaching web scraping techniques.  \n",
      "\n",
      "❌ **Not for real shopping** — all data is fictional.  \n",
      "\n",
      "--- \n",
      "\n",
      "In short: This page showcases a fictional version of a beloved children's poetry book, presented in a realistic e-commerce format, but with no real pricing or user reviews.\n",
      "- - - - - end - - - - -\n"
     ]
    }
   ],
   "source": [
    "web_content_analysis_agent = WebContentAnalysisAgent()\n",
    "\n",
    "# Input the url of the web page to be analyzed.\n",
    "url = \"http://books.toscrape.com/catalogue/a-light-in-the-attic_1000/index.html\"\n",
    "\n",
    "# Call the agent to analyze the web content.\n",
    "res = await web_content_analysis_agent.arun(url)\n",
    "\n",
    "# Print the result.\n",
    "print(f'- - - - - result - - - - -')\n",
    "print(res)\n",
    "print(f'- - - - - end - - - - -')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad2c333",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; margin: 2rem 0;\">\n",
    "<hr style=\"border: none; border-top: 2px solid #e2e8f0;\">\n",
    "</div>\n",
    "\n",
    "## What have we learnt?\n",
    "\n",
    "It can be seen from the example that Bridgic can seamlessly schedule both asynchronous and synchronous workers within the same automa. Although `crawl_web_content` performs a blocking network request, Bridgic automatically dispatches it to a thread so that the event loop remains unblocked. Meanwhile, `analyze_web_content` runs asynchronously within the event loop. Refer to [`Worker`](../../../../reference/bridgic-core/bridgic/core/automa/worker/#bridgic.core.automa.worker.Worker) for details.\n",
    "\n",
    "In this way, Bridgic keeps an asynchronous-first design, but also provides built-in support for I/O-bound operations through its thread pool, ensuring smooth execution across different types of workloads."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

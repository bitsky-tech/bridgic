{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25379a8b",
   "metadata": {},
   "source": [
    "# Dynamic Topology\n",
    "In the [previous section](../dynamic_routing) of this tutorial, we learned how to use the [`ferry_to()`](../../../../reference/bridgic-core/bridgic/core/automa/#bridgic.core.automa.GraphAutoma.ferry_to) API to implement dynamic routing. This capability allows us to create branching and looping logic, forming the foundation for handling dynamic behavior driven by runtime inputs. However, when we take into account the highly autonomous planning capabilities of LLMs, the dynamic features provided by `ferry_to()` alone are no longer sufficient.\n",
    "\n",
    "In order to support highly autonomous AI applications, the orchestration of workers in Bridgic is built on a **Dynamic Directed Graph (DDG)**, whose topology can change at runtime. This DDG-based architecture is especially useful in scenarios where the execution path planned by an LLM cannot be predetermined at coding time. It provides a greater degree of flexibility than the routing mechanism described earlier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f654d6a",
   "metadata": {},
   "source": [
    "## Example: Tool Selection\n",
    "\n",
    "Most LLMs support tool selection and invocation — a crucial step of a typical agent loop.\n",
    "In the following example, we’ll demonstrate the key process of tool selection through a *Travel Planning Agent*, and use Bridgic’s **dynamic topology** to implement tool calling.\n",
    "\n",
    "**Note**:\n",
    "\n",
    "This code example is for demonstration purposes only. It represents part of the overall execution flow within a complete agent loop.\n",
    "If you intend to use tool calling and the agent loop in production, please use the [`ReActAutoma`](../../../../reference/bridgic-core/bridgic/core/agentic/#bridgic.core.agentic.ReActAutoma) class provided by the Bridgic framework."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7afcec",
   "metadata": {},
   "source": [
    "Run the following `pip` command to make sure the ['openai' integration](../../../../reference/bridgic-llms-openai/bridgic/llms/openai/) is installed.\n",
    "\n",
    "```shell\n",
    "pip install -U bridgic\n",
    "pip install -U bridgic-llms-openai\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be65ef89",
   "metadata": {},
   "source": [
    "### 1. Initialization\n",
    "\n",
    "Before we start, let's initialize the OpenAI LLM instance and the running environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e32e34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Get the API base, API key and model name.\n",
    "_api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "_api_base = os.environ.get(\"OPENAI_API_BASE\")\n",
    "_model_name = os.environ.get(\"OPENAI_MODEL_NAME\")\n",
    "\n",
    "from bridgic.llms.openai import OpenAILlm, OpenAIConfiguration\n",
    "\n",
    "llm = OpenAILlm(  # the llm instance\n",
    "    api_base=_api_base,\n",
    "    api_key=_api_key,\n",
    "    configuration=OpenAIConfiguration(model=_model_name),\n",
    "    timeout=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f15da9",
   "metadata": {},
   "source": [
    "### 2. Preparing Tools\n",
    "\n",
    "In the travel-planning example, we need to provide several tools for the LLM to call. The following code defines these tools as functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99108f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Three mock tools defined as async functions.\n",
    "\n",
    "async def get_weather(city: str, days: int):\n",
    "    \"\"\"\n",
    "    Get the weather forecast for the next few days in a specified city.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    city : str\n",
    "        The city to get the weather of, e.g. New York.\n",
    "    days : int\n",
    "        The number of days to get the weather forecast for.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        The weather forecast for the next few days in the specified city.\n",
    "    \"\"\"\n",
    "    return f\"The weather in {city} will be mostly sunny for the next {days} days.\"\n",
    "\n",
    "async def get_flight_price(origin_city: str, destination_city: str):\n",
    "    \"\"\"\n",
    "    Get the average round-trip flight price from one city to another.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    origin_city : str\n",
    "        The origin city of the flight.\n",
    "    destination_city : str\n",
    "        The destination city of the flight.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        The average round-trip flight price from the origin city to the destination city.\n",
    "    \"\"\"\n",
    "    return f\"The average round-trip flight from {origin_city} to {destination_city} is about $850.\"\n",
    "\n",
    "async def get_hotel_price(city: str, nights: int):\n",
    "    \"\"\"\n",
    "    Get the average price of a hotel stay in a specified city for a given number of nights.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    city : str\n",
    "        The city to get the hotel price of, e.g. New York.\n",
    "    nights : int\n",
    "        The number of nights to get the hotel price for.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        The average price of a hotel stay in the specified city for the given number of nights.\n",
    "    \"\"\"\n",
    "    return f\"A 3-star hotel in {city} costs about $120 per night for {nights} nights.\"\n",
    "\n",
    "from bridgic.core.agentic.tool_specs import FunctionToolSpec\n",
    "\n",
    "funcs = [get_weather, get_flight_price, get_hotel_price]\n",
    "tool_list = [FunctionToolSpec.from_raw(func) for func in funcs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3cba94",
   "metadata": {},
   "source": [
    "In the code above, three tools are defined. The docstring of each tool provides important information, which will serve as the tool descriptions presented to the LLM. Each tool is transformed to a [`FunctionToolSpec`](../../../../reference/bridgic-core/bridgic/core/agentic/tool_specs/#bridgic.core.agentic.tool_specs.FunctionToolSpec) instance, and these three tools are stored in the `tool_list` variable for later use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5136fc6c",
   "metadata": {},
   "source": [
    "### 3. Orchestration\n",
    "\n",
    "This demo consists of four steps:\n",
    "\n",
    "1. **Invoke the LLM**: Pass the list of available tools to the LLM and obtain its `tool_calls` output.\n",
    "2. **Create workers dynamically**: Dynamically create workers based on the `tool_calls` results.\n",
    "3. **Invoke tools**: Let the Bridgic framework automatically schedule and execute those workers that represent the tools.\n",
    "4. **Aggregate results**: Combine the execution results into a list of [`ToolMessage`](../../../../reference/bridgic-core/bridgic/core/agentic/types/#bridgic.core.agentic.types.ToolMessage) objects, which may later be fed into the LLM for further processing.\n",
    "\n",
    "We implement these steps by subclassing [`GraphAutoma`](../../../../reference/bridgic-core/bridgic/core/automa/#bridgic.core.automa.GraphAutoma):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23256d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Any\n",
    "from bridgic.core.automa import GraphAutoma, worker\n",
    "from bridgic.core.agentic.tool_specs import ToolSpec\n",
    "from bridgic.core.model.types import Message, Role, ToolCall\n",
    "from bridgic.core.automa.args import From, ArgsMappingRule\n",
    "from bridgic.core.agentic.types import ToolMessage\n",
    "\n",
    "class TravelPlanner(GraphAutoma):\n",
    "    @worker(is_start=True)\n",
    "    async def invoke_llm(self, user_input: str, tool_list: List[ToolSpec]):\n",
    "        tool_calls, _ = await llm.aselect_tool(\n",
    "            messages=[\n",
    "                Message.from_text(text=\"You are an intelligent AI assistant that can perform tasks by calling available tools.\", role=Role.SYSTEM),\n",
    "                Message.from_text(text=user_input, role=Role.USER),\n",
    "            ], \n",
    "            tools=[tool.to_tool() for tool in tool_list], \n",
    "        )\n",
    "        print(f\"[invoke_llm] - LLM returns tool_calls: {tool_calls}\")\n",
    "        return tool_calls\n",
    "    \n",
    "    @worker(dependencies=[\"invoke_llm\"])\n",
    "    async def process_tool_calls(\n",
    "        self,\n",
    "        tool_calls: List[ToolCall],\n",
    "        tool_list: List[ToolSpec],\n",
    "    ):\n",
    "        matched_list = self._match_tool_calls_and_tool_specs(tool_calls, tool_list)\n",
    "        matched_tool_calls = []\n",
    "        tool_worker_keys = []\n",
    "        for tool_call, tool_spec in matched_list:\n",
    "            matched_tool_calls.append(tool_call)\n",
    "            tool_worker = tool_spec.create_worker()\n",
    "            worker_key = f\"tool_{tool_call.name}_{tool_call.id}\"\n",
    "            print(f\"[process_tool_calls] - add worker: {worker_key}\")\n",
    "            self.add_worker(\n",
    "                key=worker_key,\n",
    "                worker=tool_worker,\n",
    "            )\n",
    "            self.ferry_to(worker_key, **tool_call.arguments)\n",
    "            tool_worker_keys.append(worker_key)\n",
    "        self.add_func_as_worker(\n",
    "            key=\"aggregate_results\",\n",
    "            func=self.aggregate_results,\n",
    "            dependencies=tool_worker_keys,\n",
    "            args_mapping_rule=ArgsMappingRule.MERGE,\n",
    "        )\n",
    "        return matched_tool_calls\n",
    "\n",
    "    async def aggregate_results(\n",
    "        self, \n",
    "        tool_results: List[Any],\n",
    "        tool_calls: List[ToolCall] = From(\"process_tool_calls\"),\n",
    "    ) -> List[ToolMessage]:\n",
    "        print(f\"[aggregate_results] - tool execution results: {tool_results}\")\n",
    "        tool_messages = []\n",
    "        for tool_result, tool_call in zip(tool_results, tool_calls):\n",
    "            tool_messages.append(ToolMessage(\n",
    "                role=\"tool\", \n",
    "                content=str(tool_result), \n",
    "                tool_call_id=tool_call.id\n",
    "            ))\n",
    "        # `tool_messages` may be used as the inputs of the next LLM call...\n",
    "        print(f\"[aggregate_results] - assembled ToolMessage list: {tool_messages}\")\n",
    "        return tool_messages\n",
    "\n",
    "    def _match_tool_calls_and_tool_specs(\n",
    "        self,\n",
    "        tool_calls: List[ToolCall],\n",
    "        tool_list: List[ToolSpec],\n",
    "    ) -> List[Tuple[ToolCall, ToolSpec]]:\n",
    "        matched_list: List[Tuple[ToolCall, ToolSpec]] = []\n",
    "        for tool_call in tool_calls:\n",
    "            for tool_spec in tool_list:\n",
    "                if tool_call.name == tool_spec.tool_name:\n",
    "                    matched_list.append((tool_call, tool_spec))\n",
    "        return matched_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be93ace5",
   "metadata": {},
   "source": [
    "In the start worker `invoke_llm`, the LLM is invoked to return a list of [`ToolCalls`](../../../../reference/bridgic-core/bridgic/core/model/types/#bridgic.core.model.types.ToolCall). Therefore, the information about the tool calls contained in this list is dynamic.\n",
    "\n",
    "In the second worker `process_tool_calls`, based on the dynamic list of `tool_calls`, a worker is created (through `tool_spec.create_worker()`) for each tool to be invoked and added to the DDG. Then, the `aggregate_results` worker is also dynamically added to the DDG via the [`add_func_as_worker()`](../../../../reference/bridgic-core/bridgic/core/automa/#bridgic.core.automa.GraphAutoma.add_func_as_worker) API, responsible for aggregating the execution results from all the tool workers.\n",
    "\n",
    "It is worth noting that invoking multiple tools as workers can fully leverage certain features of the Bridgic framework, such as [Concurrency Mode](../concurrency_mode/). Here, these tools are able to execute concurrently."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5674e729",
   "metadata": {},
   "source": [
    "### 4. Let's run it\n",
    "\n",
    "Let's create a instance of `TravelPlanner` and run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58ba2ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[invoke_llm] - LLM returns tool_calls: [ToolCall(id='call_cLERxyz110tylRxgE4XQjaRQ', name='get_weather', arguments={'city': 'Tokyo', 'days': 3}), ToolCall(id='call_CqicPm6yZoyNksEl9HGVJEOQ', name='get_flight_price', arguments={'origin_city': 'San Francisco', 'destination_city': 'Tokyo'}), ToolCall(id='call_GscwR3pvHtzR2wTki1ndpHZp', name='get_hotel_price', arguments={'city': 'Tokyo', 'nights': 3})]\n",
      "[process_tool_calls] - add worker: tool_get_weather_call_cLERxyz110tylRxgE4XQjaRQ\n",
      "[process_tool_calls] - add worker: tool_get_flight_price_call_CqicPm6yZoyNksEl9HGVJEOQ\n",
      "[process_tool_calls] - add worker: tool_get_hotel_price_call_GscwR3pvHtzR2wTki1ndpHZp\n",
      "[aggregate_results] - tool execution results: ['The weather in Tokyo will be mostly sunny for the next 3 days.', 'The average round-trip flight from San Francisco to Tokyo is about $850.', 'A 3-star hotel in Tokyo costs about $120 per night for 3 nights.']\n",
      "[aggregate_results] - assembled ToolMessage list: [{'role': 'tool', 'content': 'The weather in Tokyo will be mostly sunny for the next 3 days.', 'tool_call_id': 'call_cLERxyz110tylRxgE4XQjaRQ'}, {'role': 'tool', 'content': 'The average round-trip flight from San Francisco to Tokyo is about $850.', 'tool_call_id': 'call_CqicPm6yZoyNksEl9HGVJEOQ'}, {'role': 'tool', 'content': 'A 3-star hotel in Tokyo costs about $120 per night for 3 nights.', 'tool_call_id': 'call_GscwR3pvHtzR2wTki1ndpHZp'}]\n"
     ]
    }
   ],
   "source": [
    "agent = TravelPlanner()\n",
    "await agent.arun(\n",
    "    user_input=\"Plan a 3-day trip to Tokyo. Check the weather forecast, estimate the flight price from San Francisco, and the hotel cost for 3 nights.\",\n",
    "    tool_list=tool_list,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4716b28",
   "metadata": {},
   "source": [
    "## What have we learnt?\n",
    "\n",
    "In this *Travel Planning Agent* example, we have demonstrated how to use Bridgic’s **dynamic topology** mechanism to create workers for tools. The [`GraphAutoma`](../../../../reference/bridgic-core/bridgic/core/automa/#bridgic.core.automa.GraphAutoma) class is implemented as a **Dynamic Directed Graph (DDG)** in Bridgic, to support topology change at runtime. The APIs that support dynamic change of topology include: [`add_worker`](../../../../reference/bridgic-core/bridgic/core/automa/#bridgic.core.automa.GraphAutoma.add_worker), [`add_func_as_worker`](../../../../reference/bridgic-core/bridgic/core/automa/#bridgic.core.automa.GraphAutoma.add_func_as_worker), [`remove_worker`](../../../../reference/bridgic-core/bridgic/core/automa/#bridgic.core.automa.GraphAutoma.remove_worker), and [`add_dependency`](../../../../reference/bridgic-core/bridgic/core/automa/#bridgic.core.automa.GraphAutoma.add_dependency).\n",
    "\n",
    "You might notice that interspersing these API calls within the worker implementation code can look a bit untidy. We plan to address this issue with a new feature in the near future."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bridgic_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

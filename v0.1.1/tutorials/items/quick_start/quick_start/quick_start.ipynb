{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0812860a",
   "metadata": {},
   "source": [
    "# Quick Start\n",
    "\n",
    "In this tutorial, we assume that Bridgic is already installed on your system. If thatâ€™s not the case, see [Installation](../../../installation).\n",
    "\n",
    "Let's start by building a simple word learning assistant. You provide a word, and the assistant will generate its derived forms and create sentences with them. This example will also show how to use Bridgic in practice.\n",
    "\n",
    "## Word learning assistant\n",
    "\n",
    "### 1. Model Initialization\n",
    "\n",
    "Before getting started, let's set up our environment. In this quick start, we'll use the integration out of the box.\n",
    "For an in-depth explanation of model integration, see: [LLM Integration](../../model_integration/llm_integration/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123e3ed3",
   "metadata": {},
   "source": [
    "Execute the following commands in the shell:\n",
    "\n",
    "```shell\n",
    "export OPENAI_API_KEY=\"<your_openai_api_key>\"\n",
    "export OPENAI_MODEL_NAME=\"<the_model_name>\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7468d809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the environment variables.\n",
    "import os\n",
    "\n",
    "# Import the necessary packages.\n",
    "from bridgic.core.automa import GraphAutoma, worker\n",
    "from bridgic.core.model.types import Message, Role\n",
    "\n",
    "# Here we use OpenAILikeLlm because the package `bridgic-llms-openai-like` is installed automatically \n",
    "# when you install Bridgic. This makes sure the OpenAI-like model integration works out of the box.\n",
    "from bridgic.llms.openai_like import OpenAILikeLlm, OpenAILikeConfiguration\n",
    "\n",
    "\n",
    "# In this tutorial, we use OpenAI as an example. \n",
    "# You can freely replace these model settings to use any LLM provider you like.\n",
    "_api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "_api_base = os.environ.get(\"OPENAI_API_BASE\")\n",
    "_model_name = os.environ.get(\"OPENAI_MODEL_NAME\")\n",
    "\n",
    "llm = OpenAILikeLlm(\n",
    "    api_key=_api_key,\n",
    "    api_base=_api_base,\n",
    "    configuration=OpenAILikeConfiguration(model=_model_name),\n",
    "    timeout=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d70238",
   "metadata": {},
   "source": [
    "### 2. Automa Orchestration\n",
    "\n",
    "There are two steps to complete the word learning assistant:\n",
    "\n",
    "1. Generate derivatives of the input word.\n",
    "2. Make sentences with derivatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da260e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordLearningAssistant(GraphAutoma):\n",
    "    @worker(is_start=True)\n",
    "    async def generate_derivatives(self, word: str):\n",
    "        print(f\"------Generating derivatives for {word}------\")\n",
    "        response = await llm.achat(\n",
    "            model=_model_name,\n",
    "            messages=[\n",
    "                Message.from_text(text=\"You are a word learning assistant. Generate derivatives of the input word in a list.\", role=Role.SYSTEM),\n",
    "                Message.from_text(text=word, role=Role.USER),\n",
    "            ]\n",
    "        )\n",
    "        print(response.message.content)\n",
    "        print(f\"------End of generating derivatives------\\n\")\n",
    "        return response.message.content\n",
    "\n",
    "    @worker(dependencies=[\"generate_derivatives\"], is_output=True)\n",
    "    async def make_sentences(self, derivatives):\n",
    "        print(f\"------Making sentences with------\")\n",
    "        response = await llm.achat(\n",
    "            model=_model_name,\n",
    "            messages=[\n",
    "                Message.from_text(text=\"You are a word learning assistant. Make sentences with the input derivatives in a list.\", role=Role.SYSTEM),\n",
    "                Message.from_text(text=derivatives, role=Role.USER),\n",
    "            ]\n",
    "        )\n",
    "        print(response.message.content)\n",
    "        print(f\"------End of making sentences------\\n\")\n",
    "        return response.message.content\n",
    "\n",
    "word_learning_assistant = WordLearningAssistant()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81cf951d",
   "metadata": {},
   "source": [
    "### 3. Agent Running\n",
    "\n",
    "Let's run this assistant, via [`arun`](../../../../reference/bridgic-core/bridgic/core/automa/#bridgic.core.automa.GraphAutoma.arun) method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a6fbb8d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Generating derivatives for happy------\n",
      "Here are some derivatives of the word \"happy\":\n",
      "\n",
      "1. Happiness\n",
      "2. Happily\n",
      "3. Happier\n",
      "4. Happiest\n",
      "5. Unhappy\n",
      "6. Unhappiness\n",
      "7. Happinesses (plural form)\n",
      "8. Happifying (gerund form)\n",
      "9. Happify (verb form)\n",
      "\n",
      "Feel free to ask for derivatives of another word!\n",
      "------End of generating derivatives------\n",
      "\n",
      "------Making sentences with------\n",
      "Sure! Here are sentences using each of the derivatives of the word \"happy\":\n",
      "\n",
      "1. **Happiness**: The pursuit of happiness is a common goal for many people.\n",
      "2. **Happily**: She smiled happily as she opened her birthday gifts.\n",
      "3. **Happier**: After taking a vacation, I felt much happier than I had in months.\n",
      "4. **Happiest**: That day was the happiest moment of my life when my daughter graduated.\n",
      "5. **Unhappy**: He seemed unhappy at the party and left early.\n",
      "6. **Unhappiness**: Her unhappiness was evident in her quiet demeanor.\n",
      "7. **Happinesses**: Different people find happinesses in various aspects of life, like family, work, and hobbies.\n",
      "8. **Happifying**: The act of volunteering can be a happifying experience for both the giver and the receiver.\n",
      "9. **Happify**: Listening to uplifting music can help to happify your day.\n",
      "\n",
      "Let me know if you need sentences for another word!\n",
      "------End of making sentences------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = await word_learning_assistant.arun(word=\"happy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a176cd0c",
   "metadata": {},
   "source": [
    "Congratulations! We have successfully completed the word learning assistant, which performed the task exactly according to our requirements.\n",
    "\n",
    "<div style=\"text-align: center; margin: 2rem 0;\">\n",
    "<hr style=\"border: none; border-top: 2px solid #e2e8f0;\">\n",
    "</div>\n",
    "\n",
    "## What have we done?\n",
    "\n",
    "The above example idemonstrates a typical way to write an agent application with Bridgic. Let's now explore some of its components.\n",
    "\n",
    "### Worker\n",
    "\n",
    "Any callable object (such as functions, methods, etc.) can be converted into a worker object which serve as the **basic execution unit** in Bridgic for scheduling and orchestration. \n",
    "\n",
    "Just as in the example of the word learning assistant, we can use a decorator syntax [`@worker`](../../../../reference/bridgic-core/bridgic/core/automa/#bridgic.core.automa.worker._worker_decorator.worker) to wrap functions and methods into a worker object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d507c1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyAutoma(GraphAutoma):\n",
    "    @worker(is_start=True)\n",
    "    async def start(self, x: int):\n",
    "        return x    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ed3b6b",
   "metadata": {},
   "source": [
    "Or, you can also use it like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614c5d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyAutoma(GraphAutoma): ...\n",
    "my_automa = MyAutoma()\n",
    "\n",
    "# Add the function as a worker with worker decorator in the instance of the automa\n",
    "@my_automa.worker(is_start=True)\n",
    "async def start(x: int):\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fa90f6",
   "metadata": {},
   "source": [
    "Another API [`add_func_as_worker()`](../../../../reference/bridgic-core/bridgic/core/automa/#bridgic.core.automa.GraphAutoma.add_func_as_worker) can also be used to add workers into a [`GraphAutoma`](../../../../reference/bridgic-core/bridgic/core/automa/#bridgic.core.automa.GraphAutoma)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24aa7fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def start(x: int):\n",
    "    return x\n",
    "\n",
    "class MyAutoma(GraphAutoma): ...\n",
    "my_automa = MyAutoma()\n",
    "\n",
    "# Add the function as a worker\n",
    "my_automa.add_func_as_worker(\n",
    "    key=\"start\",\n",
    "    func=start,\n",
    "    is_start=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179b434b",
   "metadata": {},
   "source": [
    "In addition to functions being convertible to workers, subclasses that inherit from [`Worker`](../../../../reference/bridgic-core/bridgic/core/automa/worker/#bridgic.core.automa.worker.Worker) and override either [`run()`](../../../../reference/bridgic-core/bridgic/core/automa/worker/#bridgic.core.automa.worker.Worker.run) or [`arun()`](../../../../reference/bridgic-core/bridgic/core/automa/worker/#bridgic.core.automa.worker.Worker.arun) can also be used directly as workers, whose instances can be added into a `GraphAutoma` by the [`add_worker()`](../../../../reference/bridgic-core/bridgic/core/automa/#bridgic.core.automa.GraphAutoma.add_worker) API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940f833b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bridgic.core.automa.worker import Worker\n",
    "\n",
    "class MyWorker(Worker):\n",
    "    async def arun(self, x: int):\n",
    "        return x\n",
    "\n",
    "my_worker = MyWorker()\n",
    "\n",
    "# Add the worker to the automa\n",
    "class MyAutoma(GraphAutoma): ...\n",
    "my_automa = MyAutoma()\n",
    "my_automa.add_worker(\n",
    "    key=\"my_worker\",\n",
    "    worker=my_worker,\n",
    "    is_start=True,\n",
    ")\n",
    "\n",
    "# Run the worker\n",
    "res = await my_automa.arun(x=1)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5107c75",
   "metadata": {},
   "source": [
    "> Note:\n",
    "> 1. A specific worker that inherits from `Worker` must override either the `run()` or `arun()` method.\n",
    "> 2. Bridgic is a framework primarily designed for asynchronous execution, if both `run()` and `arun()` of a worker are overridden, `arun()` will take precedence. Refer to [`Worker`](../../../../reference/bridgic-core/bridgic/core/automa/worker/#bridgic.core.automa.worker.Worker) for details.\n",
    "\n",
    "In any of these ways the workers can be correctly added into `MyAutoma`. \n",
    "\n",
    "Whether using decorator syntax or the corresponding API, there are usually some parameters:\n",
    "\n",
    "1. `key`: A string used as the worker key. As the unique identifier of a worker in the current automa, it must be ensured that there are no duplicate keys within the same automa. Function or class names are used by default.\n",
    "2. `func`(in [`add_func_as_worker()`](../../../../reference/bridgic-core/bridgic/core/automa/#bridgic.core.automa.GraphAutoma.add_func_as_worker)) or `worker`(in [`add_worker()`](../../../../reference/bridgic-core/bridgic/core/automa/#bridgic.core.automa.GraphAutoma.add_worker)): The actual callable object. **The decorator syntax does not need this parameter.**\n",
    "3. `is_start`: `True` or `False`. Marking the worker as the start worker of the automa. It can be set for multiple workers.\n",
    "4. `dependencies`: A list of worker keys. Marking the preceding workers that the worker depends on.\n",
    "5. `is_output`: `True` or `False`. Marking the worker as the output worker of the automa. Only one output worker can be set per execution branch.\n",
    "6. `args_mapping_rule`: The [arguments mapping rule](../../../../reference/bridgic-core/bridgic/core/automa/args/#bridgic.core.automa.args.ArgsMappingRule). For detailed information on the parameter binding between workers, please refer to the tutorial: [Parameter Binding](../../core_mechanism/parameter_binding/)\n",
    "\n",
    "> Note: In Bridgic, a worker must be added to an automa before it can be scheduled and executed. In another word, you shouldnâ€™t directly call `worker.arun()` or `worker.run()` to run a worker.\n",
    "\n",
    "### GraphAutoma\n",
    "\n",
    "An automa is an entity that manages and orchestrates a group of workers, serving as the **scheduling engine** . In the example of the word learning assistant above, we used the subclass of [`Automa`](../../../../reference/bridgic-core/bridgic/core/automa/#bridgic.core.automa.Automa), i.e. [`GraphAutoma`](../../../../reference/bridgic-core/bridgic/core/automa/#bridgic.core.automa.GraphAutoma), which performs the scheduling according to the topological sorting among workers.\n",
    "\n",
    "You should subclass `GraphAutoma` and declare methods as workers with [`@worker`](../../../../reference/bridgic-core/bridgic/core/automa/#bridgic.core.automa.worker._worker_decorator.worker)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b78c10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write workers in MyAutoma\n",
    "class MyAutoma(GraphAutoma):\n",
    "    @worker(is_start=True)\n",
    "    async def worker_0(self, a, b, x, y):\n",
    "        print(f\"worker_0: a={a}, b={b}, x={x}, y={y}\")\n",
    "\n",
    "    @worker(is_start=True)\n",
    "    async def worker_1(self, x, y):\n",
    "        print(f\"worker_1: x={x}, y={y}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448fab9c",
   "metadata": {},
   "source": [
    "After all the required workers are defined in an automa, the automa can be called with `await automa_obj.arun(*args, **kwargs)` to start the entire scheduling process. \n",
    "\n",
    "> Bridgic is a framework built on asynchronous programming. Thus `Graphautoma` must be started using arun(). However, workers may execute in [concurrency mode](../../../../tutorials/items/core_mechanism/concurrency_mode/) when needed.\n",
    "\n",
    "At startup, the arguments of `automa_obj.arun(*args, **kwargs)` will be distributed to the worker with `is_start=True` according to positional parameters and keyword parameters. \n",
    "\n",
    "- positional parameters: The positional arguments passed to `arun` are mapped to the parameters of the workers marked with `is_start=True`, following the order in which they are provided. An error will be raised if the parameter list of some worker is shorter than the number of positional arguments passed to `arun()`.\n",
    "- keyword parameters: The keyword arguments passed to `arun` are mapped to the corresponding parameters of the workers marked with `is_start=True`.\n",
    "- priority: **Positional arguments take precedence over keyword arguments.**.\n",
    "\n",
    "For example: we pass positional arguments `1` and `2`, and keyword arguments `x=3`, `y=4`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bc5041c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "worker_0: a=1, b=2, x=3, y=4\n",
      "worker_1: x=1, y=2\n"
     ]
    }
   ],
   "source": [
    "my_automa = MyAutoma()\n",
    "await my_automa.arun(1, 2, x=3, y=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9afd803",
   "metadata": {},
   "source": [
    "`1` and `2` were received in order by the first and second parameters of `worker_0` and `worker_1` respectively. Because positional arguments take precedence over keyword arguments, even if the parameter names of `worker_1` are the same as the input keyword parameters, they will still preferentially receive positional arguments.\n",
    "\n",
    "An error will be raised if the parameter list of some worker is shorter than the number of positional arguments passed to `arun`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f188d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_automa = MyAutoma()\n",
    "await my_automa.arun(1, 2, 3, y=4)  # worker_1 raises an error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753eaf90",
   "metadata": {},
   "source": [
    "If all arguments are passed in keyword format, each worker with `is_start=True` can receive the corresponding values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "331382da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "worker_0: a=1, b=2, x=3, y=4\n",
      "worker_1: x=3, y=4\n"
     ]
    }
   ],
   "source": [
    "my_automa = MyAutoma()\n",
    "await my_automa.arun(a=1, b=2, x=3, y=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023e1ed0",
   "metadata": {},
   "source": [
    "Now, we can start building our Bridgic project!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.9.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
